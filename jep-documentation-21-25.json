[
  {
    "url": "https://openjdk.org/jeps/518",
    "title": "JEP 518: JFR Cooperative Sampling",
    "content": {
      "title": "JEP 518: JFR Cooperative Sampling",
      "summary": "JEP 518: JFR Cooperative Sampling JEP 518: JFR Cooperative Sampling Owner Markus Gr&#246;nlund Type Feature Scope Implementation Status Closed&#8201;/&#8201;Delivered Release 25 Component hotspot&#8201;/&#8201;jfr Discussion hotspot dash jfr dash dev at openjdk dot org Effort M Duration M Reviewed by Erik Gahlin, Vladimir Kozlov Endorsed by Vladimir Kozlov Created 2025/02/19 14:12 Updated 2025/06/10 16:31 Issue 8350338 Summary Improve the stability of the JDK Flight Recorder (JFR) when it asynch",
      "sections": {
        "Summary": "Improve the stability of the JDK Flight Recorder (JFR) when it asynchronously samples Java thread stacks. Achieve this by walking call stacks only at safepoints, while minimizing safepoint bias.",
        "Motivation": "A running program consumes computational resources such as memory, CPU cycles, and elapsed time. To profile a program is to measure the consumption of such resources by specific elements of the program. A profile might indicate that, e.g., one method consumes 20% of a resource, while another consumes only 0.1%. Profiling can help make a program more efficient, and developers more productive, by identifying which program elements to optimize. Without profiling, we might optimize a method that was consuming few resources to begin with, having little impact on the program's overall performance while wasting effort. For example, optimizing a method that takes 0.1% of the program's total execution time to run ten times faster will only reduce the program's execution time by 0.09%. JFR, the JDK Flight Recorder, is the JDK's profiling and monitoring facility. The core of JFR is a low-overhead mechanism for recording events emitted by the HotSpot JVM or by program code. Some events, such as lo",
        "Description": "We redesign JFR's sampling mechanism to avoid relying on risky stack-parsing heuristics. Instead, we parse thread stacks only at safepoints. To avoid the safepoint bias problem, we take samples cooperatively. When it is time to take a sample, JFR's sampler thread still suspends the target thread. Rather than attempting to parse the stack, however, it just records the target's program counter and stack pointer in a sample request , which it appends to an internal thread-local queue. It then arranges for the target thread to stop at its next safepoint, and resumes the thread. The target runs normally until its next safepoint. At that time, the safepoint handling code inspects the queue. If it finds any sample requests, then, for each one, it reconstructs a stack trace, adjusting for safepoint bias, and emits a JFR execution-time sampling event. Aside from being safe, this approach has several other advantages: Creating a sample request requires hardly any work, and could be done in respo",
        "Alternatives": "The HotSpot JVM does have an existing internal but unsupported mechanism, AsyncGetCallTrace , which is used by some third-party tools. Unfortunately, this mechanism relies on the same kind of risky stack-parsing heuristics that JFR uses today, but without any crash protection, thus it is even riskier. Another drawback is that it is based on the POSIX SIGPROF signal, an equivalent of which does not exist on Windows.",
        "Testing": "This is strictly an implementation change. Existing unit, integration, and stress tests will suffice.",
        "Dependencies": "The implementation of JEP 509 (JFR CPU-Time Profiling) leverages the mechanism introduced here. Installing Contributing Sponsoring Developers' Guide Vulnerabilities JDK GA/EA Builds Mailing lists Wiki &#183; IRC Mastodon Bluesky Bylaws &#183; Census Legal Workshop JEP Process Source code GitHub Mercurial Tools Git jtreg harness Groups (overview) Adoption Build Client Libraries Compatibility &amp;",
        "Specification": "Review Compiler Conformance Core Libraries Governing Board HotSpot IDE Tooling &amp; Support Internationalization JMX Members Networking Porters Quality Security Serviceability Vulnerability Web Projects ( overview , archive ) Amber Babylon CRaC Code Tools Coin Common VM Interface Developers' Guide Device I/O Duke Galahad Graal IcedTea JDK 8 Updates JDK 9 JDK (&#8230;, 24 , 25 , 26 ) JDK Updates JMC Jigsaw Kona Lanai Leyden Lilliput Locale Enhancement Loom Memory Model Update Metropolis Multi-Language VM Nashorn New I/O OpenJFX Panama Penrose Port: AArch32 Port: AArch64 Port: BSD Port: Haiku Port: Mac OS X Port: MIPS Port: Mobile Port: PowerPC/AIX Port: RISC-V Port: s390x SCTP Shenandoah Skara Sumatra Tsan Valhalla Verona VisualVM Wakefield Zero ZGC &#169; 2025 Oracle Corporation and/or its affiliates Terms of Use &#183; License: GPLv2 &#183; Privacy &#183; Trademarks"
      },
      "fullText": "JEP 518: JFR Cooperative Sampling JEP 518: JFR Cooperative Sampling Owner Markus Gr&#246;nlund Type Feature Scope Implementation Status Closed&#8201;/&#8201;Delivered Release 25 Component hotspot&#8201;/&#8201;jfr Discussion hotspot dash jfr dash dev at openjdk dot org Effort M Duration M Reviewed by Erik Gahlin, Vladimir Kozlov Endorsed by Vladimir Kozlov Created 2025/02/19 14:12 Updated 2025/06/10 16:31 Issue 8350338 Summary Improve the stability of the JDK Flight Recorder (JFR) when it asynchronously samples Java thread stacks. Achieve this by walking call stacks only at safepoints, while minimizing safepoint bias. Motivation A running program consumes computational resources such as memory, CPU cycles, and elapsed time. To profile a program is to measure the consumption of such resources by specific elements of the program. A profile might indicate that, e.g., one method consumes 20% of a resource, while another consumes only 0.1%. Profiling can help make a program more efficient, and developers more productive, by identifying which program elements to optimize. Without profiling, we might optimize a method that was consuming few resources to begin with, having little impact on the program's overall performance while wasting effort. For example, optimizing a method that takes 0.1% of the program's total execution time to run ten times faster will only reduce the program's execution time by 0.09%. JFR, the JDK Flight Recorder, is the JDK's profiling and monitoring facility. The core of JFR is a low-overhead mechanism for recording events emitted by the HotSpot JVM or by program code. Some events, such as loading a class, are recorded whenever an action occurs. Others, such as those used for profiling, are recorded by statistically sampling the program's activity as it consumes a resource. The various JFR events can be turned on or off, allowing a more detailed, higher-overhead collection of information during development and a less detailed, lower-overhead collection of information in production. JFR can create an execution-time profile that shows which program elements consume significant elapsed real time, i.e., wall-clock time. It does this by sampling the execution stacks of program threads at fixed intervals of, say, 20 milliseconds. Each sample produces a JFR event containing a stack trace. Tools such as jfr and JDK Mission Control can summarize a stream of such events into a textual or graphical profile. In order to produce a stack trace for a program thread, JFR's sampler thread must suspend the target thread and parse the call frames on the stack. The HotSpot JVM maintains metadata to guide the parsing of stack frames, but that metadata is valid only when a thread is suspended at well-defined code locations known as safepoints . If we sample stacks only at safepoints, however, then we will likely suffer from the safepoint bias problem: We risk losing accuracy, since a frequently-executed span of code might not be anywhere near a safep"
    }
  },
  {
    "url": "https://openjdk.org/jeps/509",
    "title": "JEP 509: JFR CPU-Time Profiling (Experimental)",
    "content": {
      "title": "JEP 509: JFR CPU-Time Profiling (Experimental)",
      "summary": "JEP 509: JFR CPU-Time Profiling (Experimental) JEP 509: JFR CPU-Time Profiling (Experimental) Authors Jaroslav Bachor&#237;k, Johannes Bechberger, &amp; Ron Pressler Owner Johannes Bechberger Type Feature Scope JDK Status Closed&#8201;/&#8201;Delivered Release 25 Component hotspot&#8201;/&#8201;jfr Discussion hotspot dash jfr dash dev at openjdk dot org Effort M Duration S Reviewed by Markus Gr&#246;nlund Endorsed by Vladimir Kozlov Created 2024/08/04 10:34 Updated 2025/07/31 10:19 Issue 8337789",
      "sections": {
        "Summary": "Enhance the JDK Flight Recorder (JFR) to capture more accurate CPU-time profiling information on Linux. This is an experimental feature.",
        "Motivation": "A running program consumes computational resources such as memory, CPU cycles, and elapsed time. To profile a program is to measure the consumption of such resources by specific elements of the program. A profile might indicate that, e.g., one method consumes 20% of a resource, while another method consumes only 0.1%. Profiling can help make a program more efficient, and developers more productive, by identifying which program elements to optimize. Without profiling, we might optimize a method that consumes few resources to begin with, having little impact on the program's overall performance while wasting effort. For example, optimizing a method that takes up 0.1% of the program&#8217;s total execution time to run ten times faster will only reduce the program's execution time by 0.09%. JFR, the JDK Flight Recorder, is the JDK's profiling and monitoring facility. The core of JFR is a low-overhead mechanism for recording events emitted by the JVM or by program code. Some events, such as",
        "Description": "We add CPU-time profiling to JFR, on Linux systems only. This feature is experimental for now, so that we may refine it based on experience before making it permanent. We may add CPU-time profiling to JFR on other platforms in the future. JFR will use Linux's CPU-timer mechanism to sample the stack of every thread running Java code at fixed intervals of CPU time. Each such sample is recorded in a new type of event, jdk.CPUTimeSample . This event is not enabled by default. This event is similar to the existing jdk.ExecutionSample event for execution-time sampling. Enabling CPU-time events does not affect execution-time events in any way, so the two can be collected simultaneously. We can enable the new event in a recording started at launch like so: $ java -XX:StartFlightRecording=jdk.CPUTimeSample#enabled=true,filename=profile.jfr ... Example Consider a program, HttpRequests , with two threads, each performing HTTP requests. One thread runs a tenFastRequests method that makes ten reque",
        "Alternatives": "We could enable external tools to use the Linux CPU-time sampler by adding safe and supported native HotSpot APIs for that purpose. Doing so would, however, expose internal details of the runtime, which would make the JDK harder to evolve. This approach would also be less efficient, and thus less suitable for profiling in production, than implementing the feature directly in the JDK.",
        "Dependencies": "The implementation of this feature leverages the cooperative-sampling mechanism introduced by JEP 518 . Installing Contributing Sponsoring Developers' Guide Vulnerabilities JDK GA/EA Builds Mailing lists Wiki &#183; IRC Mastodon Bluesky Bylaws &#183; Census Legal Workshop JEP Process Source code GitHub Mercurial Tools Git jtreg harness Groups (overview) Adoption Build Client Libraries Compatibility &amp;",
        "Specification": "Review Compiler Conformance Core Libraries Governing Board HotSpot IDE Tooling &amp; Support Internationalization JMX Members Networking Porters Quality Security Serviceability Vulnerability Web Projects ( overview , archive ) Amber Babylon CRaC Code Tools Coin Common VM Interface Developers' Guide Device I/O Duke Galahad Graal IcedTea JDK 8 Updates JDK 9 JDK (&#8230;, 24 , 25 , 26 ) JDK Updates JMC Jigsaw Kona Lanai Leyden Lilliput Locale Enhancement Loom Memory Model Update Metropolis Multi-Language VM Nashorn New I/O OpenJFX Panama Penrose Port: AArch32 Port: AArch64 Port: BSD Port: Haiku Port: Mac OS X Port: MIPS Port: Mobile Port: PowerPC/AIX Port: RISC-V Port: s390x SCTP Shenandoah Skara Sumatra Tsan Valhalla Verona VisualVM Wakefield Zero ZGC &#169; 2025 Oracle Corporation and/or its affiliates Terms of Use &#183; License: GPLv2 &#183; Privacy &#183; Trademarks"
      },
      "fullText": "JEP 509: JFR CPU-Time Profiling (Experimental) JEP 509: JFR CPU-Time Profiling (Experimental) Authors Jaroslav Bachor&#237;k, Johannes Bechberger, &amp; Ron Pressler Owner Johannes Bechberger Type Feature Scope JDK Status Closed&#8201;/&#8201;Delivered Release 25 Component hotspot&#8201;/&#8201;jfr Discussion hotspot dash jfr dash dev at openjdk dot org Effort M Duration S Reviewed by Markus Gr&#246;nlund Endorsed by Vladimir Kozlov Created 2024/08/04 10:34 Updated 2025/07/31 10:19 Issue 8337789 Summary Enhance the JDK Flight Recorder (JFR) to capture more accurate CPU-time profiling information on Linux. This is an experimental feature. Motivation A running program consumes computational resources such as memory, CPU cycles, and elapsed time. To profile a program is to measure the consumption of such resources by specific elements of the program. A profile might indicate that, e.g., one method consumes 20% of a resource, while another method consumes only 0.1%. Profiling can help make a program more efficient, and developers more productive, by identifying which program elements to optimize. Without profiling, we might optimize a method that consumes few resources to begin with, having little impact on the program's overall performance while wasting effort. For example, optimizing a method that takes up 0.1% of the program&#8217;s total execution time to run ten times faster will only reduce the program's execution time by 0.09%. JFR, the JDK Flight Recorder, is the JDK's profiling and monitoring facility. The core of JFR is a low-overhead mechanism for recording events emitted by the JVM or by program code. Some events, such as loading a class, are recorded whenever an action occurs. Others, such as those used for profiling, are recorded by statistically sampling the program's activity as it consumes a resource. The various JFR events can be turned on or off, allowing a more detailed, higher-overhead collection of information during development and a less detailed, lower-overhead collection of information in production. Two important resources that are commonly profiled are heap memory and CPU. A CPU profile shows the relative amount of CPU cycles consumed by different methods. This is not necessarily related to the relative amount of total execution time it consumes. A method that sorts an array, for example, spends all of its time on the CPU. Its execution time corresponds to the number of CPU cycles it consumes. In contrast, a method that reads from a network socket might spend most of its time idly waiting for bytes to arrive over the wire. Of the time it consumes, only a small portion is spent on the CPU. Nevertheless, a CPU profile is important even for server applications that perform a lot of IO, as the throughput of such applications may be bound by CPU usage when under heavy workloads. JFR offers good support for heap allocation profiling, but its support for CPU profiling is lacking. JFR offers an approximation of CPU profiling throu"
    }
  },
  {
    "url": "https://openjdk.org/jeps/520",
    "title": "JEP 520: JFR Method Timing &amp; Tracing",
    "content": {
      "title": "JEP 520: JFR Method Timing &amp; Tracing",
      "summary": "JEP 520: JFR Method Timing &amp; Tracing JEP 520: JFR Method Timing &amp; Tracing Owner Erik Gahlin Type Feature Scope JDK Status Closed&#8201;/&#8201;Delivered Release 25 Component hotspot&#8201;/&#8201;jfr Discussion hotspot dash jfr dash dev at openjdk dot org Effort S Duration S Reviewed by Markus Gr&#246;nlund, Vladimir Kozlov Endorsed by Vladimir Kozlov Created 2024/03/20 14:10 Updated 2025/07/11 19:51 Issue 8328610 Summary Extend the JDK Flight Recorder (JFR) with facilities for method ti",
      "sections": {
        "Summary": "Extend the JDK Flight Recorder (JFR) with facilities for method timing and tracing via bytecode instrumentation .",
        "Goals": "For method invocations, record complete and exact statistics rather than incomplete and inexact sample-based statistics. Allow execution times and stack traces to be recorded for specific methods without requiring source code modifications. Allow methods to be selected via command-line arguments, configuration files, the jcmd tool , and over the network via the Java Management Extensions API (JMX).",
        "Non-Goals": "It is not a goal to record method arguments or the values of non-static fields. It is not a goal to time or trace methods that do not have a bytecode representation, such as abstract, native, or non-static non-default interface methods. It is not a goal to time or trace a large number of methods simultaneously, since that would significantly degrade performance. Use method sampling in such cases. JFR generally aims to impose a CPU overhead of less than one percent. It is not a goal to remain within this constraint when timing and tracing methods.",
        "Motivation": "Timing and tracing method invocations can help to identify performance bottlenecks, optimize code, and find the root causes of bugs. For example, if an application takes an unusually long time to start, tracing static initializers can reveal class loading that could be deferred to a later stage. If a method was changed to fix a performance bug, timing its execution can confirm that the fix was successful. If an application fails because it runs out of database connections, tracing the method that opens connections can suggest how to manage those connections more effectively. During development, we already have good tools for analyzing method execution: The Java Microbenchmark Harness (JMH) can measure method execution times, and debuggers built on top of the Java Debug Interface (JDI) can set breakpoints and inspect call stacks. During",
        "Description": "We introduce two new JFR events, jdk.MethodTiming and jdk.MethodTrace . They both accept a filter to select the methods to time and trace. For example, to see what triggers the resize of a HashMap , you can configure the MethodTrace event's filter when making a recording and then use the jfr tool to display the recorded event: $ java -XX:StartFlightRecording: jdk.MethodTrace#filter=java.util.HashMap::resize ,filename=recording.jfr ... $ jfr print --events jdk.MethodTrace --stack-depth 20 recording.jfr jdk.MethodTrace { startTime = 00:39:26.379 (2025-03-05) duration = 0.00113 ms method = java.util.HashMap.resize() eventThread = \"main\" (javaThreadId = 3) stackTrace = [ java.util.HashMap.putVal(int, Object, Object, boolean, boolean) line: 636 java.util.HashMap.put(Object, Object) line: 619 sun.awt.AppContext.put(Object, Object) line: 598 sun.awt.AppContext.&lt;init&gt;(ThreadGroup) line: 240 sun.awt.SunToolkit.createNewAppContext(ThreadGroup) line: 282 sun.awt.AppContext.initMainAppContex",
        "Alternatives": "JFR could record method arguments and non-static fields when timing or tracing. That would, however, enable it to be used as an attack vector for exfiltrating sensitive information, either programmatically by an unvetted third-party library or through a maliciously crafted configuration file. The filter grammar could allow specific method-name overloads to be specified. That would, however, complicate the syntax since comma-separated parameter names would conflict with the commas that separate JFR options. The filter grammar could accept wildcards, but that could lead to excessive numbers of instrumented methods, bringing the application to a halt. To prevent excessive numbers of instrumented methods, JFR could limit the number of methods that can be instrumented. There are, however, scenarios where that can be acceptable. For example, static initializers are only invoked once, so asking to time or trace all of them is not unreasonable.",
        "Testing": "and production, however, timing and tracing pose challenges. There are several approaches, none fully satisfactory: Add temporary log statements or JFR events to the methods under investigation. This is cumbersome at best, and not feasible for third-party libraries or classes in the JDK. Use sample-based profilers, such as the one built into JFR or third-party tools such as async-profiler . These tools capture stack traces for frequently executed methods, but they fall short of timing and tracing every invocation. Use a Java agent , such as the one employed by the JDK Mission Control tool , to instrument methods to emit JFR events. While this approach works, doing such instrumentation from within the JDK would have performance benefits. For example, the JVM can filter methods, eliminating the need to parse the bytecode of every loaded class twice. Having this feature in the JDK would also simplify usage, since methods could be timed and traced without having to configure or install an ",
        "Risks and Assumptions": "Specifying a filter that includes JDK methods used by the injected instrumentation bytecode can lead to infinite recursion. JFR attempts to avoid this, but its mechanism for doing so is fragile. If you observe such recursion then please submit a bug report; in the mean time, you can avoid the recursion by removing JDK methods from your filter. Installing Contributing Sponsoring Developers' Guide Vulnerabilities JDK GA/EA Builds Mailing lists Wiki &#183; IRC Mastodon Bluesky Bylaws &#183; Census Legal Workshop JEP Process Source code GitHub Mercurial Tools Git jtreg harness Groups (overview) Adoption Build Client Libraries Compatibility &amp;",
        "Specification": "Review Compiler Conformance Core Libraries Governing Board HotSpot IDE Tooling &amp; Support Internationalization JMX Members Networking Porters Quality Security Serviceability Vulnerability Web Projects ( overview , archive ) Amber Babylon CRaC Code Tools Coin Common VM Interface Developers' Guide Device I/O Duke Galahad Graal IcedTea JDK 8 Updates JDK 9 JDK (&#8230;, 24 , 25 , 26 ) JDK Updates JMC Jigsaw Kona Lanai Leyden Lilliput Locale Enhancement Loom Memory Model Update Metropolis Multi-Language VM Nashorn New I/O OpenJFX Panama Penrose Port: AArch32 Port: AArch64 Port: BSD Port: Haiku Port: Mac OS X Port: MIPS Port: Mobile Port: PowerPC/AIX Port: RISC-V Port: s390x SCTP Shenandoah Skara Sumatra Tsan Valhalla Verona VisualVM Wakefield Zero ZGC &#169; 2025 Oracle Corporation and/or its affiliates Terms of Use &#183; License: GPLv2 &#183; Privacy &#183; Trademarks"
      },
      "fullText": "JEP 520: JFR Method Timing &amp; Tracing JEP 520: JFR Method Timing &amp; Tracing Owner Erik Gahlin Type Feature Scope JDK Status Closed&#8201;/&#8201;Delivered Release 25 Component hotspot&#8201;/&#8201;jfr Discussion hotspot dash jfr dash dev at openjdk dot org Effort S Duration S Reviewed by Markus Gr&#246;nlund, Vladimir Kozlov Endorsed by Vladimir Kozlov Created 2024/03/20 14:10 Updated 2025/07/11 19:51 Issue 8328610 Summary Extend the JDK Flight Recorder (JFR) with facilities for method timing and tracing via bytecode instrumentation . Goals For method invocations, record complete and exact statistics rather than incomplete and inexact sample-based statistics. Allow execution times and stack traces to be recorded for specific methods without requiring source code modifications. Allow methods to be selected via command-line arguments, configuration files, the jcmd tool , and over the network via the Java Management Extensions API (JMX). Non-Goals It is not a goal to record method arguments or the values of non-static fields. It is not a goal to time or trace methods that do not have a bytecode representation, such as abstract, native, or non-static non-default interface methods. It is not a goal to time or trace a large number of methods simultaneously, since that would significantly degrade performance. Use method sampling in such cases. JFR generally aims to impose a CPU overhead of less than one percent. It is not a goal to remain within this constraint when timing and tracing methods. Motivation Timing and tracing method invocations can help to identify performance bottlenecks, optimize code, and find the root causes of bugs. For example, if an application takes an unusually long time to start, tracing static initializers can reveal class loading that could be deferred to a later stage. If a method was changed to fix a performance bug, timing its execution can confirm that the fix was successful. If an application fails because it runs out of database connections, tracing the method that opens connections can suggest how to manage those connections more effectively. During development, we already have good tools for analyzing method execution: The Java Microbenchmark Harness (JMH) can measure method execution times, and debuggers built on top of the Java Debug Interface (JDI) can set breakpoints and inspect call stacks. During testing and production, however, timing and tracing pose challenges. There are several approaches, none fully satisfactory: Add temporary log statements or JFR events to the methods under investigation. This is cumbersome at best, and not feasible for third-party libraries or classes in the JDK. Use sample-based profilers, such as the one built into JFR or third-party tools such as async-profiler . These tools capture stack traces for frequently executed methods, but they fall short of timing and tracing every invocation. Use a Java agent , such as the one employed by the JDK Mission Control tool , to instrument me"
    }
  },
  {
    "url": "https://openjdk.org/jeps/521",
    "title": "JEP 521: Generational Shenandoah",
    "content": {
      "title": "JEP 521: Generational Shenandoah",
      "summary": "JEP 521: Generational Shenandoah JEP 521: Generational Shenandoah Owner William Kemper Type Feature Scope JDK Status Closed&#8201;/&#8201;Delivered Release 25 Component hotspot&#8201;/&#8201;gc Discussion hotspot dash gc dash dev at openjdk dot org Relates to JEP 404: Generational Shenandoah (Experimental) Reviewed by Martin Doerr, Roman Kennke, Thomas Stuefe Endorsed by Vladimir Kozlov Created 2025/05/14 17:53 Updated 2025/08/01 18:15 Issue 8356990 Summary Change the generational mode of the Sh",
      "sections": {
        "Summary": "Change the generational mode of the Shenandoah garbage collector from an experimental feature to a product feature.",
        "Goals": "It is not a goal to change the default mode of the Shenandoah collector. By default, Shenandoah will continue to use a single generation.",
        "Non-Goals": "It is not a goal to change the default mode of the Shenandoah collector. By default, Shenandoah will continue to use a single generation.",
        "Motivation": "The generational mode of Shenandoah was integrated as an experimental feature by JEP&#160;404 in JDK&#160;24. Since then, we have implemented many stability and performance improvements. We have tested it extensively on multiple platforms with our own unit tests and with well-known benchmarks and workloads including DaCapo , SPECjbb2015 , SPECjvm2008 , and Heapothesys . Several users have reported success running demanding workloads. It is time to drop the generational mode&#8217;s experimental status.",
        "Description": "In JDK 24, the generational mode of Shenandoah is enabled via the command-line options $ java -XX:+UseShenandoahGC \\ -XX:+UnlockExperimentalVMOptions \\ -XX:ShenandoahGCMode=generational ... The second option, -XX:+UnlockExperimentalVMOptions , will no longer be needed once the generational mode is a product feature. We will not change any other options, or their default values. We do not expect existing users to be impacted by this change. Removing the requirement to specify -XX:+UnlockExperimentalVMOptions does not make its presence on the command line an error, so existing users need not make any changes to continue using the generational mode. Installing Contributing Sponsoring Developers' Guide Vulnerabilities JDK GA/EA Builds Mailing lists Wiki &#183; IRC Mastodon Bluesky Bylaws &#183; Census Legal Workshop JEP Process Source code GitHub Mercurial Tools Git jtreg harness Groups (overview) Adoption Build Client Libraries Compatibility &amp;",
        "Specification": "Review Compiler Conformance Core Libraries Governing Board HotSpot IDE Tooling &amp; Support Internationalization JMX Members Networking Porters Quality Security Serviceability Vulnerability Web Projects ( overview , archive ) Amber Babylon CRaC Code Tools Coin Common VM Interface Developers' Guide Device I/O Duke Galahad Graal IcedTea JDK 8 Updates JDK 9 JDK (&#8230;, 24 , 25 , 26 ) JDK Updates JMC Jigsaw Kona Lanai Leyden Lilliput Locale Enhancement Loom Memory Model Update Metropolis Multi-Language VM Nashorn New I/O OpenJFX Panama Penrose Port: AArch32 Port: AArch64 Port: BSD Port: Haiku Port: Mac OS X Port: MIPS Port: Mobile Port: PowerPC/AIX Port: RISC-V Port: s390x SCTP Shenandoah Skara Sumatra Tsan Valhalla Verona VisualVM Wakefield Zero ZGC &#169; 2025 Oracle Corporation and/or its affiliates Terms of Use &#183; License: GPLv2 &#183; Privacy &#183; Trademarks"
      },
      "fullText": "JEP 521: Generational Shenandoah JEP 521: Generational Shenandoah Owner William Kemper Type Feature Scope JDK Status Closed&#8201;/&#8201;Delivered Release 25 Component hotspot&#8201;/&#8201;gc Discussion hotspot dash gc dash dev at openjdk dot org Relates to JEP 404: Generational Shenandoah (Experimental) Reviewed by Martin Doerr, Roman Kennke, Thomas Stuefe Endorsed by Vladimir Kozlov Created 2025/05/14 17:53 Updated 2025/08/01 18:15 Issue 8356990 Summary Change the generational mode of the Shenandoah garbage collector from an experimental feature to a product feature. Non-Goals It is not a goal to change the default mode of the Shenandoah collector. By default, Shenandoah will continue to use a single generation. Motivation The generational mode of Shenandoah was integrated as an experimental feature by JEP&#160;404 in JDK&#160;24. Since then, we have implemented many stability and performance improvements. We have tested it extensively on multiple platforms with our own unit tests and with well-known benchmarks and workloads including DaCapo , SPECjbb2015 , SPECjvm2008 , and Heapothesys . Several users have reported success running demanding workloads. It is time to drop the generational mode&#8217;s experimental status. Description In JDK 24, the generational mode of Shenandoah is enabled via the command-line options $ java -XX:+UseShenandoahGC \\ -XX:+UnlockExperimentalVMOptions \\ -XX:ShenandoahGCMode=generational ... The second option, -XX:+UnlockExperimentalVMOptions , will no longer be needed once the generational mode is a product feature. We will not change any other options, or their default values. We do not expect existing users to be impacted by this change. Removing the requirement to specify -XX:+UnlockExperimentalVMOptions does not make its presence on the command line an error, so existing users need not make any changes to continue using the generational mode. Installing Contributing Sponsoring Developers' Guide Vulnerabilities JDK GA/EA Builds Mailing lists Wiki &#183; IRC Mastodon Bluesky Bylaws &#183; Census Legal Workshop JEP Process Source code GitHub Mercurial Tools Git jtreg harness Groups (overview) Adoption Build Client Libraries Compatibility &amp; Specification Review Compiler Conformance Core Libraries Governing Board HotSpot IDE Tooling &amp; Support Internationalization JMX Members Networking Porters Quality Security Serviceability Vulnerability Web Projects ( overview , archive ) Amber Babylon CRaC Code Tools Coin Common VM Interface Developers' Guide Device I/O Duke Galahad Graal IcedTea JDK 8 Updates JDK 9 JDK (&#8230;, 24 , 25 , 26 ) JDK Updates JMC Jigsaw Kona Lanai Leyden Lilliput Locale Enhancement Loom Memory Model Update Metropolis Multi-Language VM Nashorn New I/O OpenJFX Panama Penrose Port: AArch32 Port: AArch64 Port: BSD Port: Haiku Port: Mac OS X Port: MIPS Port: Mobile Port: PowerPC/AIX Port: RISC-V Port: s390x SCTP Shenandoah Skara Sumatra Tsan Valhalla Verona VisualVM Wakefield Zero ZGC &#169; 202"
    }
  },
  {
    "url": "https://openjdk.org/jeps/475",
    "title": "JEP 475: Late Barrier Expansion for G1",
    "content": {
      "title": "JEP 475: Late Barrier Expansion for G1",
      "summary": "JEP 475: Late Barrier Expansion for G1 JEP 475: Late Barrier Expansion for G1 Author Roberto Casta&#241;eda Lozano &amp; Erik &#214;sterlund Owner Roberto Castaneda Lozano Type Feature Scope Implementation Status Closed&#8201;/&#8201;Delivered Release 24 Component hotspot&#8201;/&#8201;compiler Discussion hotspot dash gc dash dev at openjdk dot org Effort M Duration M Reviewed by Thomas Schatzl, Vladimir Kozlov Endorsed by Vladimir Kozlov Created 2023/12/18 14:09 Updated 2025/01/28 08:42 Issue 8",
      "sections": {
        "Summary": "Simplify the implementation of the G1 garbage collector's barriers, which record information about application memory accesses, by shifting their expansion from early in the C2 JIT's compilation pipeline to later.",
        "Goals": "Reduce the execution time of C2 when using the G1 collector. Make G1 barriers comprehensible to HotSpot developers who lack a deep understanding of C2. Guarantee that C2 preserves invariants about the relative ordering of memory accesses, safepoints, and barriers. Preserve the quality of C2-generated code, in terms of both speed and size.",
        "Non-Goals": "It is not a goal to retain G1's current early barrier expansion as a legacy mode. The switch to late barrier expansion should be fully transparent, except for the effect of lower C2 overhead, so such a mode is not necessary.",
        "Motivation": "The increasing popularity of cloud-based Java deployments has led to a stronger focus on reducing overall JVM overhead. JIT compilation is an effective technique for speeding up Java applications, but it incurs significant overhead in terms of processing time and memory usage. This overhead is particularly noticeable for optimizing JIT compilers such as the JDK's C2 compiler. Preliminary experiments show that expanding G1 barriers early, as is currently done, increases C2's overhead by around 10-20% depending on the application. This is not surprising, given that a G1 barrier is represented by more than 100 operations in C2&#8217;s intermediate representation (IR) and results in around 50 x64 instructions . Reducing this overhead is key to making the Java Platform a better fit for the cloud. Another major contributor to JVM overhead is the garbage collector. As a semi-concurrent generational garbage collector (GC), G1 interfaces with the JIT compilers to instrument application memory a",
        "Description": "Early barrier expansion Currently, when compiling a method, C2 co-mingles barrier operations together with the method's original operations in its sea-of-nodes IR. C2 expands the barrier operations for each memory access at the beginning of its compilation pipeline, when it parses bytecode into IR operations. Specific logic for G1 and C2 guides this expansion via the Heap Access API ( JEP 304 ). Once the barriers are expanded, C2 transforms and optimizes all operations uniformly through its pipeline. This is depicted in the following diagram, where IR&lt;C,P&gt; denotes an IR that is specific to collector C and target operating-system/processor-architecture platform P: Expanding GC barriers early in the compilation pipeline has two potential advantages: The same GC barrier implementation, expressed as IR operations, can be reused for all platforms, and C2 can optimize and transform the barrier operations across the scope of the entire method, potentially improving code quality. However",
        "Alternatives": "GC barriers can be expanded at several different points of the C2 compilation pipeline: At bytecode parsing (early barrier expansion): GC barriers are expanded when initially constructing the IR. After platform-independent optimizations: GC barriers are expanded after loop transformations, escape analysis, and so forth. After instruction scheduling: GC barriers are expanded after platform-specific instructions are selected and scheduled, but before registers are allocated. (Today, there is no support for expansion at this level.) After register allocation: GC barriers are expanded between register allocation and the final C2 transformations. At code emission (late barrier expansion): GC barriers are expanded when IR instructions are translated into machine code. Each of these points offers a different tradeoff in terms of C2 overhead, required C2 knowledge, risk of suffering instruction scheduling issues, and required platform-specific effort. Generally, the later that barriers are exp",
        "Testing": "To mitigate the risk of introducing functional failures, we will combine Regular",
        "Risks and Assumptions": "As with any change affecting the interaction of core JVM components &#8212; in this case, the G1 garbage collector and the C2 compiler &#8212; there is a non-negligible risk of introducing bugs that may cause failures and introduce performance regressions. To mitigate this risk, we will conduct internal code reviews and do extensive",
        "Specification": "Review Compiler Conformance Core Libraries Governing Board HotSpot IDE Tooling &amp; Support Internationalization JMX Members Networking Porters Quality Security Serviceability Vulnerability Web Projects ( overview , archive ) Amber Babylon CRaC Code Tools Coin Common VM Interface Developers' Guide Device I/O Duke Galahad Graal IcedTea JDK 8 Updates JDK 9 JDK (&#8230;, 24 , 25 , 26 ) JDK Updates JMC Jigsaw Kona Lanai Leyden Lilliput Locale Enhancement Loom Memory Model Update Metropolis Multi-Language VM Nashorn New I/O OpenJFX Panama Penrose Port: AArch32 Port: AArch64 Port: BSD Port: Haiku Port: Mac OS X Port: MIPS Port: Mobile Port: PowerPC/AIX Port: RISC-V Port: s390x SCTP Shenandoah Skara Sumatra Tsan Valhalla Verona VisualVM Wakefield Zero ZGC &#169; 2025 Oracle Corporation and/or its affiliates Terms of Use &#183; License: GPLv2 &#183; Privacy &#183; Trademarks"
      },
      "fullText": "JEP 475: Late Barrier Expansion for G1 JEP 475: Late Barrier Expansion for G1 Author Roberto Casta&#241;eda Lozano &amp; Erik &#214;sterlund Owner Roberto Castaneda Lozano Type Feature Scope Implementation Status Closed&#8201;/&#8201;Delivered Release 24 Component hotspot&#8201;/&#8201;compiler Discussion hotspot dash gc dash dev at openjdk dot org Effort M Duration M Reviewed by Thomas Schatzl, Vladimir Kozlov Endorsed by Vladimir Kozlov Created 2023/12/18 14:09 Updated 2025/01/28 08:42 Issue 8322295 Summary Simplify the implementation of the G1 garbage collector's barriers, which record information about application memory accesses, by shifting their expansion from early in the C2 JIT's compilation pipeline to later. Goals Reduce the execution time of C2 when using the G1 collector. Make G1 barriers comprehensible to HotSpot developers who lack a deep understanding of C2. Guarantee that C2 preserves invariants about the relative ordering of memory accesses, safepoints, and barriers. Preserve the quality of C2-generated code, in terms of both speed and size. Non-Goals It is not a goal to retain G1's current early barrier expansion as a legacy mode. The switch to late barrier expansion should be fully transparent, except for the effect of lower C2 overhead, so such a mode is not necessary. Motivation The increasing popularity of cloud-based Java deployments has led to a stronger focus on reducing overall JVM overhead. JIT compilation is an effective technique for speeding up Java applications, but it incurs significant overhead in terms of processing time and memory usage. This overhead is particularly noticeable for optimizing JIT compilers such as the JDK's C2 compiler. Preliminary experiments show that expanding G1 barriers early, as is currently done, increases C2's overhead by around 10-20% depending on the application. This is not surprising, given that a G1 barrier is represented by more than 100 operations in C2&#8217;s intermediate representation (IR) and results in around 50 x64 instructions . Reducing this overhead is key to making the Java Platform a better fit for the cloud. Another major contributor to JVM overhead is the garbage collector. As a semi-concurrent generational garbage collector (GC), G1 interfaces with the JIT compilers to instrument application memory accesses with barrier code. In the case of C2, maintaining and evolving this interface requires a deep knowledge of C2 internals, which few GC developers possess. Furthermore, some barrier optimizations require applying low-level transformations and techniques which cannot be expressed in C2's intermediate representation. These obstacles have slowed down or directly blocked the evolution and optimization of key aspects of G1. Decoupling G1 barrier instrumentation from C2 internals would enable GC developers to further optimize and reduce the overhead of G1, by means of both algorithmic improvements and low-level micro-optimizations. C2 compiles Java methods to machine co"
    }
  },
  {
    "url": "https://openjdk.org/jeps/423",
    "title": "JEP 423: Region Pinning for G1",
    "content": {
      "title": "JEP 423: Region Pinning for G1",
      "summary": "JEP 423: Region Pinning for G1 JEP 423: Region Pinning for G1 Author Hamlin Li Owner Thomas Schatzl Type Feature Scope Implementation Status Closed&#8201;/&#8201;Delivered Release 22 Component hotspot&#8201;/&#8201;gc Discussion hotspot dash gc dash dev at openjdk dot java dot net Effort L Duration M Reviewed by Thomas Schatzl, Vladimir Kozlov Endorsed by Vladimir Kozlov Created 2021/10/28 08:05 Updated 2024/02/05 16:37 Issue 8276094 Summary Reduce latency by implementing region pinning in G1, s",
      "sections": {
        "Summary": "Reduce latency by implementing region pinning in G1, so that garbage collection need not be disabled during Java Native Interface (JNI) critical regions.",
        "Goals": "No stalling of threads due to JNI critical regions. No additional latency to start a garbage collection due to JNI critical regions. No regressions in GC pause times when no JNI critical regions are active. Minimal regressions in GC pause times when JNI critical regions are active.",
        "Motivation": "For interoperability with unmanaged programming languages such as C and C++, JNI defines functions to get and then release direct pointers to Java objects . These functions must always be used in pairs: First, get a pointer to an object (e.g., via GetPrimitiveArrayCritical ); then, after using the object, release the pointer (e.g., via ReleasePrimitiveArrayCritical ). Code within such function pairs is considered to run in a critical region , and the Java object available for use during that time is a critical object . When a Java thread is in a critical region, the JVM must take care not to move the associated critical object during garbage collection. It can do this by pinning such objects to their locations, essentially locking them in place as the GC moves other objects. Alternatively, it can simply disable GC whenever a thread is in a critical region. The default GC, G1 , takes the latter approach, disabling GC during every critical region. This has a significant impact on latency",
        "Description": "Background G1 partitions the heap into fixed-size memory regions (not to be confused with critical regions). G1 is a generational collector, so any non-empty region is a member of either the young generation or the old generation. In any particular collection operation, objects are evacuated (i.e., moved) from only a subset of the regions to some other subset. If G1 is unable to find space to evacuate an object during a minor (i.e., young-generation) collection then it leaves the object in place and marks both it and its containing region as having failed evacuation . After evacuation, G1 fixes up the failed regions by promoting them from the young generation to the old generation, potentially keeping them ready for subsequent evacuation. G1 is already capable of pinning objects to their memory locations during major (i.e., full) collection operations, simply by not evacuating the regions that contain them. For example, G1 pins humongous regions, which contain large objects. It also pi",
        "Alternatives": "The JNI",
        "Testing": "Aside from functionality tests, we will do benchmarking and performance measurements to collect the performance data necessary to ensure that our",
        "Risks and Assumptions": "We assume that there will be no changes to the expected usage of JNI critical regions: They will continue to be used sparingly, and they will be short in duration. There is a risk of heap exhaustion when an application pins many regions at the same time. We have no solution for this, but the fact that the Shenandoah GC pins memory regions during JNI critical regions and does not have this problem suggests that it will not be a problem for G1. Installing Contributing Sponsoring Developers' Guide Vulnerabilities JDK GA/EA Builds Mailing lists Wiki &#183; IRC Mastodon Bluesky Bylaws &#183; Census Legal Workshop JEP Process Source code GitHub Mercurial Tools Git jtreg harness Groups (overview) Adoption Build Client Libraries Compatibility &amp;",
        "Specification": "suggests two other ways to implement critical regions: At the start of a critical region, copy the critical object to the C heap, where it will not be moved; at the end of the critical region, copy it back. This is very inefficient in both time and space. In G1 we could do this only for critical objects in regions that cannot be pinned. Those regions are in the young generation, however, in which most object use and modification typically occurs, so we do not expect that this would help much. Pin objects individually. G1 can only evacuate whole regions, so a single pinned object in a region would prevent the collection of that region. The end result would be little different from what we propose above except that it would have higher overhead, since tracking individual pinned objects is more costly than maintaining per-region counts of critical objects."
      },
      "fullText": "JEP 423: Region Pinning for G1 JEP 423: Region Pinning for G1 Author Hamlin Li Owner Thomas Schatzl Type Feature Scope Implementation Status Closed&#8201;/&#8201;Delivered Release 22 Component hotspot&#8201;/&#8201;gc Discussion hotspot dash gc dash dev at openjdk dot java dot net Effort L Duration M Reviewed by Thomas Schatzl, Vladimir Kozlov Endorsed by Vladimir Kozlov Created 2021/10/28 08:05 Updated 2024/02/05 16:37 Issue 8276094 Summary Reduce latency by implementing region pinning in G1, so that garbage collection need not be disabled during Java Native Interface (JNI) critical regions. Goals No stalling of threads due to JNI critical regions. No additional latency to start a garbage collection due to JNI critical regions. No regressions in GC pause times when no JNI critical regions are active. Minimal regressions in GC pause times when JNI critical regions are active. Motivation For interoperability with unmanaged programming languages such as C and C++, JNI defines functions to get and then release direct pointers to Java objects . These functions must always be used in pairs: First, get a pointer to an object (e.g., via GetPrimitiveArrayCritical ); then, after using the object, release the pointer (e.g., via ReleasePrimitiveArrayCritical ). Code within such function pairs is considered to run in a critical region , and the Java object available for use during that time is a critical object . When a Java thread is in a critical region, the JVM must take care not to move the associated critical object during garbage collection. It can do this by pinning such objects to their locations, essentially locking them in place as the GC moves other objects. Alternatively, it can simply disable GC whenever a thread is in a critical region. The default GC, G1 , takes the latter approach, disabling GC during every critical region. This has a significant impact on latency: If a Java thread triggers a GC then it must wait until no other threads are in critical regions. The severity of the impact depends upon the frequency and duration of critical regions. In the worst cases users report critical sections blocking their entire application for minutes , unnecessary out-of-memory conditions due to thread starvation , and even premature VM shutdown. Due to these problems, the maintainers of some Java libraries and frameworks have chosen not to use critical regions by default (e.g., JavaCPP ) or even at all (e.g., Netty ), even though doing so can adversely affect throughput. With the change that we propose here, Java threads will never wait for a G1 GC operation to complete. Description Background G1 partitions the heap into fixed-size memory regions (not to be confused with critical regions). G1 is a generational collector, so any non-empty region is a member of either the young generation or the old generation. In any particular collection operation, objects are evacuated (i.e., moved) from only a subset of the regions to some other subset. If G1 is una"
    }
  },
  {
    "url": "https://openjdk.org/jeps/474",
    "title": "JEP 474: ZGC: Generational Mode by Default",
    "content": {
      "title": "JEP 474: ZGC: Generational Mode by Default",
      "summary": "JEP 474: ZGC: Generational Mode by Default JEP 474: ZGC: Generational Mode by Default Owner Axel Boldt-Christmas Type Feature Scope JDK Status Closed&#8201;/&#8201;Delivered Release 23 Component hotspot&#8201;/&#8201;gc Discussion hotspot dash gc dash dev at openjdk dot org Effort XS Relates to JEP 439: Generational ZGC JEP 490: ZGC: Remove the Non-Generational Mode Reviewed by Stefan Karlsson, Vladimir Kozlov Endorsed by Vladimir Kozlov Created 2024/02/26 11:16 Updated 2024/10/07 17:28 Issue 83",
      "sections": {
        "Summary": "Switch the default mode of the Z Garbage Collector (ZGC) to the generational mode. Deprecate the non-generational mode, with the intent to remove it in a future release.",
        "Goals": "Signal the intent that future development will focus on Generational ZGC. Reduce the maintenance cost of supporting two different modes.",
        "Non-Goals": "It is not a goal to remove non-generational ZGC from the targeted release.",
        "Motivation": "Maintaining non-generational ZGC slows the development of new features. As stated in JEP 439: Generational ZGC : Generational ZGC should be a better solution for most use cases than non-generational ZGC. We should eventually be able to replace the latter with the former in order to reduce long-term maintenance costs.",
        "Description": "Make Generational ZGC the default mode of ZGC by changing the default value of the ZGenerational option from false to true . Deprecate the non-generational mode by deprecating the ZGenerational option. After these changes the following behavior will be observed based on the provided command-line arguments: -XX:+UseZGC Generational ZGC is used. -XX:+UseZGC -XX:+ZGenerational Generational ZGC is used. A warning that the ZGenerational option is deprecated is issued. -XX:+UseZGC -XX:-ZGenerational Non-generational ZGC is used. A warning that the ZGenerational option is deprecated is issued. A warning that the non-generational mode is deprecated for removal is issued. Workloads that switch to Generational ZGC may experience differences in log output and in the data available from the serviceability and management APIs.",
        "Testing": "We will ensure that existing tests are unaffected by the deprecated option warning and that they pass in the same configurations as before this change.",
        "Risks and Assumptions": "This JEP shares its Risk and Assumptions with JEP 439: Generational ZGC . Generational ZGC will perform differently than non-generational ZGC. The main risk this presents is that some workloads are non-generational by nature, and thus could see a slight performance degradation. We believe that this is a sufficiently small set of workloads that it does not justify the cost of maintaining two separate versions of ZGC over the long term. Specific risks include: Users may be required to adjust configurations that are tuned for non-generational ZGC. The deprecation warning messages might cause issues. Workloads that are tightly coupled to JVM internals, GC logs, and the data available via management interfaces may require extra attention. Installing Contributing Sponsoring Developers' Guide Vulnerabilities JDK GA/EA Builds Mailing lists Wiki &#183; IRC Mastodon Bluesky Bylaws &#183; Census Legal Workshop JEP Process Source code GitHub Mercurial Tools Git jtreg harness Groups (overview) Adop",
        "Specification": "Review Compiler Conformance Core Libraries Governing Board HotSpot IDE Tooling &amp; Support Internationalization JMX Members Networking Porters Quality Security Serviceability Vulnerability Web Projects ( overview , archive ) Amber Babylon CRaC Code Tools Coin Common VM Interface Developers' Guide Device I/O Duke Galahad Graal IcedTea JDK 8 Updates JDK 9 JDK (&#8230;, 24 , 25 , 26 ) JDK Updates JMC Jigsaw Kona Lanai Leyden Lilliput Locale Enhancement Loom Memory Model Update Metropolis Multi-Language VM Nashorn New I/O OpenJFX Panama Penrose Port: AArch32 Port: AArch64 Port: BSD Port: Haiku Port: Mac OS X Port: MIPS Port: Mobile Port: PowerPC/AIX Port: RISC-V Port: s390x SCTP Shenandoah Skara Sumatra Tsan Valhalla Verona VisualVM Wakefield Zero ZGC &#169; 2025 Oracle Corporation and/or its affiliates Terms of Use &#183; License: GPLv2 &#183; Privacy &#183; Trademarks"
      },
      "fullText": "JEP 474: ZGC: Generational Mode by Default JEP 474: ZGC: Generational Mode by Default Owner Axel Boldt-Christmas Type Feature Scope JDK Status Closed&#8201;/&#8201;Delivered Release 23 Component hotspot&#8201;/&#8201;gc Discussion hotspot dash gc dash dev at openjdk dot org Effort XS Relates to JEP 439: Generational ZGC JEP 490: ZGC: Remove the Non-Generational Mode Reviewed by Stefan Karlsson, Vladimir Kozlov Endorsed by Vladimir Kozlov Created 2024/02/26 11:16 Updated 2024/10/07 17:28 Issue 8326667 Summary Switch the default mode of the Z Garbage Collector (ZGC) to the generational mode. Deprecate the non-generational mode, with the intent to remove it in a future release. Goals Signal the intent that future development will focus on Generational ZGC. Reduce the maintenance cost of supporting two different modes. Non-Goals It is not a goal to remove non-generational ZGC from the targeted release. Motivation Maintaining non-generational ZGC slows the development of new features. As stated in JEP 439: Generational ZGC : Generational ZGC should be a better solution for most use cases than non-generational ZGC. We should eventually be able to replace the latter with the former in order to reduce long-term maintenance costs. Description Make Generational ZGC the default mode of ZGC by changing the default value of the ZGenerational option from false to true . Deprecate the non-generational mode by deprecating the ZGenerational option. After these changes the following behavior will be observed based on the provided command-line arguments: -XX:+UseZGC Generational ZGC is used. -XX:+UseZGC -XX:+ZGenerational Generational ZGC is used. A warning that the ZGenerational option is deprecated is issued. -XX:+UseZGC -XX:-ZGenerational Non-generational ZGC is used. A warning that the ZGenerational option is deprecated is issued. A warning that the non-generational mode is deprecated for removal is issued. Workloads that switch to Generational ZGC may experience differences in log output and in the data available from the serviceability and management APIs. Testing We will ensure that existing tests are unaffected by the deprecated option warning and that they pass in the same configurations as before this change. Risks and Assumptions This JEP shares its Risk and Assumptions with JEP 439: Generational ZGC . Generational ZGC will perform differently than non-generational ZGC. The main risk this presents is that some workloads are non-generational by nature, and thus could see a slight performance degradation. We believe that this is a sufficiently small set of workloads that it does not justify the cost of maintaining two separate versions of ZGC over the long term. Specific risks include: Users may be required to adjust configurations that are tuned for non-generational ZGC. The deprecation warning messages might cause issues. Workloads that are tightly coupled to JVM internals, GC logs, and the data available via management interfaces may require extra atten"
    }
  },
  {
    "url": "https://openjdk.org/jeps/490",
    "title": "JEP 490: ZGC: Remove the Non-Generational Mode",
    "content": {
      "title": "JEP 490: ZGC: Remove the Non-Generational Mode",
      "summary": "JEP 490: ZGC: Remove the Non-Generational Mode JEP 490: ZGC: Remove the Non-Generational Mode Owner Axel Boldt-Christmas Type Feature Scope JDK Status Closed&#8201;/&#8201;Delivered Release 24 Component hotspot&#8201;/&#8201;gc Discussion hotspot dash gc dash dev at openjdk dot org Effort XS Duration XS Relates to JEP 439: Generational ZGC JEP 474: ZGC: Generational Mode by Default Reviewed by Stefan Karlsson, Vladimir Kozlov Endorsed by Vladimir Kozlov Created 2024/07/08 08:41 Updated 2025/02/1",
      "sections": {
        "Summary": "Remove the non-generational mode of the Z Garbage Collector (ZGC), keeping the generational mode as the default for ZGC. Goal Reduce the maintenance cost of supporting two different modes.",
        "Motivation": "Maintaining non-generational ZGC slows the development of new features. As stated in JEP 439: Generational ZGC : Generational ZGC should be a better solution for most use cases than non-generational ZGC. We should eventually be able to replace the latter with the former in order to reduce long-term maintenance costs.",
        "Description": "Remove the non-generational mode by obsoleting the ZGenerational option and removing the non-generational ZGC code and its tests. The option will expire in a future release, at which point it will not be recognized by the HotSpot JVM, which will refuse to start. After these changes, the relevant command-line options will work as follows: -XX:+UseZGC Generational ZGC is used. -XX:+UseZGC -XX:+ZGenerational Generational ZGC is used. An obsolete-option warning is printed. -XX:+UseZGC -XX:-ZGenerational Generational ZGC is used. An obsolete-option warning is printed. Workloads that switch to Generational ZGC may experience differences in log output and in the data available from the serviceability and management APIs.",
        "Risks and Assumptions": "This JEP shares its Risk and Assumptions with JEP 439: Generational ZGC and JEP 474: ZGC: Generational Mode by Default . Generational ZGC will perform differently than non-generational ZGC. The main risk this presents is that some workloads are non-generational by nature, and thus could see a slight performance degradation. We believe that this is a sufficiently small set of workloads that it does not justify the cost of maintaining two separate modes of ZGC over the long term. Specific risks include: Users may be required to adjust configurations that are tuned for non-generational ZGC. The obsolete-option warning messages might cause issues. Workloads that are tightly coupled to JVM internals, GC logs, and the data available via management interfaces may require extra attention. Installing Contributing Sponsoring Developers' Guide Vulnerabilities JDK GA/EA Builds Mailing lists Wiki &#183; IRC Mastodon Bluesky Bylaws &#183; Census Legal Workshop JEP Process Source code GitHub Mercuria",
        "Specification": "Review Compiler Conformance Core Libraries Governing Board HotSpot IDE Tooling &amp; Support Internationalization JMX Members Networking Porters Quality Security Serviceability Vulnerability Web Projects ( overview , archive ) Amber Babylon CRaC Code Tools Coin Common VM Interface Developers' Guide Device I/O Duke Galahad Graal IcedTea JDK 8 Updates JDK 9 JDK (&#8230;, 24 , 25 , 26 ) JDK Updates JMC Jigsaw Kona Lanai Leyden Lilliput Locale Enhancement Loom Memory Model Update Metropolis Multi-Language VM Nashorn New I/O OpenJFX Panama Penrose Port: AArch32 Port: AArch64 Port: BSD Port: Haiku Port: Mac OS X Port: MIPS Port: Mobile Port: PowerPC/AIX Port: RISC-V Port: s390x SCTP Shenandoah Skara Sumatra Tsan Valhalla Verona VisualVM Wakefield Zero ZGC &#169; 2025 Oracle Corporation and/or its affiliates Terms of Use &#183; License: GPLv2 &#183; Privacy &#183; Trademarks"
      },
      "fullText": "JEP 490: ZGC: Remove the Non-Generational Mode JEP 490: ZGC: Remove the Non-Generational Mode Owner Axel Boldt-Christmas Type Feature Scope JDK Status Closed&#8201;/&#8201;Delivered Release 24 Component hotspot&#8201;/&#8201;gc Discussion hotspot dash gc dash dev at openjdk dot org Effort XS Duration XS Relates to JEP 439: Generational ZGC JEP 474: ZGC: Generational Mode by Default Reviewed by Stefan Karlsson, Vladimir Kozlov Endorsed by Vladimir Kozlov Created 2024/07/08 08:41 Updated 2025/02/14 20:13 Issue 8335850 Summary Remove the non-generational mode of the Z Garbage Collector (ZGC), keeping the generational mode as the default for ZGC. Goal Reduce the maintenance cost of supporting two different modes. Motivation Maintaining non-generational ZGC slows the development of new features. As stated in JEP 439: Generational ZGC : Generational ZGC should be a better solution for most use cases than non-generational ZGC. We should eventually be able to replace the latter with the former in order to reduce long-term maintenance costs. Description Remove the non-generational mode by obsoleting the ZGenerational option and removing the non-generational ZGC code and its tests. The option will expire in a future release, at which point it will not be recognized by the HotSpot JVM, which will refuse to start. After these changes, the relevant command-line options will work as follows: -XX:+UseZGC Generational ZGC is used. -XX:+UseZGC -XX:+ZGenerational Generational ZGC is used. An obsolete-option warning is printed. -XX:+UseZGC -XX:-ZGenerational Generational ZGC is used. An obsolete-option warning is printed. Workloads that switch to Generational ZGC may experience differences in log output and in the data available from the serviceability and management APIs. Risks and Assumptions This JEP shares its Risk and Assumptions with JEP 439: Generational ZGC and JEP 474: ZGC: Generational Mode by Default . Generational ZGC will perform differently than non-generational ZGC. The main risk this presents is that some workloads are non-generational by nature, and thus could see a slight performance degradation. We believe that this is a sufficiently small set of workloads that it does not justify the cost of maintaining two separate modes of ZGC over the long term. Specific risks include: Users may be required to adjust configurations that are tuned for non-generational ZGC. The obsolete-option warning messages might cause issues. Workloads that are tightly coupled to JVM internals, GC logs, and the data available via management interfaces may require extra attention. Installing Contributing Sponsoring Developers' Guide Vulnerabilities JDK GA/EA Builds Mailing lists Wiki &#183; IRC Mastodon Bluesky Bylaws &#183; Census Legal Workshop JEP Process Source code GitHub Mercurial Tools Git jtreg harness Groups (overview) Adoption Build Client Libraries Compatibility &amp; Specification Review Compiler Conformance Core Libraries Governing Board HotSpot IDE Tooling &amp"
    }
  },
  {
    "url": "https://openjdk.org/jeps/515",
    "title": "JEP 515: Ahead-of-Time Method Profiling",
    "content": {
      "title": "JEP 515: Ahead-of-Time Method Profiling",
      "summary": "JEP 515: Ahead-of-Time Method Profiling JEP 515: Ahead-of-Time Method Profiling Author Igor Veresov &amp; John Rose Owner John Rose Type Feature Scope Implementation Status Closed&#8201;/&#8201;Delivered Release 25 Component hotspot&#8201;/&#8201;compiler Discussion leyden dash dev at openjdk dot org Effort M Duration M Relates to JEP 483: Ahead-of-Time Class Loading &amp; Linking Reviewed by Alex Buckley, Dan Heidinga, Vladimir Kozlov Endorsed by Vladimir Kozlov Created 2024/02/01 20:40 Updated",
      "sections": {
        "Summary": "Improve warmup time by making method-execution profiles from a previous run of an application instantly available, when the HotSpot Java Virtual Machine starts. This will enable the JIT compiler to generate native code immediately upon application startup, rather than having to wait for profiles to be collected.",
        "Goals": "Help applications warm up more quickly by shifting the collection of initial method execution profiles from production runs to training runs, conveying the profiles via the AOT cache . Do not require any change to the code of applications, libraries, or frameworks. Do not introduce any new constraints on application execution. Do not introduce new AOT workflows, but, rather, use the existing AOT cache creation commands .",
        "Motivation": "To truly know what an application does, we must run it. We can draw simple conclusions about an application's behavior by inspecting its source code or its class files, but we will be uncertain about how it interacts with the highly dynamic Java Platform. One reason for this uncertainty is that, in the absence of final or sealed modifiers, any class can be subclassed at any time, so a method can be called many times and then overridden and never called again. Another reason is that new classes can be loaded in response to external input, extending the application's behavior in ways that even its author could not predict. Static analysis can always be defeated by program complexity. When running an application, the JVM can identify which methods do the important work, and how they do it. For an application to reach peak performance, the JVM's just-in-time compiler (JIT) must find the unpredictable set of hot methods, i.e., those which consume the most CPU time, and compile their bytecod",
        "Description": "We extend the AOT cache, introduced by JEP 483 , to collect method profiles during training runs. Just as the AOT cache currently stores classes that the JVM would otherwise need to load and link at startup, the AOT cache now also stores method profiles that the JVM would otherwise need to collect in the early part of an application's run. Accordingly, production runs of the application are both faster to start and faster to achieve peak performance. Profiles cached during training runs do not prevent additional profiling during production runs. This is critical, since an application's behavior in production can diverge from what was observed in training. Even with cached profiles, the HotSpot JVM continues to profile and optimize the application as it runs, fusing the benefits of AOT profiles, on-line profiling, and JIT compilation. The net effect of cached profiles is that the JIT runs earlier and with more accuracy, using the profiles to optimize the hot methods so that the applicat",
        "Alternatives": "If an application is so predictable that we can compile its hot methods to native code ahead of time, and doing so enables it to reach peak performance without further JIT activity, then such AOT code is preferable to caching profiles. We intend to implement AOT compilation in future work. Many applications, however, benefit from a mix of AOT compilation and JIT compilation, since their behavior cannot be accurately predicted by an AOT compiler. Cached profiles and cached AOT code are thus not mutually antagonistic, and will synergize to provide the best performance for a range of applications. A partial AOT solution, where reasonable AOT code is gradually replaced by better-optimized JIT code, seems likely to be the best solution in the end. The JIT can initially stay out of the application's way, taking its time to get the final code just right, based on the latest profiling information.",
        "Testing": "We will create new unit tests for this feature. We will run existing AOT cache tests with this feature enabled, and ensure that they pass.",
        "Risks and Assumptions": "There are no new risks beyond those already noted in JEP 483 . The base assumption of the AOT cache remains operative: A training run is assumed to be a good source of observations that, when passed through an AOT cache to a production run, will benefit the performance of that production run. Installing Contributing Sponsoring Developers' Guide Vulnerabilities JDK GA/EA Builds Mailing lists Wiki &#183; IRC Mastodon Bluesky Bylaws &#183; Census Legal Workshop JEP Process Source code GitHub Mercurial Tools Git jtreg harness Groups (overview) Adoption Build Client Libraries Compatibility &amp;",
        "Specification": "Review Compiler Conformance Core Libraries Governing Board HotSpot IDE Tooling &amp; Support Internationalization JMX Members Networking Porters Quality Security Serviceability Vulnerability Web Projects ( overview , archive ) Amber Babylon CRaC Code Tools Coin Common VM Interface Developers' Guide Device I/O Duke Galahad Graal IcedTea JDK 8 Updates JDK 9 JDK (&#8230;, 24 , 25 , 26 ) JDK Updates JMC Jigsaw Kona Lanai Leyden Lilliput Locale Enhancement Loom Memory Model Update Metropolis Multi-Language VM Nashorn New I/O OpenJFX Panama Penrose Port: AArch32 Port: AArch64 Port: BSD Port: Haiku Port: Mac OS X Port: MIPS Port: Mobile Port: PowerPC/AIX Port: RISC-V Port: s390x SCTP Shenandoah Skara Sumatra Tsan Valhalla Verona VisualVM Wakefield Zero ZGC &#169; 2025 Oracle Corporation and/or its affiliates Terms of Use &#183; License: GPLv2 &#183; Privacy &#183; Trademarks"
      },
      "fullText": "JEP 515: Ahead-of-Time Method Profiling JEP 515: Ahead-of-Time Method Profiling Author Igor Veresov &amp; John Rose Owner John Rose Type Feature Scope Implementation Status Closed&#8201;/&#8201;Delivered Release 25 Component hotspot&#8201;/&#8201;compiler Discussion leyden dash dev at openjdk dot org Effort M Duration M Relates to JEP 483: Ahead-of-Time Class Loading &amp; Linking Reviewed by Alex Buckley, Dan Heidinga, Vladimir Kozlov Endorsed by Vladimir Kozlov Created 2024/02/01 20:40 Updated 2025/07/17 19:01 Issue 8325147 Summary Improve warmup time by making method-execution profiles from a previous run of an application instantly available, when the HotSpot Java Virtual Machine starts. This will enable the JIT compiler to generate native code immediately upon application startup, rather than having to wait for profiles to be collected. Goals Help applications warm up more quickly by shifting the collection of initial method execution profiles from production runs to training runs, conveying the profiles via the AOT cache . Do not require any change to the code of applications, libraries, or frameworks. Do not introduce any new constraints on application execution. Do not introduce new AOT workflows, but, rather, use the existing AOT cache creation commands . Motivation To truly know what an application does, we must run it. We can draw simple conclusions about an application's behavior by inspecting its source code or its class files, but we will be uncertain about how it interacts with the highly dynamic Java Platform. One reason for this uncertainty is that, in the absence of final or sealed modifiers, any class can be subclassed at any time, so a method can be called many times and then overridden and never called again. Another reason is that new classes can be loaded in response to external input, extending the application's behavior in ways that even its author could not predict. Static analysis can always be defeated by program complexity. When running an application, the JVM can identify which methods do the important work, and how they do it. For an application to reach peak performance, the JVM's just-in-time compiler (JIT) must find the unpredictable set of hot methods, i.e., those which consume the most CPU time, and compile their bytecode to native code. (Hence the name \"HotSpot JVM\".) Since previous application behavior is an excellent predictor of future behavior, a summary of previous behavior can focus the JVM's compilation efforts upon the code that really matters. Since JDK 1.2, the HotSpot JVM has automatically collected this summary in the form of profiles . For any given method, a profile tallies many useful events, e.g., how many times its bytecode instructions are executed and which object types are encountered. With enough profile data, the JVM has a statistical basis to predict the method's future behavior, and thus to generate optimized code for that method. Profiles allow the JVM to both optimize hot methods and "
    }
  },
  {
    "url": "https://openjdk.org/jeps/483",
    "title": "JEP 483: Ahead-of-Time Class Loading &amp; Linking",
    "content": {
      "title": "JEP 483: Ahead-of-Time Class Loading &amp; Linking",
      "summary": "JEP 483: Ahead-of-Time Class Loading &amp; Linking JEP 483: Ahead-of-Time Class Loading &amp; Linking Authors Ioi Lam, Dan Heidinga, &amp; John Rose Owner Ioi Lam Type Feature Scope JDK Status Closed&#8201;/&#8201;Delivered Release 24 Component hotspot&#8201;/&#8201;runtime Discussion leyden dash dev at openjdk dot org Relates to JEP 515: Ahead-of-Time Method Profiling JEP 514: Ahead-of-Time Command-Line Ergonomics Reviewed by Alex Buckley, Brian Goetz, Mark Reinhold, Vladimir Kozlov Endorsed by",
      "sections": {
        "Summary": "Improve startup time by making the classes of an application instantly available, in a loaded and linked state, when the HotSpot Java Virtual Machine starts. Achieve this by monitoring the application during one run and storing the loaded and linked forms of all classes in a cache for use in subsequent runs. Lay a foundation for future improvements to both startup and warmup time.",
        "Goals": "Improve startup time by exploiting the fact that most applications start up in roughly the same way every time they run. Do not require any change to the code of applications, libraries, or frameworks. Do not require any change to how applications are started from the command line with the java launcher, beyond the command-line options related directly to this feature. Do not require the use of the jlink or jpackage tools. Lay a foundation for continued improvements to startup time and also to warmup time, i.e., the time required for the HotSpot JVM to optimize an application&#8217;s code for peak performance.",
        "Non-Goals": "It is not a goal to cache classes that are loaded by user-defined class loaders. Only classes loaded from the class path, the module path, and the JDK itself, by the JDK&#8217;s built-in class loaders , can be cached. We may address this limitation in future work.",
        "Motivation": "The Java Platform is highly dynamic. This is a source of great strength. Features such as dynamic class loading, dynamic linkage, dynamic dispatch, and dynamic reflection give vast expressive power to developers. They can create frameworks which use reflection to determine an application&#8217;s configuration by inspecting application code for annotations. They can write libraries which dynamically load and then link to plug-in components discovered at run time. They can, finally, assemble applications by composing libraries which dynamically link to other libraries, leveraging the rich Java ecosystem. Features such as dynamic compilation, dynamic deoptimization, and dynamic storage reclamation give broad flexibility to the JVM. It can compile a method from bytecode to native code when it detects, by observing an application&#8217;s behavior, that doing so will be worthwhile. It can speculatively optimize native code, assuming a particular frequent path of execution, and revert to inte",
        "Description": "We extend the HotSpot JVM to support an ahead-of-time cache which can store classes after reading, parsing, loading, and linking them. Once a cache is created for a specific application, it can be re-used in subsequent runs of that application to improve startup time. To create a cache takes two steps. First, run the application once, in a training run , to record its AOT configuration, in this case into the file app.aotconf : $ java -XX:AOTMode=record -XX:AOTConfiguration=app.aotconf \\ -cp app.jar com.example.App ... Second, use the configuration to create the cache, in the file app.aot : $ java -XX:AOTMode=create -XX:AOTConfiguration=app.aotconf \\ -XX:AOTCache=app.aot -cp app.jar (This second step doesn&#8217;t run the application, it just creates the cache. We intend to streamline the process of cache creation in future work.) Subsequently, in",
        "Testing": "or production, run the application with the cache: $ java -XX:AOTCache=app.aot -cp app.jar com.example.App ... (If the cache file is unusable or does not exist then the JVM issues a warning message and continues.) Note that the format of the configuration and cache files is not specified and is subject to change without notice. With the AOT cache, the reading, parsing, loading, and linking work that the JVM would usually do just-in-time when the program runs in the third step is shifted ahead-of-time to the second step, which creates the cache. Subsequently, the program starts up faster in the third step because its classes are available instantly from the cache. For example, here is a program which, though short, uses the Stream API and thus causes almost 600 JDK classes to be read, parsed, loaded, and linked: import java.util.*; import java.util.stream.*; public class HelloStream { public static void main(String ... args) { var words = List.of(\"hello\", \"fuzzy\", \"world\"); var greeting",
        "Risks and Assumptions": "We assume that the consistency required across training and subsequent runs is tolerable to developers who want to use this feature. They must, especially, ensure that class paths and module configurations are consistent in all runs. We assume that the limited support for user-defined class loaders is tolerable. Conversations with some potential users suggest that they are willing to accept fixed class paths and module configurations, and thus a fixed set of built-in class loaders, and to use specialized class loaders only when that flexibility is required. We assume that the low-level side effects of ahead-of-time loading and linking are immaterial in practice. These include the timing of filesystem accesses, log messages, JDK-internal bookkeeping activities, and changes in CPU and memory usage. Applications that observe and depend on such subtle effects may become unstable if classes are loaded and linked ahead-of-time. We assume that such applications are rare, and that they can be ",
        "Specification": "s give the JVM broad freedom in scheduling these operations. When we shift these operations from just-in-time to ahead-of-time, the application observes classes being loaded and linked as if the JVM did that work at the exact moment requested &#8212; though unaccountably fast. Future work The two-step workflow proposed here is cumbersome. In the near future we expect to reduce this to one step which both performs the training run and creates the AOT cache. At present, the only way to do a training run is to have the application run a representative workload, at least through startup, and then exit. In future work we may create new tools to help developers more flexibly define and evaluate such training runs and workloads, and perhaps also allow them to manually adjust what is stored in AOT caches. We may also enable training data to be gathered unobtrusively during production runs. ZGC is not yet supported. We intend to address this limitation in future work . In some cases the JVM can"
      },
      "fullText": "JEP 483: Ahead-of-Time Class Loading &amp; Linking JEP 483: Ahead-of-Time Class Loading &amp; Linking Authors Ioi Lam, Dan Heidinga, &amp; John Rose Owner Ioi Lam Type Feature Scope JDK Status Closed&#8201;/&#8201;Delivered Release 24 Component hotspot&#8201;/&#8201;runtime Discussion leyden dash dev at openjdk dot org Relates to JEP 515: Ahead-of-Time Method Profiling JEP 514: Ahead-of-Time Command-Line Ergonomics Reviewed by Alex Buckley, Brian Goetz, Mark Reinhold, Vladimir Kozlov Endorsed by Vladimir Kozlov Created 2023/09/06 04:07 Updated 2025/05/30 16:06 Issue 8315737 Summary Improve startup time by making the classes of an application instantly available, in a loaded and linked state, when the HotSpot Java Virtual Machine starts. Achieve this by monitoring the application during one run and storing the loaded and linked forms of all classes in a cache for use in subsequent runs. Lay a foundation for future improvements to both startup and warmup time. Goals Improve startup time by exploiting the fact that most applications start up in roughly the same way every time they run. Do not require any change to the code of applications, libraries, or frameworks. Do not require any change to how applications are started from the command line with the java launcher, beyond the command-line options related directly to this feature. Do not require the use of the jlink or jpackage tools. Lay a foundation for continued improvements to startup time and also to warmup time, i.e., the time required for the HotSpot JVM to optimize an application&#8217;s code for peak performance. Non-Goals It is not a goal to cache classes that are loaded by user-defined class loaders. Only classes loaded from the class path, the module path, and the JDK itself, by the JDK&#8217;s built-in class loaders , can be cached. We may address this limitation in future work. Motivation The Java Platform is highly dynamic. This is a source of great strength. Features such as dynamic class loading, dynamic linkage, dynamic dispatch, and dynamic reflection give vast expressive power to developers. They can create frameworks which use reflection to determine an application&#8217;s configuration by inspecting application code for annotations. They can write libraries which dynamically load and then link to plug-in components discovered at run time. They can, finally, assemble applications by composing libraries which dynamically link to other libraries, leveraging the rich Java ecosystem. Features such as dynamic compilation, dynamic deoptimization, and dynamic storage reclamation give broad flexibility to the JVM. It can compile a method from bytecode to native code when it detects, by observing an application&#8217;s behavior, that doing so will be worthwhile. It can speculatively optimize native code, assuming a particular frequent path of execution, and revert to interpreting bytecode when it observes that the assumption no longer holds. It can reclaim storage when it observes that "
    }
  },
  {
    "url": "https://openjdk.org/jeps/514",
    "title": "JEP 514: Ahead-of-Time Command-Line Ergonomics",
    "content": {
      "title": "JEP 514: Ahead-of-Time Command-Line Ergonomics",
      "summary": "JEP 514: Ahead-of-Time Command-Line Ergonomics JEP 514: Ahead-of-Time Command-Line Ergonomics Owner John Rose Type Feature Scope JDK Status Closed&#8201;/&#8201;Delivered Release 25 Component hotspot&#8201;/&#8201;runtime Discussion leyden dash dev at openjdk dot org Effort M Duration S Relates to JEP 483: Ahead-of-Time Class Loading &amp; Linking Reviewed by Alex Buckley, Vladimir Kozlov Endorsed by Vladimir Kozlov Created 2025/02/13 18:07 Updated 2025/06/06 19:25 Issue 8350022 Summary Make it ",
      "sections": {
        "Summary": "Make it easier to create ahead-of-time caches , which accelerate the startup of Java applications, by simplifying the commands required for common use cases.",
        "Goals": "Simplify the process of creating an ahead-of-time (AOT) cache, with no loss of expressiveness. Do not introduce fundamentally new AOT workflows, but rather make it easier to access existing ones.",
        "Non-Goals": "It is not a goal to introduce new AOT optimizations; rather, we aim to simplify access to all AOT optimizations, both present and future.",
        "Motivation": "Ahead-of-time caches, introduced by JEP 483 , accelerate the startup of Java applications. Their benefits are expected to grow as Project Leyden brings new AOT-related optimizations to the HotSpot JVM. With JDK 24, you create an AOT cache in two steps, invoking the java launcher in two distinct AOT modes . The first invocation specifies record mode, directing the JVM to observe the dynamics of a training run of your application and record them into an AOT configuration . The second invocation specifies create mode, directing the JVM to create an AOT cache based on the configuration recorded during the training run. Here is an example of this two-step workflow, taken from JEP 483 : $ java -XX:AOTMode=record -XX:AOTConfiguration=app.aotconf \\ -cp app.jar com.example.App ... $ java -XX:AOTMode=create -XX:AOTConfiguration=app.aotconf \\ -XX:AOTCache=app.aot Subsequently, you run your application specifying just the AOT cache: $ java -XX:AOTCache=app.aot -cp app.jar com.example.App ... This ",
        "Description": "We extend the java launcher with a new command-line option, AOTCacheOutput , that specifies an AOT cache output file. When used alone, with no other AOT options, this option causes the launcher to, in effect, split its invocation into two sub-invocations: The first does a training run ( AOTMode=record ) and then the second creates the AOT cache ( AOTMode=create ). For example, the two-step workflow shown earlier can be replaced by the single step: $ java -XX:AOTCacheOutput=app.aot -cp app.jar com.example.App ... As a convenience, when operating in this way the JVM creates a temporary file for the AOT configuration and deletes the file when finished. A production run that uses the AOT cache is started the same way as before: $ java -XX:AOTCache=app.aot -cp app.jar com.example.App ... A new environment variable, JDK_AOT_VM_OPTIONS , can be used to pass command-line options that apply specifically to cache creation ( AOTMode=create ), without affecting the training run ( AOTMode=record ).",
        "Alternatives": "We considered a combined AOT mode, AOTMode=record+create . That could work today, but in the future we may extend training runs to read an existing AOT cache. At that point, the option -XX:AOTCache=myapp.aot would become ambiguous, and we would likely wind up introducing the AOTCacheOutput option anyway. Installing Contributing Sponsoring Developers' Guide Vulnerabilities JDK GA/EA Builds Mailing lists Wiki &#183; IRC Mastodon Bluesky Bylaws &#183; Census Legal Workshop JEP Process Source code GitHub Mercurial Tools Git jtreg harness Groups (overview) Adoption Build Client Libraries Compatibility &amp;",
        "Specification": "of these options is available here . Manually orchestrating training and cache creation There are still use cases where it may be preferable to use two steps to create an AOT cache, specifying the AOT mode explicitly each time. For example, if you intend to deploy an application to small instances in a cloud then you could do the training run on a small instance but create the AOT cache on a large instance. That way the training run reflects the deployment environment, but the creation of the AOT cache can leverage the additional CPU cores and memory of the large instance. Such a division of labor may become more important as Leyden AOT optimizations become more complex. For example, some future AOT optimization might require minutes of time to create a cache on a small instance, but just seconds on a large instance."
      },
      "fullText": "JEP 514: Ahead-of-Time Command-Line Ergonomics JEP 514: Ahead-of-Time Command-Line Ergonomics Owner John Rose Type Feature Scope JDK Status Closed&#8201;/&#8201;Delivered Release 25 Component hotspot&#8201;/&#8201;runtime Discussion leyden dash dev at openjdk dot org Effort M Duration S Relates to JEP 483: Ahead-of-Time Class Loading &amp; Linking Reviewed by Alex Buckley, Vladimir Kozlov Endorsed by Vladimir Kozlov Created 2025/02/13 18:07 Updated 2025/06/06 19:25 Issue 8350022 Summary Make it easier to create ahead-of-time caches , which accelerate the startup of Java applications, by simplifying the commands required for common use cases. Goals Simplify the process of creating an ahead-of-time (AOT) cache, with no loss of expressiveness. Do not introduce fundamentally new AOT workflows, but rather make it easier to access existing ones. Non-Goals It is not a goal to introduce new AOT optimizations; rather, we aim to simplify access to all AOT optimizations, both present and future. Motivation Ahead-of-time caches, introduced by JEP 483 , accelerate the startup of Java applications. Their benefits are expected to grow as Project Leyden brings new AOT-related optimizations to the HotSpot JVM. With JDK 24, you create an AOT cache in two steps, invoking the java launcher in two distinct AOT modes . The first invocation specifies record mode, directing the JVM to observe the dynamics of a training run of your application and record them into an AOT configuration . The second invocation specifies create mode, directing the JVM to create an AOT cache based on the configuration recorded during the training run. Here is an example of this two-step workflow, taken from JEP 483 : $ java -XX:AOTMode=record -XX:AOTConfiguration=app.aotconf \\ -cp app.jar com.example.App ... $ java -XX:AOTMode=create -XX:AOTConfiguration=app.aotconf \\ -XX:AOTCache=app.aot Subsequently, you run your application specifying just the AOT cache: $ java -XX:AOTCache=app.aot -cp app.jar com.example.App ... This production run of the application starts more quickly because the application's classes do not need to be discovered, loaded, and linked. They are available instantly from the cache. It is inconvenient to have to run java twice in order to create an AOT cache. It is also inconvenient to have the AOT configuration file left over &#8212; it is just a temporary file, not required for production runs, and can be deleted. It would be far more convenient if, at least in common use cases, only one step were needed to perform a training run and create an AOT cache. This would be efficient for users and also convenient for applications such as JRuby that coordinate their own training against custom workloads. The ability to specify AOT modes and AOT configurations explicitly can remain for uncommon use cases. Description We extend the java launcher with a new command-line option, AOTCacheOutput , that specifies an AOT cache output file. When used alone, with no other AOT options, thi"
    }
  },
  {
    "url": "https://openjdk.org/jeps/519",
    "title": "JEP 519: Compact Object Headers",
    "content": {
      "title": "JEP 519: Compact Object Headers",
      "summary": "JEP 519: Compact Object Headers JEP 519: Compact Object Headers Owner Roman Kennke Type Feature Scope Implementation Status Closed&#8201;/&#8201;Delivered Release 25 Component hotspot&#8201;/&#8201;runtime Discussion hotspot dash dev at openjdk dot org Effort S Duration XS Relates to JEP 450: Compact Object Headers (Experimental) Reviewed by Coleen Phillimore, Stefan Karlsson, Vladimir Kozlov Endorsed by Vladimir Kozlov Created 2025/04/15 14:01 Updated 2025/08/24 18:03 Issue 8354672 Summary Chan",
      "sections": {
        "Summary": "Change compact object headers from an experimental feature to a product feature.",
        "Goals": "It is not a goal to make compact object headers be the default object-header layout.",
        "Non-Goals": "It is not a goal to make compact object headers be the default object-header layout.",
        "Motivation": "Compact object headers were introduced as an alternative object-header layout by JEP&#160;450 in JDK&#160;24. Features of this size are best introduced carefully and gradually, so we introduced it as an experimental feature. Since JDK&#160;24, compact object headers have proven their stability and performance. They have been tested at Oracle by running the full JDK test suite. They have also been tested at Amazon by hundreds of services in production, most of them using backports of the feature to JDK&#160;21 and JDK&#160;17. Various experiments demonstrate that enabling compact object headers improves performance: In one setting, the SPECjbb2015 benchmark uses 22% less heap space and 8% less CPU time . In another setting, the number of garbage collections done by SPECjbb2015 is reduced by 15% , with both the G1 and Parallel collectors. A highly parallel JSON parser benchmark runs in 10% less time . It is time to change compact object headers from an experimental feature to a product f",
        "Description": "Compact object headers are enabled in JDK&#160;24 via the command-line options $ java -XX:+UnlockExperimentalVMOptions -XX:+UseCompactObjectHeaders ... The first option, -XX:+UnlockExperimentalVMOptions , will no longer be needed once they are a product feature.",
        "Testing": "Compact object headers were subjected to massive",
        "Risks and Assumptions": "As discussed in JEP 450 , future features may require additional object-header bits. We have already reserved four bits for Project Valhalla . If a need for even more bits arises then we can shrink compressed class pointers and identity hash codes even further, using techniques we have already prototyped in Project Lilliput . Installing Contributing Sponsoring Developers' Guide Vulnerabilities JDK GA/EA Builds Mailing lists Wiki &#183; IRC Mastodon Bluesky Bylaws &#183; Census Legal Workshop JEP Process Source code GitHub Mercurial Tools Git jtreg harness Groups (overview) Adoption Build Client Libraries Compatibility &amp;",
        "Specification": "Review Compiler Conformance Core Libraries Governing Board HotSpot IDE Tooling &amp; Support Internationalization JMX Members Networking Porters Quality Security Serviceability Vulnerability Web Projects ( overview , archive ) Amber Babylon CRaC Code Tools Coin Common VM Interface Developers' Guide Device I/O Duke Galahad Graal IcedTea JDK 8 Updates JDK 9 JDK (&#8230;, 24 , 25 , 26 ) JDK Updates JMC Jigsaw Kona Lanai Leyden Lilliput Locale Enhancement Loom Memory Model Update Metropolis Multi-Language VM Nashorn New I/O OpenJFX Panama Penrose Port: AArch32 Port: AArch64 Port: BSD Port: Haiku Port: Mac OS X Port: MIPS Port: Mobile Port: PowerPC/AIX Port: RISC-V Port: s390x SCTP Shenandoah Skara Sumatra Tsan Valhalla Verona VisualVM Wakefield Zero ZGC &#169; 2025 Oracle Corporation and/or its affiliates Terms of Use &#183; License: GPLv2 &#183; Privacy &#183; Trademarks"
      },
      "fullText": "JEP 519: Compact Object Headers JEP 519: Compact Object Headers Owner Roman Kennke Type Feature Scope Implementation Status Closed&#8201;/&#8201;Delivered Release 25 Component hotspot&#8201;/&#8201;runtime Discussion hotspot dash dev at openjdk dot org Effort S Duration XS Relates to JEP 450: Compact Object Headers (Experimental) Reviewed by Coleen Phillimore, Stefan Karlsson, Vladimir Kozlov Endorsed by Vladimir Kozlov Created 2025/04/15 14:01 Updated 2025/08/24 18:03 Issue 8354672 Summary Change compact object headers from an experimental feature to a product feature. Non-Goals It is not a goal to make compact object headers be the default object-header layout. Motivation Compact object headers were introduced as an alternative object-header layout by JEP&#160;450 in JDK&#160;24. Features of this size are best introduced carefully and gradually, so we introduced it as an experimental feature. Since JDK&#160;24, compact object headers have proven their stability and performance. They have been tested at Oracle by running the full JDK test suite. They have also been tested at Amazon by hundreds of services in production, most of them using backports of the feature to JDK&#160;21 and JDK&#160;17. Various experiments demonstrate that enabling compact object headers improves performance: In one setting, the SPECjbb2015 benchmark uses 22% less heap space and 8% less CPU time . In another setting, the number of garbage collections done by SPECjbb2015 is reduced by 15% , with both the G1 and Parallel collectors. A highly parallel JSON parser benchmark runs in 10% less time . It is time to change compact object headers from an experimental feature to a product feature. Description Compact object headers are enabled in JDK&#160;24 via the command-line options $ java -XX:+UnlockExperimentalVMOptions -XX:+UseCompactObjectHeaders ... The first option, -XX:+UnlockExperimentalVMOptions , will no longer be needed once they are a product feature. Testing Compact object headers were subjected to massive testing as part of JEP&#160;450 , in addition to the testing mentioned above . No further testing is required. Some tests currently supply the -XX:+UnlockExperimentalVMOptions command-line option when enabling compact object headers. This will no longer be needed, so we will adjust these tests accordingly. Risks and Assumptions As discussed in JEP 450 , future features may require additional object-header bits. We have already reserved four bits for Project Valhalla . If a need for even more bits arises then we can shrink compressed class pointers and identity hash codes even further, using techniques we have already prototyped in Project Lilliput . Installing Contributing Sponsoring Developers' Guide Vulnerabilities JDK GA/EA Builds Mailing lists Wiki &#183; IRC Mastodon Bluesky Bylaws &#183; Census Legal Workshop JEP Process Source code GitHub Mercurial Tools Git jtreg harness Groups (overview) Adoption Build Client Libraries Compatibility &amp; Specification R"
    }
  },
  {
    "url": "https://openjdk.org/jeps/491",
    "title": "JEP 491: Synchronize Virtual Threads without Pinning",
    "content": {
      "title": "JEP 491: Synchronize Virtual Threads without Pinning",
      "summary": "JEP 491: Synchronize Virtual Threads without Pinning JEP 491: Synchronize Virtual Threads without Pinning Author Patricio Chilano Mateo &amp; Alan Bateman Owner Alan Bateman Type Feature Scope Implementation Status Closed&#8201;/&#8201;Delivered Release 24 Component hotspot&#8201;/&#8201;runtime Discussion hotspot dash dev at openjdk dot org, loom dash dev at openjdk dot org Effort M Reviewed by Daniel Daugherty, Vladimir Kozlov Endorsed by Vladimir Kozlov Created 2024/07/29 17:09 Updated 2025/0",
      "sections": {
        "Summary": "Improve the scalability of Java code that uses synchronized methods and statements by arranging for virtual threads that block in such constructs to release their underlying platform threads for use by other virtual threads. This will eliminate nearly all cases of virtual threads being pinned to platform threads, which severely restricts the number of virtual threads available to handle an application's workload.",
        "Goals": "Enable existing Java libraries to scale well with virtual threads without having to change them not to use synchronized methods and statements. Improve the diagnostics that identify the remaining situations in which virtual threads fail to release platform threads.",
        "Motivation": "Virtual threads, which were introduced in Java&#160;21 via JEP&#160;444 , are lightweight threads that are provided by the JDK rather than the operating system (OS). Virtual threads significantly reduce the effort of developing, maintaining, and observing high-throughput concurrent applications by enabling applications to use huge numbers of threads. The basic model of virtual threads is as follows: To do useful work, a thread must be scheduled , that is, assigned for execution on a processor core. For platform threads, which are implemented as OS threads, the JDK relies on the scheduler in the OS. For virtual threads, by contrast, the JDK has its own scheduler. Rather than assign virtual threads to processor cores directly, the JDK's scheduler assigns virtual threads to platform threads, which are then scheduled by the OS as usual. To run code in a virtual thread, the JDK's scheduler assigns the virtual thread for execution on a platform thread by mounting the virtual thread on the pl",
        "Description": "We will change the JVM's implementation of the synchronized keyword so that virtual threads can acquire, hold, and release monitors, independently of their carriers. The mounting and unmounting operations will do the bookkeeping necessary to allow a virtual thread to unmount and re-mount when inside a synchronized method or statement, or when waiting on a monitor. Blocking to acquire a monitor will unmount a virtual thread and release its carrier to the JDK's scheduler. When the monitor is released, and the JVM selects the virtual thread to continue, the JVM will submit the virtual thread to the scheduler. The scheduler will mount the virtual thread, perhaps on a different carrier, to resume execution and try again to acquire the monitor. The Object.wait() method, and its timed-wait variants, will similarly unmount a virtual thread when waiting and blocking to re-acquire a monitor. When awakened with Object.notify() , and the monitor is released, and the JVM selects the virtual thread ",
        "Alternatives": "Compensate for pinning by temporarily expanding the parallelism of the virtual-thread scheduler. The scheduler already does this for Object.wait() , by ensuring that a spare platform thread is available while a virtual thread is waiting. Increasing parallelism would help with some cases, but it does not scale. The maximum number of platform threads available to the scheduler is limited, with a default limit of 256 threads. If many virtual threads were to block inside a synchronized method then no value of parallelism would help. Rewrite the bytecode of each class, as the JVM loads it, to replace each use of synchronized with an equivalent use of ReentrantLock . The synchronized statement can be used with any object, so this would require maintaining a mapping from objects to locks, a significant overhead. There are cases where the transformation would not be fully transparent, in particular for synchronized methods, since JVMS &#167;2.11.10 requires acquiring the monitor before invokin",
        "Risks and Assumptions": "The performance of some code may be different when virtual threads are used in place of platform threads. When a thread exits a monitor it may have to queue a virtual thread to the scheduler. This is currently not as efficient as the case where exiting a monitor unparks a platform thread.",
        "Dependencies": "The changes we propose here depend upon a change to the",
        "Specification": "of the JVM&#160;TI function GetObjectMonitorUsage in Java&#160;23 . This function no longer supports returning information about monitors owned by virtual threads. Doing so would have required significant bookkeeping to find the monitors owned by unmounted virtual threads. Installing Contributing Sponsoring Developers' Guide Vulnerabilities JDK GA/EA Builds Mailing lists Wiki &#183; IRC Mastodon Bluesky Bylaws &#183; Census Legal Workshop JEP Process Source code GitHub Mercurial Tools Git jtreg harness Groups (overview) Adoption Build Client Libraries Compatibility &amp;"
      },
      "fullText": "JEP 491: Synchronize Virtual Threads without Pinning JEP 491: Synchronize Virtual Threads without Pinning Author Patricio Chilano Mateo &amp; Alan Bateman Owner Alan Bateman Type Feature Scope Implementation Status Closed&#8201;/&#8201;Delivered Release 24 Component hotspot&#8201;/&#8201;runtime Discussion hotspot dash dev at openjdk dot org, loom dash dev at openjdk dot org Effort M Reviewed by Daniel Daugherty, Vladimir Kozlov Endorsed by Vladimir Kozlov Created 2024/07/29 17:09 Updated 2025/02/04 18:54 Issue 8337395 Summary Improve the scalability of Java code that uses synchronized methods and statements by arranging for virtual threads that block in such constructs to release their underlying platform threads for use by other virtual threads. This will eliminate nearly all cases of virtual threads being pinned to platform threads, which severely restricts the number of virtual threads available to handle an application's workload. Goals Enable existing Java libraries to scale well with virtual threads without having to change them not to use synchronized methods and statements. Improve the diagnostics that identify the remaining situations in which virtual threads fail to release platform threads. Motivation Virtual threads, which were introduced in Java&#160;21 via JEP&#160;444 , are lightweight threads that are provided by the JDK rather than the operating system (OS). Virtual threads significantly reduce the effort of developing, maintaining, and observing high-throughput concurrent applications by enabling applications to use huge numbers of threads. The basic model of virtual threads is as follows: To do useful work, a thread must be scheduled , that is, assigned for execution on a processor core. For platform threads, which are implemented as OS threads, the JDK relies on the scheduler in the OS. For virtual threads, by contrast, the JDK has its own scheduler. Rather than assign virtual threads to processor cores directly, the JDK's scheduler assigns virtual threads to platform threads, which are then scheduled by the OS as usual. To run code in a virtual thread, the JDK's scheduler assigns the virtual thread for execution on a platform thread by mounting the virtual thread on the platform thread. This makes the platform thread become the carrier of the virtual thread. Later, after running some code, the virtual thread can unmount from its carrier. At that point the platform thread is released so that the JDK's scheduler can mount a different virtual thread on it, thereby making it a carrier again. A virtual thread unmounts when performing a blocking operation such as I&#65279;/&#65279;O. Later, when the blocking operation is ready to complete because, e.g., bytes were received on a socket, the operation submits the virtual thread back to the JDK's scheduler. The scheduler mounts the virtual thread on a platform thread to resume running code. Virtual threads are mounted and unmounted frequently and transparently, without blocking any p"
    }
  },
  {
    "url": "https://openjdk.org/jeps/512",
    "title": "JEP 512: Compact Source Files and Instance Main Methods",
    "content": {
      "title": "JEP 512: Compact Source Files and Instance Main Methods",
      "summary": "JEP 512: Compact Source Files and Instance Main Methods JEP 512: Compact Source Files and Instance Main Methods Authors Ron Pressler, Jim Laskey, &amp; Gavin Bierman Owner Gavin Bierman Type Feature Scope SE Status Closed&#8201;/&#8201;Delivered Release 25 Component specification&#8201;/&#8201;language Discussion amber dash dev at openjdk dot org Relates to JEP 511: Module Import Declarations JEP 495: Simple Source Files and Instance Main Methods (Fourth Preview) Reviewed by Alex Buckley, Brian ",
      "sections": {
        "Summary": "Evolve the Java programming language so that beginners can write their first programs without needing to understand language features designed for large programs. Far from using a separate dialect of the language, beginners can write streamlined declarations for single-class programs and then seamlessly expand their programs to use more advanced features as their skills grow. Experienced developers can likewise enjoy writing small programs succinctly, without the need for constructs intended for programming in the large. History This feature was first proposed for preview by JEP&#160;445 (JDK&#160;21) and subsequently improved and refined by JEP&#160;463 (JDK&#160;22), JEP&#160;477 (JDK&#160;23), and JEP&#160;495 (JDK&#160;24). We here propose to finalize the feature in JDK&#160;25, renaming simple source files to compact source files, with several minor improvements based upon experience and feedback: The new IO class for basic console I/O is now in the java.lang package rather than t",
        "Goals": "Offer a smooth on-ramp to Java programming, so that instructors can introduce concepts in a gradual manner. Help students write simple programs in a concise manner, and grow their code gracefully as their skills grow. Reduce the ceremony of writing other kinds of small programs, such as scripts and command-line utilities. Do not introduce a separate dialect of the Java language. Do not introduce a separate toolchain. Small Java programs should be compiled and run with the same tools as large programs.",
        "Motivation": "The Java programming language excels for large, complex applications developed and maintained by large teams over many years. It has rich features for data hiding, reuse, access control, namespace management, and modularity which allow components to be cleanly composed while being developed and maintained independently. With these features, components can expose well-defined interfaces for their interaction with other components and, at the same time, hide internal implementation details so as to permit the independent evolution of each. Indeed, the object-oriented paradigm is, fundamentally, about plugging together components that interact through well-defined protocols while abstracting away implementation details. This composition of large components is called programming in the large . The Java programming language is also, however, intended to be a first language. When programmers first start out they do not write large programs, in a team &#8212; they write small programs, alone.",
        "Description": "First, we allow main methods to omit the infamous boilerplate of public static void main(String[] args) , which simplifies the Hello, World! program to: class HelloWorld { void main() { System.out.println(\"Hello, World!\"); } } Second, we introduce a compact form of source file that lets developers get straight to the code, without a superfluous class declaration: void main() { System.out.println(\"Hello, World!\"); } Third, we add a new class in the java.lang package that provides basic line-oriented I/O methods for beginners, thereby replacing the mysterious System.out.println with a simpler form: void main() { IO.println(\"Hello, World!\"); } Finally, for programs that go beyond Hello, World! and need, for example, basic data structures or file I/O, in compact source files we automatically import a range of standard APIs beyond the java.lang package. These changes combine to offer an on-ramp , that is, a gradual incline that merges gracefully onto the highway. As beginners move on to lar",
        "Alternatives": "Automatically import the console I/O methods In earlier previews of this feature, we explored the possibility of compact source files automatically importing the static methods of the new IO class. Thus developers could write println(...) in compact source files instead of IO.println(...) . This had the pleasing effect of making the methods in IO appear to be built-in to the Java language, but it added a speed bump to the on-ramp: To evolve a compact source file into an ordinary source file, a beginner would have to add a static import declaration &#8212; another advanced concept. This runs contrary to our second goal, namely that that beginners should be able to grow their code gracefully. This design would also create a long-term burden of reviewing a likely endless stream of proposals to add additional methods to the IO class. Automatically import fewer packages Rather than automatically importing all 54 packages from the java.base module into compact source files, we could instead ",
        "Specification": "&#8201;/&#8201;language Discussion amber dash dev at openjdk dot org Relates to JEP 511: Module Import Declarations JEP 495: Simple Source Files and Instance Main Methods (Fourth Preview) Reviewed by Alex Buckley, Brian Goetz Endorsed by Brian Goetz Created 2024/11/21 11:58 Updated 2025/07/11 06:45 Issue 8344699"
      },
      "fullText": "JEP 512: Compact Source Files and Instance Main Methods JEP 512: Compact Source Files and Instance Main Methods Authors Ron Pressler, Jim Laskey, &amp; Gavin Bierman Owner Gavin Bierman Type Feature Scope SE Status Closed&#8201;/&#8201;Delivered Release 25 Component specification&#8201;/&#8201;language Discussion amber dash dev at openjdk dot org Relates to JEP 511: Module Import Declarations JEP 495: Simple Source Files and Instance Main Methods (Fourth Preview) Reviewed by Alex Buckley, Brian Goetz Endorsed by Brian Goetz Created 2024/11/21 11:58 Updated 2025/07/11 06:45 Issue 8344699 Summary Evolve the Java programming language so that beginners can write their first programs without needing to understand language features designed for large programs. Far from using a separate dialect of the language, beginners can write streamlined declarations for single-class programs and then seamlessly expand their programs to use more advanced features as their skills grow. Experienced developers can likewise enjoy writing small programs succinctly, without the need for constructs intended for programming in the large. History This feature was first proposed for preview by JEP&#160;445 (JDK&#160;21) and subsequently improved and refined by JEP&#160;463 (JDK&#160;22), JEP&#160;477 (JDK&#160;23), and JEP&#160;495 (JDK&#160;24). We here propose to finalize the feature in JDK&#160;25, renaming simple source files to compact source files, with several minor improvements based upon experience and feedback: The new IO class for basic console I/O is now in the java.lang package rather than the java.io package. Thus it is implicitly imported by every source file. The static methods of the IO class are no longer implicitly imported into compact source files. Thus invocations of these methods must name the class, e.g., IO.println(\"Hello, world!\") , unless the methods are explicitly imported. The implementation of the IO class is now based upon System.out and System.in rather than the java.io.Console class. Goals Offer a smooth on-ramp to Java programming, so that instructors can introduce concepts in a gradual manner. Help students write simple programs in a concise manner, and grow their code gracefully as their skills grow. Reduce the ceremony of writing other kinds of small programs, such as scripts and command-line utilities. Do not introduce a separate dialect of the Java language. Do not introduce a separate toolchain. Small Java programs should be compiled and run with the same tools as large programs. Motivation The Java programming language excels for large, complex applications developed and maintained by large teams over many years. It has rich features for data hiding, reuse, access control, namespace management, and modularity which allow components to be cleanly composed while being developed and maintained independently. With these features, components can expose well-defined interfaces for their interaction with other components and, at the same tim"
    }
  },
  {
    "url": "https://openjdk.org/jeps/513",
    "title": "JEP 513: Flexible Constructor Bodies",
    "content": {
      "title": "JEP 513: Flexible Constructor Bodies",
      "summary": "JEP 513: Flexible Constructor Bodies JEP 513: Flexible Constructor Bodies Author Archie Cobbs &amp; Gavin Bierman Owner Gavin Bierman Type Feature Scope SE Status Closed&#8201;/&#8201;Delivered Release 25 Component specification&#8201;/&#8201;language Discussion amber dash dev at openjdk dot org Relates to JEP 492: Flexible Constructor Bodies (Third Preview) Reviewed by Alex Buckley, Brian Goetz Endorsed by Brian Goetz Created 2024/11/21 12:03 Updated 2025/07/22 15:03 Issue 8344702 Summary In th",
      "sections": {
        "Summary": "In the body of a constructor, allow statements to appear before an explicit constructor invocation, i.e., super(...) or this(...) . Such statements cannot reference the object under construction, but they can initialize its fields and perform other safe computations. This change allows many constructors to be expressed more naturally. It also allows fields to be initialized before they become visible to other code in the class, such as methods called from a superclass constructor, thereby improving safety. History Flexible constructor bodies were first proposed as a preview feature by JEP&#160;447 (JDK&#160;22), under a different title. They were revised and re-previewed by JEP&#160;482 (JDK&#160;23) and then previewed again, without change, by JEP&#160;492 (JDK&#160;24). We here propose to finalize the feature in JDK&#160;25, without change.",
        "Goals": "Remove unnecessary restrictions on code in constructors, so that arguments can easily be validated before calling superclass constructors. Provide additional guarantees that the state of a new object is fully initialized before any code can use it. Reimagine the process of how constructors interact with each other to create a fully initialized object.",
        "Motivation": "The constructors of a class are responsible for creating valid instances of the class. Typically, a constructor validates and transforms its arguments and then initializes the fields declared in its class to legitimate values. In the presence of subclassing, constructors of superclasses and subclasses share responsibility for creating valid instances. For example, consider a Person class with an Employee subclass. Every Employee constructor will invoke, either implicitly or explicitly, a Person constructor, and the two constructors should work together to construct a valid instance. The Employee constructor is responsible for the fields declared in the Employee class, while the Person constructor is responsible for the fields declared in the Person class. Since code in the Employee constructor can refer to fields declared in the Person class, it is only safe for the Employee constructor to access those fields after the Person constructor has finished assigning values to them. The Java ",
        "Description": "We propose to remove the simplistic syntactic top-down rule, enforced since the Java language was created, that every constructor body begin, either explicitly or implicitly, with a constructor invocation, i.e., super(..) or this(..) . This change allows us to write readable constructors that validate their arguments before invoking superclass constructors. For example, we can write our Employee constructor directly and more clearly to fail fast: class Employee extends Person { String officeID; Employee(..., int age, String officeID) { if (age &lt; 18 || age &gt; 67) // Now fails fast! throw new IllegalArgumentException(...); super(..., age); this.officeID = officeID; } } This change also enables us to ensure that subclass constructors establish integrity by initializing their fields before invoking superclass constructors. For example, we can further revise the Employee constructor to initialize the officeID field before invoking the superclass constructor: class Employee extends Pers",
        "Testing": "We will test the compiler changes with existing unit tests, unchanged except for those tests that verify changed behavior, plus new positive and negative test cases as appropriate. We will compile all JDK classes using the previous and new versions of the compiler and verify that the resulting bytecode is identical. No platform-specific",
        "Risks and Assumptions": "The changes we propose above are both source- and behavior-compatible. They strictly expand the set of legal Java programs while preserving the meaning of all existing Java programs. These changes, though modest in themselves, represent a significant change in how constructors participate in safe object initialization. They relax the long-standing requirement that a constructor invocation, if present, must always be the first statement in a constructor body. This requirement is deeply embedded in code analyzers, style checkers, syntax highlighters, development environments, and other tools in the Java ecosystem. As with any language change, there may be a period of pain as tools are updated.",
        "Dependencies": "The Java Virtual Machine Flexible constructor bodies in the Java language depend on the ability of the JVM to verify and execute arbitrary code that appears before constructor invocations in constructors, so long as that code does not reference the instance under construction except to initialize uninitialized fields. Fortunately, the JVM already supports a more flexible treatment of constructor bodies: Multiple constructor invocations may appear in a constructor body provided that, on any code path, there is exactly one invocation; Arbitrary code may appear before constructor invocations so long as that code does not reference the instance under construction except to assign fields; and Explicit constructor invocations may not appear within a try block, i.e., within a bytecode exception range. The JVM's rules still ensure safe object initialization: Superclass initialization always happens exactly once, either directly via a superclass constructor invocation or indirectly via an alter",
        "Specification": "&#8201;/&#8201;language Discussion amber dash dev at openjdk dot org Relates to JEP 492: Flexible Constructor Bodies (Third Preview) Reviewed by Alex Buckley, Brian Goetz Endorsed by Brian Goetz Created 2024/11/21 12:03 Updated 2025/07/22 15:03 Issue 8344702"
      },
      "fullText": "JEP 513: Flexible Constructor Bodies JEP 513: Flexible Constructor Bodies Author Archie Cobbs &amp; Gavin Bierman Owner Gavin Bierman Type Feature Scope SE Status Closed&#8201;/&#8201;Delivered Release 25 Component specification&#8201;/&#8201;language Discussion amber dash dev at openjdk dot org Relates to JEP 492: Flexible Constructor Bodies (Third Preview) Reviewed by Alex Buckley, Brian Goetz Endorsed by Brian Goetz Created 2024/11/21 12:03 Updated 2025/07/22 15:03 Issue 8344702 Summary In the body of a constructor, allow statements to appear before an explicit constructor invocation, i.e., super(...) or this(...) . Such statements cannot reference the object under construction, but they can initialize its fields and perform other safe computations. This change allows many constructors to be expressed more naturally. It also allows fields to be initialized before they become visible to other code in the class, such as methods called from a superclass constructor, thereby improving safety. History Flexible constructor bodies were first proposed as a preview feature by JEP&#160;447 (JDK&#160;22), under a different title. They were revised and re-previewed by JEP&#160;482 (JDK&#160;23) and then previewed again, without change, by JEP&#160;492 (JDK&#160;24). We here propose to finalize the feature in JDK&#160;25, without change. Goals Remove unnecessary restrictions on code in constructors, so that arguments can easily be validated before calling superclass constructors. Provide additional guarantees that the state of a new object is fully initialized before any code can use it. Reimagine the process of how constructors interact with each other to create a fully initialized object. Motivation The constructors of a class are responsible for creating valid instances of the class. Typically, a constructor validates and transforms its arguments and then initializes the fields declared in its class to legitimate values. In the presence of subclassing, constructors of superclasses and subclasses share responsibility for creating valid instances. For example, consider a Person class with an Employee subclass. Every Employee constructor will invoke, either implicitly or explicitly, a Person constructor, and the two constructors should work together to construct a valid instance. The Employee constructor is responsible for the fields declared in the Employee class, while the Person constructor is responsible for the fields declared in the Person class. Since code in the Employee constructor can refer to fields declared in the Person class, it is only safe for the Employee constructor to access those fields after the Person constructor has finished assigning values to them. The Java language ensures construction of valid instances by running constructors from the top down: A constructor in a superclass runs before a constructor in a subclass. To achieve this, the language requires the first statement in a constructor to be a constructor invocation, i.e., su"
    }
  },
  {
    "url": "https://openjdk.org/jeps/511",
    "title": "JEP 511: Module Import Declarations",
    "content": {
      "title": "JEP 511: Module Import Declarations",
      "summary": "JEP 511: Module Import Declarations JEP 511: Module Import Declarations Author Jim Laskey &amp; Gavin Bierman Owner Gavin Bierman Type Feature Scope SE Status Closed&#8201;/&#8201;Delivered Release 25 Component specification&#8201;/&#8201;language Discussion amber dash dev at openjdk dot org Relates to JEP 494: Module Import Declarations (Second Preview) JEP 512: Compact Source Files and Instance Main Methods Reviewed by Alex Buckley, Brian Goetz Endorsed by Brian Goetz Created 2024/11/21 12:00 ",
      "sections": {
        "Summary": "Enhance the Java programming language with the ability to succinctly import all of the packages exported by a module. This simplifies the reuse of modular libraries, but does not require the importing code to be in a module itself. History Module import declarations were proposed as a preview feature by JEP&#160;476 (JDK&#160;23) and subsequently refined by JEP&#160;494 (JDK&#160;24). We here propose to finalize the feature in JDK&#160;25, without change.",
        "Goals": "Simplify the reuse of modular libraries by allowing entire modules to be imported at once. Avoid the noise of multiple type-import-on-demand declarations (e.g., import com.foo.bar.* ) when using diverse parts of the API exported by a module. Allow beginners to more easily use third-party libraries and fundamental Java classes without having to learn where they are located in a package hierarchy. Ensure that module import declarations work smoothly alongside existing import declarations. Do not require developers who use the module import feature to modularize their own code.",
        "Motivation": "Classes and interfaces in the java.lang package, such as Object , String , and Comparable , are essential to every Java program. For this reason, the Java compiler automatically imports, on demand, all of the classes and interfaces in the java.lang package, as if import java.lang.*; appears at the beginning of every source file. As the Java Platform has evolved, classes and interfaces such as List , Map , Stream , and Path have become almost as essential. However, none of these are in java.lang , so they are not automatically imported; rather, developers have to keep the compiler happy by writing a plethora of import declarations at the beginning of every source file. For example, the following code converts an array of strings into a map from capital letters to strings, but the imports take almost as many lines as the code: import java.util.Map; // or import java.util.*; import java.util.function.Function; // or import java.util.function.*; import java.util.stream.Collectors; // or im",
        "Description": "A module import declaration has the form import module M; It imports, on demand, all of the public top-level classes and interfaces in The packages exported by the module M to the current module, and The packages exported by the modules that are read by the current module due to reading the module M . The second clause allows a program to use the API of a module, which might refer to classes and interfaces from other modules, without having to import all of those other modules. For example: import module java.base has the same effect as 54 on-demand package imports, one for each of the packages exported by the java.base module. It is as if the source file contains import java.io.* and import java.util.* and so on. import module java.sql has the same effect as import java.sql.* and import javax.sql.* plus on-demand package imports for the indirect exports of the java.sql module . Syntax and semantics We extend the grammar of import declarations ( JLS&#160;&#167;7.5 ) to include import m",
        "Alternatives": "An alternative to import module ... is to automatically import more packages than just java.lang . This would bring more classes into scope, i.e., usable by their simple names, and delay the need for beginners to learn about imports of any kind. But, which additional packages should we import automatically? Every reader will have suggestions for which packages to auto-import from the omnipresent java.base module: java.io and java.util would be near-universal suggestions; java.util.stream and java.util.function would be common; and java.math , java.net , and java.time would each have supporters. For the JShell tool, we managed to find ten java.* packages which are broadly useful when experimenting with one-off Java code, but it is difficult to see which subset of java.* packages deserves to be permanently and automatically imported into every Java program. The list would, moreover, change change as the Java Platform evolves; e.g., java.util.stream and java.util.function were introduced ",
        "Risks and Assumptions": "Using one or more module import declarations leads to a risk of name ambiguity due to different packages declaring members with the same simple name. This ambiguity is not detected until the ambiguous simple name is used in a program, when a compile-time error will occur. The ambiguity can be resolved by adding a single-type-import declaration, but managing and resolving such name ambiguities could be burdensome and lead to code that is brittle and difficult to read and maintain. Installing Contributing Sponsoring Developers' Guide Vulnerabilities JDK GA/EA Builds Mailing lists Wiki &#183; IRC Mastodon Bluesky Bylaws &#183; Census Legal Workshop JEP Process Source code GitHub Mercurial Tools Git jtreg harness Groups (overview) Adoption Build Client Libraries Compatibility &amp;",
        "Dependencies": "would be a further convenience when prototyping and exploring.",
        "Specification": "&#8201;/&#8201;language Discussion amber dash dev at openjdk dot org Relates to JEP 494: Module Import Declarations (Second Preview) JEP 512: Compact Source Files and Instance Main Methods Reviewed by Alex Buckley, Brian Goetz Endorsed by Brian Goetz Created 2024/11/21 12:00 Updated 2025/07/22 14:42 Issue 8344700"
      },
      "fullText": "JEP 511: Module Import Declarations JEP 511: Module Import Declarations Author Jim Laskey &amp; Gavin Bierman Owner Gavin Bierman Type Feature Scope SE Status Closed&#8201;/&#8201;Delivered Release 25 Component specification&#8201;/&#8201;language Discussion amber dash dev at openjdk dot org Relates to JEP 494: Module Import Declarations (Second Preview) JEP 512: Compact Source Files and Instance Main Methods Reviewed by Alex Buckley, Brian Goetz Endorsed by Brian Goetz Created 2024/11/21 12:00 Updated 2025/07/22 14:42 Issue 8344700 Summary Enhance the Java programming language with the ability to succinctly import all of the packages exported by a module. This simplifies the reuse of modular libraries, but does not require the importing code to be in a module itself. History Module import declarations were proposed as a preview feature by JEP&#160;476 (JDK&#160;23) and subsequently refined by JEP&#160;494 (JDK&#160;24). We here propose to finalize the feature in JDK&#160;25, without change. Goals Simplify the reuse of modular libraries by allowing entire modules to be imported at once. Avoid the noise of multiple type-import-on-demand declarations (e.g., import com.foo.bar.* ) when using diverse parts of the API exported by a module. Allow beginners to more easily use third-party libraries and fundamental Java classes without having to learn where they are located in a package hierarchy. Ensure that module import declarations work smoothly alongside existing import declarations. Do not require developers who use the module import feature to modularize their own code. Motivation Classes and interfaces in the java.lang package, such as Object , String , and Comparable , are essential to every Java program. For this reason, the Java compiler automatically imports, on demand, all of the classes and interfaces in the java.lang package, as if import java.lang.*; appears at the beginning of every source file. As the Java Platform has evolved, classes and interfaces such as List , Map , Stream , and Path have become almost as essential. However, none of these are in java.lang , so they are not automatically imported; rather, developers have to keep the compiler happy by writing a plethora of import declarations at the beginning of every source file. For example, the following code converts an array of strings into a map from capital letters to strings, but the imports take almost as many lines as the code: import java.util.Map; // or import java.util.*; import java.util.function.Function; // or import java.util.function.*; import java.util.stream.Collectors; // or import java.util.stream.*; import java.util.stream.Stream; // (can be removed) String[] fruits = new String[] { \"apple\", \"berry\", \"citrus\" }; Map&lt;String, String&gt; m = Stream.of(fruits) .collect(Collectors.toMap(s -&gt; s.toUpperCase().substring(0,1), Function.identity())); Developers have diverse views as to whether to prefer single-type-import or type-import-on-demand declarations. Many "
    }
  },
  {
    "url": "https://openjdk.org/jeps/456",
    "title": "JEP 456: Unnamed Variables &amp; Patterns",
    "content": {
      "title": "JEP 456: Unnamed Variables &amp; Patterns",
      "summary": "JEP 456: Unnamed Variables &amp; Patterns JEP 456: Unnamed Variables &amp; Patterns Owner Angelos Bimpoudis Type Feature Scope SE Status Closed&#8201;/&#8201;Delivered Release 22 Component specification&#8201;/&#8201;language Discussion amber dash dev at openjdk dot org Effort S Duration S Relates to JEP 443: Unnamed Patterns and Variables (Preview) Reviewed by Brian Goetz Endorsed by Brian Goetz Created 2023/07/10 16:17 Updated 2025/09/23 15:52 Issue 8311828 Summary Enhance the Java programming",
      "sections": {
        "Summary": "Enhance the Java programming language with unnamed variables and unnamed patterns, which can be used when variable declarations or nested patterns are required but never used. Both are denoted by the underscore character, _ . History Unnamed variables and unnamed patterns first previewed in JDK 21 via JEP 443 , which was titled Unnamed Patterns and Variables . We here propose to finalize this feature without change.",
        "Goals": "Capture developer intent that a given binding or lambda parameter is unused, and enforce that property, so as to clarify programs and reduce opportunities for error. Improve the maintainability of all code by identifying variables that must be declared (e.g., in catch clauses) but are not used. Allow multiple patterns to appear in a single case label, provided that none of them declare any pattern variables. Improve the readability of record patterns by eliding unnecessary nested type patterns.",
        "Non-Goals": "It is not a goal to allow unnamed fields or method parameters. It is not a goal to alter the semantics of local variables in, e.g., definite assignment analysis .",
        "Motivation": "Developers sometimes declare variables that they do not intend to use, whether as a matter of code style or because the language requires variable declarations in certain contexts. The intent of non-use is known at the time the code is written, but if it is not captured explicitly then later maintainers might accidentally use the variable, thereby violating the intent. If we could make it impossible to accidentally use such variables then code would be more informative, more readable, and less prone to error. Unused variables The need to declare a variable that is never used is especially common in code whose side-effect is more important than its result. For example, this code calculates total as the side effect of a loop, without using the loop variable order : static int count(Iterable&lt;Order&gt; orders) { int total = 0; for (Order order : orders) // order is unused total++; return total; } The prominence of the declaration of order is unfortunate, given that order is not used. Th",
        "Description": "An unnamed variable is declared by using an underscore character, _ (U+005F), to stand in for the name of the local variable in a local variable declaration statement, or an exception parameter in a catch clause, or a lambda parameter in a lambda expression. An unnamed pattern variable is declared by using an underscore character to stand in for the pattern variable in a type pattern. The unnamed pattern is denoted by an underscore character and is equivalent to the unnamed type pattern var _ . It allows both the type and name of a record component to be elided in pattern matching. A single underscore character is the lightest reasonable syntax for signifying the absence of a name. It is commonly used in other languages, such as Scala and Python, for this purpose. A single underscore was, originally, a valid identifier in Java&#160;1.0, but we later reclaimed it for unnamed variables and patterns: We started issuing compile-time warnings when underscore was used as an identifier in Jav",
        "Alternatives": "It is possible to define an analogous concept of unnamed method parameters . However, this has some subtle interactions with the",
        "Risks and Assumptions": "We assume that little if any actively-maintained code uses underscore as a variable name. Developers migrating from Java&#160;7 to Java&#160;22 without having seen the warnings issued in Java&#160;8 or the errors issued since Java&#160;9 could be surprised. They face the risk of dealing with compile-time errors when reading or writing variables named _ and when declaring any other kind of element (class, field, etc.) with the name _ . We expect developers of static analysis tools to understand the new role of underscore for unnamed variables and avoid flagging the non-use of such variables in modern code.",
        "Specification": "&#8201;/&#8201;language Discussion amber dash dev at openjdk dot org Effort S Duration S Relates to JEP 443: Unnamed Patterns and Variables (Preview) Reviewed by Brian Goetz Endorsed by Brian Goetz Created 2023/07/10 16:17 Updated 2025/09/23 15:52 Issue 8311828"
      },
      "fullText": "JEP 456: Unnamed Variables &amp; Patterns JEP 456: Unnamed Variables &amp; Patterns Owner Angelos Bimpoudis Type Feature Scope SE Status Closed&#8201;/&#8201;Delivered Release 22 Component specification&#8201;/&#8201;language Discussion amber dash dev at openjdk dot org Effort S Duration S Relates to JEP 443: Unnamed Patterns and Variables (Preview) Reviewed by Brian Goetz Endorsed by Brian Goetz Created 2023/07/10 16:17 Updated 2025/09/23 15:52 Issue 8311828 Summary Enhance the Java programming language with unnamed variables and unnamed patterns, which can be used when variable declarations or nested patterns are required but never used. Both are denoted by the underscore character, _ . History Unnamed variables and unnamed patterns first previewed in JDK 21 via JEP 443 , which was titled Unnamed Patterns and Variables . We here propose to finalize this feature without change. Goals Capture developer intent that a given binding or lambda parameter is unused, and enforce that property, so as to clarify programs and reduce opportunities for error. Improve the maintainability of all code by identifying variables that must be declared (e.g., in catch clauses) but are not used. Allow multiple patterns to appear in a single case label, provided that none of them declare any pattern variables. Improve the readability of record patterns by eliding unnecessary nested type patterns. Non-Goals It is not a goal to allow unnamed fields or method parameters. It is not a goal to alter the semantics of local variables in, e.g., definite assignment analysis . Motivation Developers sometimes declare variables that they do not intend to use, whether as a matter of code style or because the language requires variable declarations in certain contexts. The intent of non-use is known at the time the code is written, but if it is not captured explicitly then later maintainers might accidentally use the variable, thereby violating the intent. If we could make it impossible to accidentally use such variables then code would be more informative, more readable, and less prone to error. Unused variables The need to declare a variable that is never used is especially common in code whose side-effect is more important than its result. For example, this code calculates total as the side effect of a loop, without using the loop variable order : static int count(Iterable&lt;Order&gt; orders) { int total = 0; for (Order order : orders) // order is unused total++; return total; } The prominence of the declaration of order is unfortunate, given that order is not used. The declaration can be shortened to var order , but there is no way to avoid giving this variable a name. The name itself can be shortened to, e.g., o , but this syntactic trick does not communicate the intent that the variable never be used. In addition, static analysis tools typically complain about unused variables, even when the developer intends non-use and may not have a way to silence the warnings. For another"
    }
  },
  {
    "url": "https://openjdk.org/jeps/484",
    "title": "JEP 484: Class-File API",
    "content": {
      "title": "JEP 484: Class-File API",
      "summary": "JEP 484: Class-File API JEP 484: Class-File API Author Brian Goetz Owner Adam Sotona Type Feature Scope SE Status Closed&#8201;/&#8201;Delivered Release 24 Component core-libs&#8201;/&#8201;java.lang.classfile Discussion core dash libs dash dev at openjdk dot org Effort S Duration M Relates to JEP 466: Class-File API (Second Preview) Reviewed by Paul Sandoz Endorsed by Paul Sandoz Created 2024/06/21 08:36 Updated 2025/08/14 08:02 Issue 8334712 Summary Provide a standard API for parsing, generati",
      "sections": {
        "Summary": "Provide a standard API for parsing, generating, and transforming Java class files. History The Class-File API was originally proposed as a preview feature by JEP&#160;457 in JDK&#160;22 and refined by JEP&#160;466 in JDK&#160;23 . We here propose to finalize the API in JDK&#160;24 with minor changes, detailed below , based on further experience and feedback.",
        "Goals": "Provide an API for processing class files that tracks the class file format defined by the Java Virtual Machine",
        "Non-Goals": "It is not a goal to obsolete existing libraries that process class files, nor to be the world's fastest class-file library. It is not a goal to extend the Core Reflection API to give access to the bytecode of loaded classes. It is not a goal to provide code analysis functionality; that can be layered atop the Class-File API via third-party libraries.",
        "Motivation": "Class files are the lingua franca of the Java ecosystem. Parsing, generating, and transforming class files is ubiquitous because it allows independent tools and libraries to examine and extend programs without jeopardizing the maintainability of source code. For example, frameworks use on-the-fly bytecode transformation to transparently add functionality that would be impractical, if not impossible, for application developers to include in source code. The Java ecosystem has many libraries for parsing and generating class files, each with different design",
        "Description": "We have adopted the following design",
        "Alternatives": ": AccessFlags::ofClass(AccessFlag ...) AccessFlags::ofClass(int) AccessFlags::ofField(AccessFlag ...) AccessFlags::ofField(int) AccessFlags::ofMethod(AccessFlag ...) AccessFlags::ofMethod(int) BufWriter::copyTo(byte[], int) BufWriter::writeBytes(BufWriter) BufWriter::writeListIndices(List&lt;? extends PoolEntry&gt;) ClassBuilder::original() ClassFileBuilder::canWriteDirect(ConstantPool) ClassFileTransform::resolve(B) ClassReader::readClassEntry(int) ClassReader::readMethodHandleEntry(int) ClassReader::readModuleEntry(int) ClassReader::readNameAndTypeEntry(int) ClassReader::readPackageEntry(int) ClassReader::readUtf8Entry(int) ClassReader::readUtf8EntryOrNull(int) ClassTransform::resolve(ClassBuilder) CodeBuilder::loadConstant(Opcode, ConstantDesc) CodeBuilder::original() CodeRelabeler::relabel(Label, CodeBuilder) CodeTransform::resolve(CodeBuilder) CompoundElement::elements() ConstantPoolBuilder::annotationConstantValueEntry(ConstantDesc) ConstantPoolBuilder::writeBootstrapMethods(BufW",
        "Testing": "The Class-File API has a large surface area and must generate classes in conformance with the Java Virtual Machine",
        "Dependencies": "for a class dependency graph then we can simply iterate through the instructions and match on the ones we find interesting. A CodeModel describes a Code attribute; we can iterate over its CodeElement s and handle those that include symbolic references to other types: CodeModel code = ... Set&lt;ClassDesc&gt; deps = new HashSet&lt;&gt;(); for (CodeElement e : code) { switch (e) { case FieldInstruction f -&gt; deps.add(f.owner()); case InvokeInstruction i -&gt; deps.add(i.owner()); ... and so on for instanceof, cast, etc ... } } Generating class files with builders Suppose we wish to generate the following method in a class file: void fooBar(boolean z, int x) { if (z) foo(x); else bar(x); } With ASM we could generate the method as follows: ClassWriter classWriter = ...; MethodVisitor mv = classWriter.visitMethod(0, \"fooBar\", \"(ZI)V\", null, null); mv.visitCode(); mv.visitVarInsn(ILOAD, 1); Label label1 = new Label(); mv.visitJumpInsn(IFEQ, label1); mv.visitVarInsn(ALOAD, 0); mv.visitVarIn",
        "Specification": ". Enable JDK components to migrate to the standard API, and eventually remove the JDK's internal copy of the third-party ASM library."
      },
      "fullText": "JEP 484: Class-File API JEP 484: Class-File API Author Brian Goetz Owner Adam Sotona Type Feature Scope SE Status Closed&#8201;/&#8201;Delivered Release 24 Component core-libs&#8201;/&#8201;java.lang.classfile Discussion core dash libs dash dev at openjdk dot org Effort S Duration M Relates to JEP 466: Class-File API (Second Preview) Reviewed by Paul Sandoz Endorsed by Paul Sandoz Created 2024/06/21 08:36 Updated 2025/08/14 08:02 Issue 8334712 Summary Provide a standard API for parsing, generating, and transforming Java class files. History The Class-File API was originally proposed as a preview feature by JEP&#160;457 in JDK&#160;22 and refined by JEP&#160;466 in JDK&#160;23 . We here propose to finalize the API in JDK&#160;24 with minor changes, detailed below , based on further experience and feedback. Goals Provide an API for processing class files that tracks the class file format defined by the Java Virtual Machine Specification . Enable JDK components to migrate to the standard API, and eventually remove the JDK's internal copy of the third-party ASM library. Non-Goals It is not a goal to obsolete existing libraries that process class files, nor to be the world's fastest class-file library. It is not a goal to extend the Core Reflection API to give access to the bytecode of loaded classes. It is not a goal to provide code analysis functionality; that can be layered atop the Class-File API via third-party libraries. Motivation Class files are the lingua franca of the Java ecosystem. Parsing, generating, and transforming class files is ubiquitous because it allows independent tools and libraries to examine and extend programs without jeopardizing the maintainability of source code. For example, frameworks use on-the-fly bytecode transformation to transparently add functionality that would be impractical, if not impossible, for application developers to include in source code. The Java ecosystem has many libraries for parsing and generating class files, each with different design goals, strengths, and weaknesses. Frameworks that process class files generally bundle a class-file library such as ASM , BCEL , or Javassist . However, a significant problem for class-file libraries is that the class-file format is evolving more quickly than in the past, due to the six-month release cadence of the JDK. In recent years, the class-file format has evolved to support Java language features such as sealed classes and to expose JVM features such as dynamic constants and nestmates . This trend will continue with forthcoming features such as value classes and generic method specialization. Because the class-file format can evolve every six months, frameworks are more frequently encountering class files that are newer than the class-file library that they bundle. This version skew results in errors visible to application developers or, worse, in framework developers trying to write code to parse class files from the future and engaging in leaps of faith that"
    }
  },
  {
    "url": "https://openjdk.org/jeps/454",
    "title": "JEP 454: Foreign Function &amp; Memory API",
    "content": {
      "title": "JEP 454: Foreign Function &amp; Memory API",
      "summary": "JEP 454: Foreign Function &amp; Memory API JEP 454: Foreign Function &amp; Memory API Owner Maurizio Cimadamore Type Feature Scope SE Status Closed&#8201;/&#8201;Delivered Release 22 Component core-libs&#8201;/&#8201;java.lang.foreign Discussion panama dash dev at openjdk dot org Relates to JEP 472: Prepare to Restrict the Use of JNI JEP 442: Foreign Function &amp; Memory API (Third Preview) Reviewed by Alex Buckley, Jorn Vernee Endorsed by Alan Bateman Created 2023/06/22 09:36 Updated 2024/10/0",
      "sections": {
        "Summary": "Introduce an API by which Java programs can interoperate with code and data outside of the Java runtime. By efficiently invoking foreign functions (i.e., code outside the JVM), and by safely accessing foreign memory (i.e., memory not managed by the JVM), the API enables Java programs to call native libraries and process native data without the brittleness and danger of JNI. History The Foreign Function &amp; Memory (FFM) API was originally proposed as a preview feature by JEP 424 (JDK&#160;19) and subsequently refined by JEP 434 (JDK&#160;20) and JEP 442 (JDK&#160;21). This JEP proposes to finalize the FFM API with further small refinements based upon continued experience and feedback. In this version we have: Provided a new linker option allowing clients to pass heap segments to downcall method handles; Introduced the Enable-Native-Access JAR-file manifest attribute, allowing code in executable JAR files to call restricted methods without having to use the --enable-native-access comma",
        "Goals": "Productivity &#8212; Replace the brittle machinery of native methods and the Java Native Interface (JNI) with a concise, readable, and pure-Java API. Performance &#8212; Provide access to foreign functions and memory with overhead comparable to, if not better than, JNI and sun.misc.Unsafe . Broad platform support &#8212; Enable the discovery and invocation of native libraries on every platform where the JVM runs. Uniformity &#8212; Provide ways to operate on structured and unstructured data, of unlimited size, in multiple kinds of memory (e.g., native memory, persistent memory, and managed heap memory). Soundness &#8212; Guarantee no use-after-free bugs, even when memory is allocated and deallocated across multiple threads. Integrity &#8212; Allow programs to perform unsafe operations with native code and data, but warn users about such operations by default.",
        "Non-Goals": "It is not a goal to Re-implement JNI on top of this API, or otherwise change JNI in any way; Re-implement legacy Java APIs, such as sun.misc.Unsafe , on top of this API; Provide tooling that mechanically generates Java code from native-code header files; or Change how Java applications that interact with native libraries are packaged and deployed (e.g., via multi-platform JAR files).",
        "Motivation": "The Java Platform has always offered a rich foundation to library and application developers who wish to reach beyond the JVM and interact with other platforms. Java APIs expose non-Java resources conveniently and reliably, whether to access remote data (JDBC), invoke web services (HTTP client), serve remote clients (NIO channels), or communicate with local processes (Unix-domain sockets). Unfortunately, Java developers still face significant obstacles in accessing an important kind of non-Java resource: code and data on the same machine as the JVM, but outside the Java runtime. Foreign memory Objects created via the new keyword are stored in the JVM's heap , where they are subject to garbage collection when no longer needed. However, the cost and unpredictability of garbage collection is unacceptable for performance-critical libraries such as Tensorflow , Ignite , Lucene , and Netty . They need to store data outside the heap, in off-heap memory which they allocate and deallocate thems",
        "Description": "The Foreign Function &amp; Memory API (FFM API) defines classes and interfaces so that client code in libraries and applications can Control the allocation and deallocation of foreign memory ( MemorySegment , Arena , and SegmentAllocator ), Manipulate and access structured foreign memory ( MemoryLayout and VarHandle ), and Call foreign functions ( Linker , SymbolLookup , FunctionDescriptor , and MethodHandle ). The FFM API resides in the java.lang.foreign package of the java.base module. Example As a brief example of using the FFM API, here is Java code that obtains a method handle for a C library function radixsort and then uses it to sort four strings which start life in a Java array (a few details are elided). // 1. Find foreign function on the C library path Linker linker = Linker.nativeLinker(); SymbolLookup stdlib = linker.defaultLookup(); MethodHandle radixsort = linker.downcallHandle(stdlib.find(\"radixsort\"), ...); // 2. Allocate on-heap memory to store four strings String[] ja",
        "Risks and Assumptions": "Creating an API to access foreign memory in a way that is both safe and efficient is a daunting task. Since spatial and temporal bounds need to be checked upon every access, it is crucial that JIT compilers be able to optimize away these checks by, e.g., hoisting them outside of hot loops. The JIT implementations will likely require some work to ensure that uses of the API are as efficient and optimizable as uses of existing APIs such as ByteBuffer and Unsafe . The JIT implementations will also require work to ensure that uses of the native method handles produced by the API are at least as efficient and optimizable as uses of existing JNI native methods.",
        "Dependencies": "The jextract tool depends on the FFM API. It takes the header files for a native library and mechanically generates the downcall method handles required to interoperate with that library. This reduces the overhead of using native libraries from Java code. Installing Contributing Sponsoring Developers' Guide Vulnerabilities JDK GA/EA Builds Mailing lists Wiki &#183; IRC Mastodon Bluesky Bylaws &#183; Census Legal Workshop JEP Process Source code GitHub Mercurial Tools Git jtreg harness Groups (overview) Adoption Build Client Libraries Compatibility &amp;",
        "Specification": "Review Compiler Conformance Core Libraries Governing Board HotSpot IDE Tooling &amp; Support Internationalization JMX Members Networking Porters Quality Security Serviceability Vulnerability Web Projects ( overview , archive ) Amber Babylon CRaC Code Tools Coin Common VM Interface Developers' Guide Device I/O Duke Galahad Graal IcedTea JDK 8 Updates JDK 9 JDK (&#8230;, 24 , 25 , 26 ) JDK Updates JMC Jigsaw Kona Lanai Leyden Lilliput Locale Enhancement Loom Memory Model Update Metropolis Multi-Language VM Nashorn New I/O OpenJFX Panama Penrose Port: AArch32 Port: AArch64 Port: BSD Port: Haiku Port: Mac OS X Port: MIPS Port: Mobile Port: PowerPC/AIX Port: RISC-V Port: s390x SCTP Shenandoah Skara Sumatra Tsan Valhalla Verona VisualVM Wakefield Zero ZGC &#169; 2025 Oracle Corporation and/or its affiliates Terms of Use &#183; License: GPLv2 &#183; Privacy &#183; Trademarks"
      },
      "fullText": "JEP 454: Foreign Function &amp; Memory API JEP 454: Foreign Function &amp; Memory API Owner Maurizio Cimadamore Type Feature Scope SE Status Closed&#8201;/&#8201;Delivered Release 22 Component core-libs&#8201;/&#8201;java.lang.foreign Discussion panama dash dev at openjdk dot org Relates to JEP 472: Prepare to Restrict the Use of JNI JEP 442: Foreign Function &amp; Memory API (Third Preview) Reviewed by Alex Buckley, Jorn Vernee Endorsed by Alan Bateman Created 2023/06/22 09:36 Updated 2024/10/07 14:18 Issue 8310626 Summary Introduce an API by which Java programs can interoperate with code and data outside of the Java runtime. By efficiently invoking foreign functions (i.e., code outside the JVM), and by safely accessing foreign memory (i.e., memory not managed by the JVM), the API enables Java programs to call native libraries and process native data without the brittleness and danger of JNI. History The Foreign Function &amp; Memory (FFM) API was originally proposed as a preview feature by JEP 424 (JDK&#160;19) and subsequently refined by JEP 434 (JDK&#160;20) and JEP 442 (JDK&#160;21). This JEP proposes to finalize the FFM API with further small refinements based upon continued experience and feedback. In this version we have: Provided a new linker option allowing clients to pass heap segments to downcall method handles; Introduced the Enable-Native-Access JAR-file manifest attribute, allowing code in executable JAR files to call restricted methods without having to use the --enable-native-access command-line option; Enabled clients to build C-language function descriptors programmatically, avoiding platform-specific constants; Improved support for variable-length arrays in native memory; and Added support for arbitrary charsets for native strings. Goals Productivity &#8212; Replace the brittle machinery of native methods and the Java Native Interface (JNI) with a concise, readable, and pure-Java API. Performance &#8212; Provide access to foreign functions and memory with overhead comparable to, if not better than, JNI and sun.misc.Unsafe . Broad platform support &#8212; Enable the discovery and invocation of native libraries on every platform where the JVM runs. Uniformity &#8212; Provide ways to operate on structured and unstructured data, of unlimited size, in multiple kinds of memory (e.g., native memory, persistent memory, and managed heap memory). Soundness &#8212; Guarantee no use-after-free bugs, even when memory is allocated and deallocated across multiple threads. Integrity &#8212; Allow programs to perform unsafe operations with native code and data, but warn users about such operations by default. Non-goals It is not a goal to Re-implement JNI on top of this API, or otherwise change JNI in any way; Re-implement legacy Java APIs, such as sun.misc.Unsafe , on top of this API; Provide tooling that mechanically generates Java code from native-code header files; or Change how Java applications that interact with native libraries are pac"
    }
  },
  {
    "url": "https://openjdk.org/jeps/506",
    "title": "JEP 506: Scoped Values",
    "content": {
      "title": "JEP 506: Scoped Values",
      "summary": "JEP 506: Scoped Values JEP 506: Scoped Values Author Andrew Haley &amp; Andrew Dinn Owner Andrew Haley Type Feature Scope SE Status Closed&#8201;/&#8201;Delivered Release 25 Component core-libs Discussion loom dash dev at openjdk dot org Relates to JEP 487: Scoped Values (Fourth Preview) Reviewed by Alan Bateman Endorsed by Paul Sandoz Created 2025/03/24 10:10 Updated 2025/06/06 13:57 Issue 8352695 Summary Introduce scoped values , which enable a method to share immutable data both with its call",
      "sections": {
        "Summary": "Introduce scoped values , which enable a method to share immutable data both with its callees within a thread, and with child threads. Scoped values are easier to reason about than thread-local variables. They also have lower space and time costs, especially when used together with virtual threads ( JEP&#160;444 ) and structured concurrency ( JEP&#160;505 ). History The scoped values API was proposed for incubation by JEP&#160;429 (JDK&#160;20), proposed for preview by JEP&#160;446 (JDK&#160;21), and subsequently improved and refined by JEP&#160;464 (JDK&#160;22), JEP&#160;481 (JDK&#160;23), and JEP&#160;487 (JDK&#160;24). We here propose to finalize the scoped values API in JDK 25, with one small change: The ScopedValue.orElse method no longer accepts null as its argument.",
        "Goals": "Ease of use &#8212; It should be easy to reason about dataflow. Comprehensibility &#8212; The lifetime of shared data should be apparent from the syntactic structure of code. Robustness &#8212; Data shared by a caller should be retrievable only by legitimate callees. Performance &#8212; Data should be efficiently sharable across a large number of threads.",
        "Non-Goals": "It is not a goal to change the Java programming language. It is not a goal to require migration away from thread-local variables, or to deprecate the existing ThreadLocal API.",
        "Motivation": "Java applications and libraries are structured as collections of classes which contain methods. These methods communicate through method calls. Most methods allow a caller to pass data to a method by passing the data as parameters. When method A wants method B to do some work for it, it invokes B with the appropriate parameters, and B may pass some of those parameters to C , and so forth. B may have to include in its parameter list not only the things B directly needs but also the things B has to pass to C . For example, if B is going to set up and execute a database call, it might want a Connection passed in, even if B is not going to use the Connection directly. Most of the time this \"pass what your indirect callees need\" approach is the most effective and convenient way to share data. However, sometimes it is impractical to pass all the data that every indirect callee might need in the initial call. An example It is a common pattern in large Java programs to transfer control from on",
        "Description": "A scoped value is a container object that allows a data value to be safely and efficiently shared by a method with its direct and indirect callees within the same thread, and with child threads, without resorting to method parameters. It is a variable of type ScopedValue . It is typically declared as a static final field, and its accessibility is set to private so that it cannot be directly accessed by code in other classes. Like a thread-local variable, a scoped value has multiple values associated with it, one per thread. The particular value that is used depends on which thread calls its methods. Unlike a thread-local variable, a scoped value is written once, and is available only for a bounded period during execution of the thread. A scoped value is used as shown below. Some code calls ScopedValue.where , presenting a scoped value and the object to which it is to be bound. A chained call of the run method binds the scoped value, providing a copy that is specific to the current thre",
        "Alternatives": "It is possible to emulate many of the features of scoped values with thread-local variables, albeit at some cost in memory footprint, security, and performance. We experimented with a modified version of ThreadLocal that supports some of the characteristics of scoped values. However, carrying the additional baggage of thread-local variables results in an implementation that is unduly burdensome, or an API that returns UnsupportedOperationException for much of its core functionality, or both. It is better, therefore, not to modify ThreadLocal but to introduce scoped values as an entirely separate concept. We also experimented with a version of scoped-value binding that supports the AutoCloseable interface, and so could be used in a try -with-resources construct. We ultimately rejected that idea because it is impossible to guarantee correct operation when relying on user code to invoke the close method at the right time. Also, even if that method is invoked as designed, by a try -with-re",
        "Specification": "Review Compiler Conformance Core Libraries Governing Board HotSpot IDE Tooling &amp; Support Internationalization JMX Members Networking Porters Quality Security Serviceability Vulnerability Web Projects ( overview , archive ) Amber Babylon CRaC Code Tools Coin Common VM Interface Developers' Guide Device I/O Duke Galahad Graal IcedTea JDK 8 Updates JDK 9 JDK (&#8230;, 24 , 25 , 26 ) JDK Updates JMC Jigsaw Kona Lanai Leyden Lilliput Locale Enhancement Loom Memory Model Update Metropolis Multi-Language VM Nashorn New I/O OpenJFX Panama Penrose Port: AArch32 Port: AArch64 Port: BSD Port: Haiku Port: Mac OS X Port: MIPS Port: Mobile Port: PowerPC/AIX Port: RISC-V Port: s390x SCTP Shenandoah Skara Sumatra Tsan Valhalla Verona VisualVM Wakefield Zero ZGC &#169; 2025 Oracle Corporation and/or its affiliates Terms of Use &#183; License: GPLv2 &#183; Privacy &#183; Trademarks"
      },
      "fullText": "JEP 506: Scoped Values JEP 506: Scoped Values Author Andrew Haley &amp; Andrew Dinn Owner Andrew Haley Type Feature Scope SE Status Closed&#8201;/&#8201;Delivered Release 25 Component core-libs Discussion loom dash dev at openjdk dot org Relates to JEP 487: Scoped Values (Fourth Preview) Reviewed by Alan Bateman Endorsed by Paul Sandoz Created 2025/03/24 10:10 Updated 2025/06/06 13:57 Issue 8352695 Summary Introduce scoped values , which enable a method to share immutable data both with its callees within a thread, and with child threads. Scoped values are easier to reason about than thread-local variables. They also have lower space and time costs, especially when used together with virtual threads ( JEP&#160;444 ) and structured concurrency ( JEP&#160;505 ). History The scoped values API was proposed for incubation by JEP&#160;429 (JDK&#160;20), proposed for preview by JEP&#160;446 (JDK&#160;21), and subsequently improved and refined by JEP&#160;464 (JDK&#160;22), JEP&#160;481 (JDK&#160;23), and JEP&#160;487 (JDK&#160;24). We here propose to finalize the scoped values API in JDK 25, with one small change: The ScopedValue.orElse method no longer accepts null as its argument. Goals Ease of use &#8212; It should be easy to reason about dataflow. Comprehensibility &#8212; The lifetime of shared data should be apparent from the syntactic structure of code. Robustness &#8212; Data shared by a caller should be retrievable only by legitimate callees. Performance &#8212; Data should be efficiently sharable across a large number of threads. Non-Goals It is not a goal to change the Java programming language. It is not a goal to require migration away from thread-local variables, or to deprecate the existing ThreadLocal API. Motivation Java applications and libraries are structured as collections of classes which contain methods. These methods communicate through method calls. Most methods allow a caller to pass data to a method by passing the data as parameters. When method A wants method B to do some work for it, it invokes B with the appropriate parameters, and B may pass some of those parameters to C , and so forth. B may have to include in its parameter list not only the things B directly needs but also the things B has to pass to C . For example, if B is going to set up and execute a database call, it might want a Connection passed in, even if B is not going to use the Connection directly. Most of the time this \"pass what your indirect callees need\" approach is the most effective and convenient way to share data. However, sometimes it is impractical to pass all the data that every indirect callee might need in the initial call. An example It is a common pattern in large Java programs to transfer control from one component (a \"framework\") to another (\"application code\") and then back. For example, a web framework could accept incoming HTTP requests and then call an application handler to handle it. The application handler may then call the framework t"
    }
  },
  {
    "url": "https://openjdk.org/jeps/485",
    "title": "JEP 485: Stream Gatherers",
    "content": {
      "title": "JEP 485: Stream Gatherers",
      "summary": "JEP 485: Stream Gatherers JEP 485: Stream Gatherers Owner Viktor Klang Type Feature Scope SE Status Closed&#8201;/&#8201;Delivered Release 24 Component core-libs&#8201;/&#8201;java.util.stream Discussion core dash libs dash dev at openjdk dot org Effort M Duration M Relates to JEP 473: Stream Gatherers (Second Preview) Reviewed by Alan Bateman, Paul Sandoz Endorsed by Paul Sandoz Created 2024/07/08 15:42 Updated 2025/06/12 14:49 Issue 8335899 Summary Enhance the Stream API to support custom inte",
      "sections": {
        "Summary": "Enhance the Stream API to support custom intermediate operations. This will allow stream pipelines to transform data in ways that are not easily achievable with the existing built-in intermediate operations. History Stream Gatherers were proposed as a preview feature by JEP 461 in JDK&#160;22 and re-previewed by JEP 473 in JDK&#160;23. We here propose to finalize the API in JDK&#160;24, without change.",
        "Goals": "Make stream pipelines more flexible and expressive. Insofar as possible, allow custom intermediate operations to manipulate streams of infinite size.",
        "Non-Goals": "It is not a goal to change the Java programming language to better facilitate stream processing. It is not a goal to special-case the compilation of code that uses the Stream&#160;API.",
        "Motivation": "Java 8 introduced the first API designed specifically for lambda expressions: the Stream API, java.util.stream . A stream is a lazily computed, potentially unbounded sequence of values. The API supports the ability to process a stream either sequentially or in parallel. A stream pipeline consists of three parts: a source of elements, any number of intermediate operations, and a terminal operation. For example: long numberOfWords = Stream.of(\"the\", \"\", \"fox\", \"jumps\", \"over\", \"the\", \"\", \"dog\") // (1) .filter(Predicate.not(String::isEmpty)) // (2) .collect(Collectors.counting()); // (3) This programming style is both expressive and efficient. With the builder-style API, each intermediate operation returns a new stream; evaluation begins only when a terminal operation is invoked. In this example, line (1) creates a stream, but does not evaluate it, line (2) sets up an intermediate filter operation but still does not evaluate the stream, and finally the terminal collect operation on line (",
        "Description": "Stream::gather(Gatherer) is a new intermediate stream operation that processes the elements of a stream by applying a user-defined entity called a gatherer . With the gather operation we can build efficient, parallel-ready streams that implement almost any intermediate operation. Stream::gather(Gatherer) is to intermediate operations what Stream::collect(Collector) is to terminal operations. A gatherer represents a transform of the elements of a stream; it is an instance of the java.util.stream.Gatherer interface. Gatherers can transform elements in a one-to-one, one-to-many, many-to-one, or many-to-many fashion. They can track previously seen elements in order to influence the transformation of later elements, they can short-circuit in order to transform infinite streams to finite ones, and they can enable parallel execution. For example, a gatherer can transform one input element to one output element until some condition becomes true, at which time it starts to transform one input e",
        "Alternatives": "We explored",
        "Risks and Assumptions": "The use of custom gatherers, and of the built-in gatherers declared in the Gatherers class, will not be as succinct as the use of the built-in intermediate operations declared in the Stream class. The definition of custom gatherers will, however, be similar in complexity to the definition of custom collectors for terminal collect operations. The use of both custom and built-in gatherers will, moreover, be similar in complexity to the use of custom collectors and the built-in collectors declared in the Collectors class. We might revise the set of built-in gatherers over the course of previewing this feature, and we might revise the set of built-in gatherers in future releases. We will not add a new intermediate operation to the Stream class for each of the built-in gatherers defined in the Gatherers class, even though for the sake of uniformity it is tempting to do so. In order to preserve the learnability of the Stream class we will consider adding new intermediate operations to it onl",
        "Specification": "Review Compiler Conformance Core Libraries Governing Board HotSpot IDE Tooling &amp; Support Internationalization JMX Members Networking Porters Quality Security Serviceability Vulnerability Web Projects ( overview , archive ) Amber Babylon CRaC Code Tools Coin Common VM Interface Developers' Guide Device I/O Duke Galahad Graal IcedTea JDK 8 Updates JDK 9 JDK (&#8230;, 24 , 25 , 26 ) JDK Updates JMC Jigsaw Kona Lanai Leyden Lilliput Locale Enhancement Loom Memory Model Update Metropolis Multi-Language VM Nashorn New I/O OpenJFX Panama Penrose Port: AArch32 Port: AArch64 Port: BSD Port: Haiku Port: Mac OS X Port: MIPS Port: Mobile Port: PowerPC/AIX Port: RISC-V Port: s390x SCTP Shenandoah Skara Sumatra Tsan Valhalla Verona VisualVM Wakefield Zero ZGC &#169; 2025 Oracle Corporation and/or its affiliates Terms of Use &#183; License: GPLv2 &#183; Privacy &#183; Trademarks"
      },
      "fullText": "JEP 485: Stream Gatherers JEP 485: Stream Gatherers Owner Viktor Klang Type Feature Scope SE Status Closed&#8201;/&#8201;Delivered Release 24 Component core-libs&#8201;/&#8201;java.util.stream Discussion core dash libs dash dev at openjdk dot org Effort M Duration M Relates to JEP 473: Stream Gatherers (Second Preview) Reviewed by Alan Bateman, Paul Sandoz Endorsed by Paul Sandoz Created 2024/07/08 15:42 Updated 2025/06/12 14:49 Issue 8335899 Summary Enhance the Stream API to support custom intermediate operations. This will allow stream pipelines to transform data in ways that are not easily achievable with the existing built-in intermediate operations. History Stream Gatherers were proposed as a preview feature by JEP 461 in JDK&#160;22 and re-previewed by JEP 473 in JDK&#160;23. We here propose to finalize the API in JDK&#160;24, without change. Goals Make stream pipelines more flexible and expressive. Insofar as possible, allow custom intermediate operations to manipulate streams of infinite size. Non-Goals It is not a goal to change the Java programming language to better facilitate stream processing. It is not a goal to special-case the compilation of code that uses the Stream&#160;API. Motivation Java 8 introduced the first API designed specifically for lambda expressions: the Stream API, java.util.stream . A stream is a lazily computed, potentially unbounded sequence of values. The API supports the ability to process a stream either sequentially or in parallel. A stream pipeline consists of three parts: a source of elements, any number of intermediate operations, and a terminal operation. For example: long numberOfWords = Stream.of(\"the\", \"\", \"fox\", \"jumps\", \"over\", \"the\", \"\", \"dog\") // (1) .filter(Predicate.not(String::isEmpty)) // (2) .collect(Collectors.counting()); // (3) This programming style is both expressive and efficient. With the builder-style API, each intermediate operation returns a new stream; evaluation begins only when a terminal operation is invoked. In this example, line (1) creates a stream, but does not evaluate it, line (2) sets up an intermediate filter operation but still does not evaluate the stream, and finally the terminal collect operation on line (3) evaluates the entire stream pipeline. The Stream API provides a reasonably rich, albeit fixed, set of intermediate and terminal operations: mapping, filtering, reduction, sorting, and so forth. It also includes an extensible terminal operation, Stream::collect , which enables the output of a pipeline to be summarized in a variety of ways. The use of streams in the Java ecosystem is by now pervasive, and ideal for many tasks, but the fixed set of intermediate operations means that some complex tasks cannot easily be expressed as stream pipelines. Either a required intermediate operation does not exist, or it exists but does not directly support the task. As an example, suppose the task is to take a stream of strings and make it distinct, but with distinctness based"
    }
  },
  {
    "url": "https://openjdk.org/jeps/472",
    "title": "JEP 472: Prepare to Restrict the Use of JNI",
    "content": {
      "title": "JEP 472: Prepare to Restrict the Use of JNI",
      "summary": "JEP 472: Prepare to Restrict the Use of JNI JEP 472: Prepare to Restrict the Use of JNI Author Ron Pressler &amp; Alex Buckley Owner Ron Pressler Type Feature Scope SE Status Closed&#8201;/&#8201;Delivered Release 24 Component core-libs Discussion jdk dash dev at openjdk dot org Relates to JEP 454: Foreign Function &amp; Memory API Reviewed by Dan Heidinga, Jorn Vernee, Mark Reinhold, Maurizio Cimadamore Endorsed by Alan Bateman Created 2023/05/03 09:08 Updated 2025/07/16 16:11 Issue 8307341 Sum",
      "sections": {
        "Summary": "Issue warnings about uses of the Java Native Interface (JNI) and adjust the Foreign Function &amp; Memory (FFM) API to issue warnings in a consistent manner. All such warnings aim to prepare developers for a future release that ensures integrity by default by uniformly restricting JNI and the FFM API. Application developers can avoid both current warnings and future restrictions by selectively enabling these interfaces where essential.",
        "Goals": "Preserve the status of JNI as a standard way to interoperate with native code. Prepare the Java ecosystem for a future release that disallows interoperation with native code by default, whether via JNI or the FFM API. As of that release, application developers will have to explicitly enable the use of JNI and the FFM API at startup. Align the use of JNI and the FFM API so that library maintainers can migrate from one to the other without requiring application developers to change any command-line options.",
        "Non-Goals": "It is not a goal to deprecate JNI or to remove JNI from the Java Platform. It is not a goal to restrict the behavior of native code called via JNI. For example, all of the native JNI functions will remain usable by native code.",
        "Motivation": "The Java Native Interface (JNI) was introduced in JDK&#160;1.1 as the primary means for interoperating between Java code and native code, typically written in C. JNI allows Java code to call native code (a downcall ) and native code to call Java code (an upcall ). Unfortunately, any interaction at all between Java code and native code is risky because it can compromise the integrity of applications and of the Java Platform itself. According to the policy of integrity by default , all JDK features that are capable of breaking integrity must obtain explicit approval from the application's developer. Here are four common interactions and their risks: Calling native code can lead to arbitrary undefined behavior , including JVM crashes. Such problems cannot be prevented by the Java runtime, nor do they provoke exceptions for Java code to catch. For example, this C function takes a long value passed from Java code and treats it as an address in memory, storing a value at that address: void J",
        "Description": "In JDK 22 and later releases, you can call native code via the Java Native Interface (JNI) or the Foreign Function &amp; Memory (FFM) API. In either case, you must first load a native library and link a Java construct to a function in the library. These loading and linking steps are restricted in the FFM API, which means that they cause a warning to be issued at run time by default. In JDK&#160;24, we will restrict the loading and linking steps in JNI so that they also cause a warning to be issued at run time by default. We refer to restrictions on loading and linking native libraries as native access restrictions . In JDK&#160;24, native access restrictions will apply uniformly whether JNI or the FFM API is used to load and link native libraries. The exact operations that load and link native libraries in JNI, which are now subject to native access restrictions, are described later . We will strengthen the effect of native access restrictions over time. Rather than issue warnings, a f",
        "Alternatives": "Rather than restrict the loading of native libraries and the binding of native methods, the JVM could apply access control rules when native code uses JNI functions to access Java fields and methods. However, this is insufficient to maintain integrity because any use of native code can lead to undefined behavior, whether or not it uses JNI functions. Portions of the FFM API are restricted for the same reason, even though the FFM API does not offer access to Java objects from native code. Installing Contributing Sponsoring Developers' Guide Vulnerabilities JDK GA/EA Builds Mailing lists Wiki &#183; IRC Mastodon Bluesky Bylaws &#183; Census Legal Workshop JEP Process Source code GitHub Mercurial Tools Git jtreg harness Groups (overview) Adoption Build Client Libraries Compatibility &amp;",
        "Risks and Assumptions": "JNI has been part of the Java Platform since JDK 1.1, so there is a risk that existing applications will be impacted by restrictions on the use of JNI. An analysis of artifacts on Maven Central found that about 7% of existing artifacts depend on native code. Of these, about 25% use JNI directly; the remainder depend on some other artifact that uses JNI, either directly or indirectly. We assume that developers whose applications rely directly or indirectly on native code will be able to configure the Java runtime to enable the use of JNI via --enable-native-access , as described above . This is similar to how they can already configure the Java runtime to disable strong encapsulation for modules, via --add-opens .",
        "Specification": "Review Compiler Conformance Core Libraries Governing Board HotSpot IDE Tooling &amp; Support Internationalization JMX Members Networking Porters Quality Security Serviceability Vulnerability Web Projects ( overview , archive ) Amber Babylon CRaC Code Tools Coin Common VM Interface Developers' Guide Device I/O Duke Galahad Graal IcedTea JDK 8 Updates JDK 9 JDK (&#8230;, 24 , 25 , 26 ) JDK Updates JMC Jigsaw Kona Lanai Leyden Lilliput Locale Enhancement Loom Memory Model Update Metropolis Multi-Language VM Nashorn New I/O OpenJFX Panama Penrose Port: AArch32 Port: AArch64 Port: BSD Port: Haiku Port: Mac OS X Port: MIPS Port: Mobile Port: PowerPC/AIX Port: RISC-V Port: s390x SCTP Shenandoah Skara Sumatra Tsan Valhalla Verona VisualVM Wakefield Zero ZGC &#169; 2025 Oracle Corporation and/or its affiliates Terms of Use &#183; License: GPLv2 &#183; Privacy &#183; Trademarks"
      },
      "fullText": "JEP 472: Prepare to Restrict the Use of JNI JEP 472: Prepare to Restrict the Use of JNI Author Ron Pressler &amp; Alex Buckley Owner Ron Pressler Type Feature Scope SE Status Closed&#8201;/&#8201;Delivered Release 24 Component core-libs Discussion jdk dash dev at openjdk dot org Relates to JEP 454: Foreign Function &amp; Memory API Reviewed by Dan Heidinga, Jorn Vernee, Mark Reinhold, Maurizio Cimadamore Endorsed by Alan Bateman Created 2023/05/03 09:08 Updated 2025/07/16 16:11 Issue 8307341 Summary Issue warnings about uses of the Java Native Interface (JNI) and adjust the Foreign Function &amp; Memory (FFM) API to issue warnings in a consistent manner. All such warnings aim to prepare developers for a future release that ensures integrity by default by uniformly restricting JNI and the FFM API. Application developers can avoid both current warnings and future restrictions by selectively enabling these interfaces where essential. Goals Preserve the status of JNI as a standard way to interoperate with native code. Prepare the Java ecosystem for a future release that disallows interoperation with native code by default, whether via JNI or the FFM API. As of that release, application developers will have to explicitly enable the use of JNI and the FFM API at startup. Align the use of JNI and the FFM API so that library maintainers can migrate from one to the other without requiring application developers to change any command-line options. Non-Goals It is not a goal to deprecate JNI or to remove JNI from the Java Platform. It is not a goal to restrict the behavior of native code called via JNI. For example, all of the native JNI functions will remain usable by native code. Motivation The Java Native Interface (JNI) was introduced in JDK&#160;1.1 as the primary means for interoperating between Java code and native code, typically written in C. JNI allows Java code to call native code (a downcall ) and native code to call Java code (an upcall ). Unfortunately, any interaction at all between Java code and native code is risky because it can compromise the integrity of applications and of the Java Platform itself. According to the policy of integrity by default , all JDK features that are capable of breaking integrity must obtain explicit approval from the application's developer. Here are four common interactions and their risks: Calling native code can lead to arbitrary undefined behavior , including JVM crashes. Such problems cannot be prevented by the Java runtime, nor do they provoke exceptions for Java code to catch. For example, this C function takes a long value passed from Java code and treats it as an address in memory, storing a value at that address: void Java_pkg_C_setPointerToThree__J(jlong ptr) { *(int*)ptr = 3; } Calling this C function could corrupt memory used by the JVM, causing the JVM to crash at an unpredictable time, long after the C function returns. Such crashes, and other unexpected behaviors, are difficult to diagnose. Native"
    }
  },
  {
    "url": "https://openjdk.org/jeps/498",
    "title": "JEP 498: Warn upon Use of Memory-Access Methods in sun.misc.Unsafe",
    "content": {
      "title": "JEP 498: Warn upon Use of Memory-Access Methods in sun.misc.Unsafe",
      "summary": "JEP 498: Warn upon Use of Memory-Access Methods in sun.misc.Unsafe JEP 498: Warn upon Use of Memory-Access Methods in sun.misc.Unsafe Author Ron Pressler &amp; Alex Buckley Owner Ron Pressler Type Feature Scope JDK Status Closed&#8201;/&#8201;Delivered Release 24 Component core-libs Discussion jdk dash dev at openjdk dot org Effort S Duration S Relates to JEP 471: Deprecate the Memory-Access Methods in sun.misc.Unsafe for Removal Reviewed by Alan Bateman Endorsed by Alan Bateman Created 2024/10/",
      "sections": {
        "Summary": "Issue a warning at run time on the first occasion that any memory-access method in sun.misc.Unsafe is invoked. All of these unsupported methods were terminally deprecated in JDK&#160;23. They have been superseded by standard APIs, namely the VarHandle API ( JEP&#160;193 , JDK&#160;9) and the Foreign Function &amp; Memory API ( JEP&#160;454 , JDK&#160;22). We strongly encourage library developers to migrate from sun.misc.Unsafe to supported replacements, so that applications can migrate smoothly to modern JDK releases. History This JEP is the successor of JEP 471 (JDK&#160;23), which deprecated the memory-access methods in sun.misc.Unsafe for removal in a future release and described a gradual process of removal. The",
        "Goals": ",",
        "Non-Goals": ",",
        "Motivation": ", and",
        "Description": "We are deprecating and removing the memory-access methods in sun.misc.Unsafe in phases: JDK 23 deprecated all of the memory-access methods for removal . This caused compile-time deprecation warnings for code that refers to the methods, alerting library developers to their forthcoming removal. JDK 24 will, by default, issue a warning on the first occasion that any memory-access method is used, whether directly or via reflection. That is, it will issue at most one warning regardless of which memory-access methods are used and how many times any particular method is used. This will alert application developers and users to the forthcoming removal of the methods, and the need to upgrade libraries. An example of the warning is: WARNING: A terminally deprecated method in sun.misc.Unsafe has been called WARNING: sun.misc.Unsafe::setMemory has been called by com.foo.bar.Server (file:/tmp/foobarserver/thing.jar) WARNING: Please consider reporting this to the maintainers of com.foo.bar.Server WA",
        "Alternatives": ". Over the past several years, we have introduced two standard APIs that are safe and performant replacements for the memory-access methods in sun.misc.Unsafe : java.lang.invoke.VarHandle , introduced in JDK&#160;9 ( JEP&#160;193 ), provides methods to safely and efficiently manipulate on-heap memory, i.e., fields of objects, static fields of classes, and elements of arrays. java.lang.foreign.MemorySegment , introduced in JDK&#160;22 ( JEP&#160;454 ), provides methods to safely and efficiently access off-heap memory, sometimes in cooperation with VarHandle . These standard APIs guarantee no undefined behavior, promise long-term stability, and have high-quality integration with the tooling and documentation of the Java Platform. (Examples of their use are given in JEP&#160;471 .) Given the availability of these APIs, it is now appropriate to deprecate and eventually remove the memory-access methods in sun.misc.Unsafe . Removing the memory-access methods in sun.misc.Unsafe is part of a l",
        "Risks and Assumptions": "sections of this JEP are essentially identical to that of JEP&#160;471.",
        "Specification": "Review Compiler Conformance Core Libraries Governing Board HotSpot IDE Tooling &amp; Support Internationalization JMX Members Networking Porters Quality Security Serviceability Vulnerability Web Projects ( overview , archive ) Amber Babylon CRaC Code Tools Coin Common VM Interface Developers' Guide Device I/O Duke Galahad Graal IcedTea JDK 8 Updates JDK 9 JDK (&#8230;, 24 , 25 , 26 ) JDK Updates JMC Jigsaw Kona Lanai Leyden Lilliput Locale Enhancement Loom Memory Model Update Metropolis Multi-Language VM Nashorn New I/O OpenJFX Panama Penrose Port: AArch32 Port: AArch64 Port: BSD Port: Haiku Port: Mac OS X Port: MIPS Port: Mobile Port: PowerPC/AIX Port: RISC-V Port: s390x SCTP Shenandoah Skara Sumatra Tsan Valhalla Verona VisualVM Wakefield Zero ZGC &#169; 2025 Oracle Corporation and/or its affiliates Terms of Use &#183; License: GPLv2 &#183; Privacy &#183; Trademarks"
      },
      "fullText": "JEP 498: Warn upon Use of Memory-Access Methods in sun.misc.Unsafe JEP 498: Warn upon Use of Memory-Access Methods in sun.misc.Unsafe Author Ron Pressler &amp; Alex Buckley Owner Ron Pressler Type Feature Scope JDK Status Closed&#8201;/&#8201;Delivered Release 24 Component core-libs Discussion jdk dash dev at openjdk dot org Effort S Duration S Relates to JEP 471: Deprecate the Memory-Access Methods in sun.misc.Unsafe for Removal Reviewed by Alan Bateman Endorsed by Alan Bateman Created 2024/10/14 17:42 Updated 2025/03/03 15:21 Issue 8342077 Summary Issue a warning at run time on the first occasion that any memory-access method in sun.misc.Unsafe is invoked. All of these unsupported methods were terminally deprecated in JDK&#160;23. They have been superseded by standard APIs, namely the VarHandle API ( JEP&#160;193 , JDK&#160;9) and the Foreign Function &amp; Memory API ( JEP&#160;454 , JDK&#160;22). We strongly encourage library developers to migrate from sun.misc.Unsafe to supported replacements, so that applications can migrate smoothly to modern JDK releases. History This JEP is the successor of JEP 471 (JDK&#160;23), which deprecated the memory-access methods in sun.misc.Unsafe for removal in a future release and described a gradual process of removal. The Goals, Non-Goals, Motivation, and Risks and Assumptions sections of this JEP are essentially identical to that of JEP&#160;471. Goals Prepare the ecosystem for the removal of the memory-access methods in sun.misc.Unsafe in a future JDK release. Notify developers when their applications use, directly or indirectly, the memory-access methods in sun.misc.Unsafe . Non-Goals It is not a goal to issue warnings upon use of any member of the sun.misc.Unsafe class. A small number of its methods are not used for memory access; these will be deprecated and removed separately. Motivation The sun.misc.Unsafe class was introduced in 2002 as a way for Java classes in the JDK to perform low-level operations. Most of its methods &#8212; 79 out of 87 &#8212; are for accessing memory, either in the JVM's garbage-collected heap or in off-heap memory, which is not controlled by the JVM. As the name of the class suggests, these memory-access methods are unsafe: They can lead to undefined behavior, including JVM crashes. Therefore, they were not exposed as a standard API. They were neither envisaged for use by a broad range of clients nor intended to be permanent. Rather, they were introduced with the assumption that they were exclusively for use within the JDK, and that callers within the JDK would perform exhaustive safety checks before using them, and that safe standard APIs for this functionality would eventually be added to the Java Platform. However, with no way in 2002 to prevent sun.misc.Unsafe from being used outside the JDK, its memory-access methods became a handy tool for library developers who wanted more power and performance than standard APIs could offer. For example, sun.misc.Unsafe::compareAndS"
    }
  },
  {
    "url": "https://openjdk.org/jeps/510",
    "title": "JEP 510: Key Derivation Function API",
    "content": {
      "title": "JEP 510: Key Derivation Function API",
      "summary": "JEP 510: Key Derivation Function API JEP 510: Key Derivation Function API Owner Kevin Driver Type Feature Scope SE Status Closed&#8201;/&#8201;Delivered Release 25 Component security-libs&#8201;/&#8201;javax.crypto Discussion security dash dev at openjdk dot org Effort XS Duration XS Relates to JEP 478: Key Derivation Function API (Preview) Reviewed by Sean Mullan Endorsed by Sean Mullan Created 2025/03/31 14:08 Updated 2025/07/21 13:50 Issue 8353275 Summary Introduce an API for Key Derivation F",
      "sections": {
        "Summary": "Introduce an API for Key Derivation Functions (KDFs), which are cryptographic algorithms for deriving additional keys from a secret key and other data. History We proposed the KDF API as a preview feature in JEP 478 and delivered it in JDK&#160;24. We here propose to finalize the API in JDK&#160;25, without change.",
        "Goals": "Enable applications to use KDF algorithms such as the HMAC-based Extract-and-Expand Key Derivation Function (HKDF, RFC 5869 ) and Argon2&#160;( RFC 9106 ). Enable the use of KDFs in Key Encapsulation Mechanism (KEM, JEP&#160;452 ) implementations such as ML-KEM , in higher level protocols such as Hybrid Key Exchange in TLS 1.3 , and in cryptographic schemes such as Hybrid Public Key Encryption (HPKE, RFC 9180 ). Enable a PKCS#11 implementation of HKDF in the JDK. Enable an implementation of Hybrid Public Key Encryption (HPKE) in the JDK to use KDFs in its key schedule setup and secret export. Enable a refactoring of the TLS&#160;1.3 and DHKEM implementations in the JDK to use the KDF API rather than an internal HKDF implementation. Allow security providers to implement KDF algorithms in either Java code or native code. Include an implementation of HKDF and introduce additional HKDF-specific APIs.",
        "Non-Goals": "It is not a goal to make the existing implementations of the Password-Based Key Derivation Functions PBKDF1 and PBKDF2 available via the new KDF API. These implementations will remain available via the existing SecretKeyFactory API.",
        "Motivation": "Key Derivation Functions (KDFs) make use of cryptographic inputs, such as initial key material, a salt value, and a pseudorandom function, to create new cryptographically strong key material. A KDF is often used to create cryptographic data from which multiple keys can be obtained. A KDF allows keys to be created in a manner that is both secure and reproducible by two parties sharing knowledge of the inputs. Deriving keys is similar to hashing passwords. A KDF uses a keyed hash along with additional entropy from its other inputs to either extract new key material or securely expand values into a larger stream of key material. With the advent of quantum computing, classical cryptographic algorithms will increasingly be vulnerable to practical attacks. It is therefore critical for the Java Platform to support Post-Quantum Cryptography (PQC) , which is resistant to these attacks. We aim to do so eventually by supporting Hybrid Public Key Encryption (HPKE), which enables the smooth transit",
        "Description": "A key derivation function has two fundamental operations: Instantiation and initialization , which creates the KDF and initializes it with the appropriate parameters, and Derivation , which accepts key material and other optional inputs as well as parameters to describe the output, and then generates the derived key or data. We define a new class, javax.crypto.KDF , to represent key derivation functions. Instantiation and initialization The KDF class provides the usual suite of getInstance methods with the usual combinations of parameters, including optional KDFParameters and crypto provider names. The getInstance methods both instantiate a KDF and initialize its algorithm. The HKDF algorithm, which is the only KDF we intend to include at this time, does not require a KDFParameters object. Other algorithms, however, such as SHAKE , may need it. Derivation The KDF class defines two methods for deriving keys: deriveKey(String alg, AlgorithmParameterSpec spec ) constructs a SecretKey obje",
        "Alternatives": "Use existing APIs &#8212; We considered using the existing KeyGenerator and SecretKeyFactory APIs to represent KDFs. Earlier key derivation algorithms such as TLS-PRF, PBKDF1, and PBKDF2 have been made to fit into these APIs, but in general these APIs do not work well for KDFs. KeyGenerator is designed around the introduction of entropy, via a SecureRandom object, to create a non-deterministic key from a set of inputs. KDFs, by contrast, support the independent derivation by two separate parties of the same key material. SecretKeyFactory is designed for the creation of a single key. Though there are scenarios in which a KDF may be used in this manner, KDFs are also required to support successive derivations from a key stream in a deterministic fashion. Make PBKDF2 available via the new KDF API &#8212; PBKDF2 is rapidly being replaced by stronger algorithms, such as Argon2. Developers who use PBKDF2 already will likely continue to use it via the SecretKeyFactory API, rather than refacto",
        "Testing": "We will add RFC 5869 known-answer (KAT) tests, if available, along with tests for exception handling and SSL/TLS regression",
        "Specification": "AlgorithmParameterSpec params = HKDFParameterSpec.ofExtract() .addIKM(initialKeyMaterial) .addSalt(salt).thenExpand(info, 32); // Derive a 32-byte AES key SecretKey key = hkdf.deriveKey(\"AES\", params); // Additional deriveKey calls can be made with the same KDF object Implementing KDF providers A KDF implementation must extend the abstract class javax.crypto.KDFSpi . Some KDF algorithms derive multiple cryptographic keys in a single derivation operation. If you are implementing such an algorithm, we recommend that you either provide a SecretKey subclass with methods that provide access to each key, or else return all of the keys in a single byte array and document how to separate them. Future Work Implement Argon2 &#8212; We intend eventually to implement the Argon2 password-hashing KDF."
      },
      "fullText": "JEP 510: Key Derivation Function API JEP 510: Key Derivation Function API Owner Kevin Driver Type Feature Scope SE Status Closed&#8201;/&#8201;Delivered Release 25 Component security-libs&#8201;/&#8201;javax.crypto Discussion security dash dev at openjdk dot org Effort XS Duration XS Relates to JEP 478: Key Derivation Function API (Preview) Reviewed by Sean Mullan Endorsed by Sean Mullan Created 2025/03/31 14:08 Updated 2025/07/21 13:50 Issue 8353275 Summary Introduce an API for Key Derivation Functions (KDFs), which are cryptographic algorithms for deriving additional keys from a secret key and other data. History We proposed the KDF API as a preview feature in JEP 478 and delivered it in JDK&#160;24. We here propose to finalize the API in JDK&#160;25, without change. Goals Enable applications to use KDF algorithms such as the HMAC-based Extract-and-Expand Key Derivation Function (HKDF, RFC 5869 ) and Argon2&#160;( RFC 9106 ). Enable the use of KDFs in Key Encapsulation Mechanism (KEM, JEP&#160;452 ) implementations such as ML-KEM , in higher level protocols such as Hybrid Key Exchange in TLS 1.3 , and in cryptographic schemes such as Hybrid Public Key Encryption (HPKE, RFC 9180 ). Enable a PKCS#11 implementation of HKDF in the JDK. Enable an implementation of Hybrid Public Key Encryption (HPKE) in the JDK to use KDFs in its key schedule setup and secret export. Enable a refactoring of the TLS&#160;1.3 and DHKEM implementations in the JDK to use the KDF API rather than an internal HKDF implementation. Allow security providers to implement KDF algorithms in either Java code or native code. Include an implementation of HKDF and introduce additional HKDF-specific APIs. Non-Goals It is not a goal to make the existing implementations of the Password-Based Key Derivation Functions PBKDF1 and PBKDF2 available via the new KDF API. These implementations will remain available via the existing SecretKeyFactory API. Motivation Key Derivation Functions (KDFs) make use of cryptographic inputs, such as initial key material, a salt value, and a pseudorandom function, to create new cryptographically strong key material. A KDF is often used to create cryptographic data from which multiple keys can be obtained. A KDF allows keys to be created in a manner that is both secure and reproducible by two parties sharing knowledge of the inputs. Deriving keys is similar to hashing passwords. A KDF uses a keyed hash along with additional entropy from its other inputs to either extract new key material or securely expand values into a larger stream of key material. With the advent of quantum computing, classical cryptographic algorithms will increasingly be vulnerable to practical attacks. It is therefore critical for the Java Platform to support Post-Quantum Cryptography (PQC) , which is resistant to these attacks. We aim to do so eventually by supporting Hybrid Public Key Encryption (HPKE), which enables the smooth transition to quantum-safe encryption algorithms. The KEM"
    }
  },
  {
    "url": "https://openjdk.org/jeps/486",
    "title": "JEP 486: Permanently Disable the Security Manager",
    "content": {
      "title": "JEP 486: Permanently Disable the Security Manager",
      "summary": "JEP 486: Permanently Disable the Security Manager JEP 486: Permanently Disable the Security Manager Author Sean Mullan &amp; Alex Buckley Owner Sean Mullan Type Feature Scope SE Status Closed&#8201;/&#8201;Delivered Release 24 Component security-libs&#8201;/&#8201;java.security Discussion security dash dev at openjdk dot java dot net Effort L Duration L Relates to JEP 411: Deprecate the Security Manager for Removal Reviewed by Alan Bateman, Mark Reinhold, Stuart Marks Endorsed by Alan Bateman Cr",
      "sections": {
        "Summary": "The Security Manager has not been the primary means of securing client-side Java code for many years, it has rarely been used to secure server-side code, and it is costly to maintain. We therefore deprecated it for removal in Java&#160;17 via JEP&#160;411 (2021). As the next step toward removing the Security Manager, we will revise the Java Platform",
        "Goals": "Remove the ability to enable the Security Manager when starting the Java runtime ( java -Djava.security.manager ... ). Remove the ability to install a Security Manager while an application is running ( System.setSecurityManager(...) ). Improve the maintainability of hundreds of JDK classes that currently delegate resource-access decisions to the Security Manager. Revise the",
        "Non-Goals": "It is not a goal to provide a replacement for any of the Security Manager's functionality, in particular the ability to sandbox Java code or intercept calls to the Java Platform API.",
        "Motivation": "The Security Manager has been a feature of the Java Platform since its first release. It is based upon the principle of least privilege: Code is untrusted by default, so it cannot access resources such as the filesystem or the network, and developers place trust in specific code by granting it permission to access specific resources. In theory, this can protect machines and applications against code that contains accidental vulnerabilities or was crafted with malicious intent. In practice, however, the permission scheme is so complex that the Security Manager has always been disabled by default, and its use is exceedingly rare. Despite the fact that the Security Manager is disabled by default, the least-privilege model induces extraordinary complexity in the Java Platform libraries. From networking, I/O, and JDBC, to XML, AWT, and Swing, the libraries must implement the least-privilege model in case the Security Manager is enabled: Over 1,000 methods must check for permission to access",
        "Description": "In JDK 24, we will: Remove the ability to enable the Security Manager at startup, Remove the ability to install a custom Security Manager during run time, and Render the Security Manager API non-functional, in advance of removing the API in a future release. Enabling the Security Manager in JDK 24 is an error In JDK 24, you cannot enable the Security Manager at startup, nor can you install a custom Security Manager during run time. It is an error to enable a Security Manager at startup, for example via: $ java -Djava.security.manager -jar app.jar $ java -Djava.security.manager=\"\" -jar app.jar $ java -Djava.security.manager=allow -jar app.jar $ java -Djava.security.manager=default -jar app.jar $ java -Djava.security.manager=com.foo.CustomSM -jar app.jar Attempting to do so causes the JVM to report the error and then exit: Error occurred during initialization of VM java.lang.Error: A command line option has attempted to allow or enable the Security Manager. Enabling a Security Manager is",
        "Alternatives": "The numerous check* methods in the Security Manager API always throw an exception so as to avoid unconditionally permitting operations that formerly required a permission check, and thus might not have been permitted. This may be inconvenient for application maintainers, who may have to take some corrective action. An alternative would be to have these methods always succeed, but that would allow an application to operate insecurely without notifying the maintainer.",
        "Testing": "The breadth of the Security Manager API and the depth of its support in the JDK codebase is reflected in the approximately 4,000 tests developed for it since JDK&#160;1.0. They fall into three categories: Tests that directly exercise functionality of the Security Manager, e.g., making sure that permissions are enforced correctly. Tests that address security vulnerabilities, which typically ensure that it is no longer possible for specific exploits that allowed untrusted code, such as applets, to escape the sandbox. Conformance tests which ensure that the Security Manager implementation complies with the",
        "Risks and Assumptions": "In JDK 24, attempting to enable the Security Manager on the command line will immediately result in an error message and the application will not start. If an application does not start then downstream systems might fail and business processes might be impacted. We assume that application maintainers can respond to the error by updating their java command lines to avoid giving the -Djava.security.manager option and by mitigating security concerns using other mechanisms. (When we remove a feature from the JDK, we conventionally reject any associated command line options. This includes the use of java -D... to set a system property such as java.security.manager . For example, setting the java.ext.dirs system property caused an error when the Extension Mechanism was removed in JDK&#160;9. This forces application maintainers to swiftly remove outdated options, avoiding situations where the JDK is run with a confusing or misleading set of options.) There is a risk that frameworks which rely",
        "Specification": "so that developers cannot enable it and other Platform classes do not refer to it. This change will have no impact on the vast majority of applications, libraries, and tools. We will remove the Security Manager API in a future release."
      },
      "fullText": "JEP 486: Permanently Disable the Security Manager JEP 486: Permanently Disable the Security Manager Author Sean Mullan &amp; Alex Buckley Owner Sean Mullan Type Feature Scope SE Status Closed&#8201;/&#8201;Delivered Release 24 Component security-libs&#8201;/&#8201;java.security Discussion security dash dev at openjdk dot java dot net Effort L Duration L Relates to JEP 411: Deprecate the Security Manager for Removal Reviewed by Alan Bateman, Mark Reinhold, Stuart Marks Endorsed by Alan Bateman Created 2024/08/19 23:43 Updated 2025/09/02 15:58 Issue 8338625 Summary The Security Manager has not been the primary means of securing client-side Java code for many years, it has rarely been used to secure server-side code, and it is costly to maintain. We therefore deprecated it for removal in Java&#160;17 via JEP&#160;411 (2021). As the next step toward removing the Security Manager, we will revise the Java Platform specification so that developers cannot enable it and other Platform classes do not refer to it. This change will have no impact on the vast majority of applications, libraries, and tools. We will remove the Security Manager API in a future release. Goals Remove the ability to enable the Security Manager when starting the Java runtime ( java -Djava.security.manager ... ). Remove the ability to install a Security Manager while an application is running ( System.setSecurityManager(...) ). Improve the maintainability of hundreds of JDK classes that currently delegate resource-access decisions to the Security Manager. Revise the specification of the Security Manager API so that all implementations of it behave as if no Security Manager is ever enabled. Retain the Security Manager API in this release, so that maintainers of existing code that depends upon it have time to migrate away. Non-Goals It is not a goal to provide a replacement for any of the Security Manager's functionality, in particular the ability to sandbox Java code or intercept calls to the Java Platform API. Motivation The Security Manager has been a feature of the Java Platform since its first release. It is based upon the principle of least privilege: Code is untrusted by default, so it cannot access resources such as the filesystem or the network, and developers place trust in specific code by granting it permission to access specific resources. In theory, this can protect machines and applications against code that contains accidental vulnerabilities or was crafted with malicious intent. In practice, however, the permission scheme is so complex that the Security Manager has always been disabled by default, and its use is exceedingly rare. Despite the fact that the Security Manager is disabled by default, the least-privilege model induces extraordinary complexity in the Java Platform libraries. From networking, I/O, and JDBC, to XML, AWT, and Swing, the libraries must implement the least-privilege model in case the Security Manager is enabled: Over 1,000 methods must check for p"
    }
  },
  {
    "url": "https://openjdk.org/jeps/497",
    "title": "JEP 497: Quantum-Resistant Module-Lattice-Based Digital Signature Algorithm",
    "content": {
      "title": "JEP 497: Quantum-Resistant Module-Lattice-Based Digital Signature Algorithm",
      "summary": "JEP 497: Quantum-Resistant Module-Lattice-Based Digital Signature Algorithm JEP 497: Quantum-Resistant Module-Lattice-Based Digital Signature Algorithm Owner Weijun Wang Type Feature Scope SE Status Closed&#8201;/&#8201;Delivered Release 24 Component security-libs&#8201;/&#8201;java.security Discussion security dash dev at openjdk dot org Effort M Duration M Reviewed by Sean Mullan Endorsed by Alan Bateman, Sean Mullan Created 2024/08/26 18:34 Updated 2025/03/13 14:49 Issue 8339010 Summary Enhan",
      "sections": {
        "Summary": "Enhance the security of Java applications by providing an implementation of the quantum-resistant Module-Lattice-Based Digital Signature Algorithm (ML-DSA). Digital signatures are used to detect unauthorized modifications to data and to authenticate the identity of signatories. ML-DSA is designed to be secure against future quantum computing attacks. It has been standardized by the United States National Institute of Standards and Technology (NIST) in FIPS&#160;204 .",
        "Goals": "Provide ML-DSA implementations of the KeyPairGenerator , Signature , and KeyFactory APIs, with support for the parameter sets ML-DSA-44, ML-DSA-65, and ML-DSA-87 standardized in FIPS&#160;204. Non",
        "Motivation": "The field of quantum computing has been advancing steadily for years. A future large-scale quantum computer could use Shor&#8217;s algorithm , which is capable of factoring integers and solving the discrete logarithm problem, to compromise the security of widely-deployed public-key based algorithms including Rivest-Shamir-Adleman (RSA) and Diffie-Hellman. Such algorithms are used by the Java Platform to, among other things, digitally sign JAR files and establish secure network connections via the Transport Layer Security (TLS) protocol. An attack that a conventional supercomputer might need thousands to millions of years to complete could be accomplished by a quantum computer using Shor's algorithm in mere hours. Cryptographers have responded to this threat by inventing quantum-resistant cryptographic algorithms, which cannot be defeated by Shor's algorithm. For the purposes of signing data and authenticating identities in a quantum-resistant fashion, NIST standardized the Module-Latti",
        "Description": "We will provide ML-DSA implementations of the KeyPairGenerator API to generate ML-DSA key pairs, of the Signature API to sign and verify ML-DSA signatures, and of the KeyFactory API to convert ML-DSA keys to and from their encodings. In the Java Security Standard Algorithm Names",
        "Alternatives": "The Open Quantum Safe project provides a JNI wrapper for their liboqs C library , which implements a collection of quantum-resistant algorithms including Dilithium and ML-DSA. If Open Quantum Safe achieves its goal of becoming the primary quantum-resistant cryptography implementation for major projects such as OpenSSL, BoringSSL, OpenSSH, and Mozilla, then it will gain substantial performance and robustness through widespread",
        "Testing": "and usage. Compared to a native implementation, a Java implementation of ML-DSA provides the key benefit of being integrated directly into the JDK. This makes it immediately available on all of the platforms to which the JDK is already ported.",
        "Specification": ", we will define a new standard algorithm family name, \"ML-DSA\" , for the KeyPairGenerator , Signature , and KeyFactory APIs. FIPS 204 specifies three parameter sets for ML-DSA. In order of increasing security strength and decreasing performance, they are named \"ML-DSA-44\" , \"ML-DSA-65\" , and \"ML-DSA-87\" . These parameter-set names will also be defined as standard algorithm names for the KeyPairGenerator , Signature , and KeyFactory APIs, and, further, will be represented by the new NamedParameterSpec constants ML_DSA_44 , ML_DSA_65 , and ML_DSA_87 . Generating ML-DSA key pairs You can generate an ML-DSA key pair in one of three ways: Instantiate a KeyPairGenerator with the family name and initialize it with a parameter-set name: KeyPairGenerator g = KeyPairGenerator.getInstance(\"ML-DSA\"); g.initialize(NamedParameterSpec.ML_DSA_44); KeyPair kp = g.generateKeyPair(); // an ML-DSA-44 key pair If you do not initialize the KeyPairGenerator with a parameter set, the implementation will use "
      },
      "fullText": "JEP 497: Quantum-Resistant Module-Lattice-Based Digital Signature Algorithm JEP 497: Quantum-Resistant Module-Lattice-Based Digital Signature Algorithm Owner Weijun Wang Type Feature Scope SE Status Closed&#8201;/&#8201;Delivered Release 24 Component security-libs&#8201;/&#8201;java.security Discussion security dash dev at openjdk dot org Effort M Duration M Reviewed by Sean Mullan Endorsed by Alan Bateman, Sean Mullan Created 2024/08/26 18:34 Updated 2025/03/13 14:49 Issue 8339010 Summary Enhance the security of Java applications by providing an implementation of the quantum-resistant Module-Lattice-Based Digital Signature Algorithm (ML-DSA). Digital signatures are used to detect unauthorized modifications to data and to authenticate the identity of signatories. ML-DSA is designed to be secure against future quantum computing attacks. It has been standardized by the United States National Institute of Standards and Technology (NIST) in FIPS&#160;204 . Goals Provide ML-DSA implementations of the KeyPairGenerator , Signature , and KeyFactory APIs, with support for the parameter sets ML-DSA-44, ML-DSA-65, and ML-DSA-87 standardized in FIPS&#160;204. Non Goals It is not a goal to implement the Dilithium algorithm , from which ML-DSA was derived. The two algorithms are not interoperable. It is not a goal to add support for ML-DSA to components of the Java Platform for which the necessary standards do not yet exist. That is the case for, in particular, JAR-file signing as well as the implementation of Transport Layer Security (TLS) in the javax.net.ssl package. We will add such support once the standards do exist. It is not a goal to support Pre-Hash ML-DSA (FIPS&#160;204 &#167;5.4) or allow users to set application-specific context strings (FIPS&#160;204 &#167;5.2). We may implement these features in a future release. Motivation The field of quantum computing has been advancing steadily for years. A future large-scale quantum computer could use Shor&#8217;s algorithm , which is capable of factoring integers and solving the discrete logarithm problem, to compromise the security of widely-deployed public-key based algorithms including Rivest-Shamir-Adleman (RSA) and Diffie-Hellman. Such algorithms are used by the Java Platform to, among other things, digitally sign JAR files and establish secure network connections via the Transport Layer Security (TLS) protocol. An attack that a conventional supercomputer might need thousands to millions of years to complete could be accomplished by a quantum computer using Shor's algorithm in mere hours. Cryptographers have responded to this threat by inventing quantum-resistant cryptographic algorithms, which cannot be defeated by Shor's algorithm. For the purposes of signing data and authenticating identities in a quantum-resistant fashion, NIST standardized the Module-Lattice-Based Digital Signature Algorithm (ML-DSA) in FIPS&#160;204 . In the United States, government computer systems that handle sensitive inform"
    }
  },
  {
    "url": "https://openjdk.org/jeps/496",
    "title": "JEP 496: Quantum-Resistant Module-Lattice-Based Key Encapsulation Mechanism",
    "content": {
      "title": "JEP 496: Quantum-Resistant Module-Lattice-Based Key Encapsulation Mechanism",
      "summary": "JEP 496: Quantum-Resistant Module-Lattice-Based Key Encapsulation Mechanism JEP 496: Quantum-Resistant Module-Lattice-Based Key Encapsulation Mechanism Owner Weijun Wang Type Feature Scope SE Status Closed&#8201;/&#8201;Delivered Release 24 Component security-libs&#8201;/&#8201;javax.crypto Discussion security dash dev at openjdk dot org Effort M Duration S Reviewed by Sean Mullan Endorsed by Alan Bateman, Sean Mullan Created 2024/08/26 18:33 Updated 2025/03/13 14:49 Issue 8339009 Summary Enhanc",
      "sections": {
        "Summary": "Enhance the security of Java applications by providing an implementation of the quantum-resistant Module-Lattice-Based Key-Encapsulation Mechanism (ML-KEM). Key encapsulation mechanisms (KEMs) are used to secure symmetric keys over insecure communication channels using public key cryptography. ML-KEM is designed to be secure against future quantum computing attacks. It has been standardized by the United States National Institute of Standards and Technology (NIST) in FIPS&#160;203 .",
        "Goals": "Provide ML-KEM implementations of the KeyPairGenerator , KEM , and KeyFactory APIs, with support for the parameter sets ML-KEM-512, ML-KEM-768, and ML-KEM-1024 standardized in FIPS&#160;203. Non",
        "Motivation": "The field of quantum computing has been advancing steadily for years. A future large-scale quantum computer could use Shor&#8217;s algorithm , which is capable of factoring integers and solving the discrete logarithm problem, to compromise the security of widely-deployed public-key based algorithms including Rivest-Shamir-Adleman (RSA) and Diffie-Hellman. Such algorithms are used by the Java Platform to, among other things, digitally sign JAR files and establish secure network connections via the Transport Layer Security (TLS) protocol. An attack that a conventional supercomputer might need thousands to millions of years to complete could be accomplished by a quantum computer using Shor's algorithm in mere hours. Cryptographers have responded to this threat by inventing quantum-resistant cryptographic algorithms, which cannot be defeated by Shor's algorithm. Switching to quantum-resistant algorithms is urgent even though large-scale quantum computers do not yet exist, since an adversar",
        "Description": "As described in JEP 452 , a KEM consists of three functions: A key pair generation function returns a key pair containing a public key and a private key. A key encapsulation function , called by the sender, takes the receiver's public key and an encryption option; it returns a secret key K and a key encapsulation message . The sender sends the key encapsulation message to the receiver. A key decapsulation function , called by the receiver, takes the receiver's private key and the received key encapsulation message; it returns the secret key K . For the first function, we will provide an implementation of the KeyPairGenerator API that generates ML-KEM key pairs. For the second and third functions, we will provide an implementation of the KEM API that negotiates shared secret keys based on an ML-KEM key pair. We will also provide an implementation of the KeyFactory API that converts ML-KEM keys to and from their encodings. In the Java Security Standard Algorithm Names",
        "Alternatives": "The Open Quantum Safe project provides a JNI wrapper for their liboqs C library , which implements a collection of quantum-resistant algorithms including Kyber and ML-KEM. If Open Quantum Safe achieves its goal of becoming the primary quantum-resistant cryptography implementation for major projects such as OpenSSL, BoringSSL, OpenSSH, and Mozilla, then it will gain substantial performance and robustness through widespread",
        "Testing": "and usage. Compared to a native implementation, a Java implementation of ML-KEM provides the key benefit of being integrated directly into the JDK. This makes it immediately available on all of the platforms to which the JDK is already ported.",
        "Specification": ", we will define a new standard algorithm family name, \"ML-KEM\" , for the KeyPairGenerator , KEM , and KeyFactory APIs. FIPS 203 specifies three parameter sets for ML-KEM. In order of increasing security strength and decreasing performance, they are named \"ML-KEM-512\" , \"ML-KEM-768\" , and \"ML-KEM-1024\" . These parameter-set names will also be defined as standard algorithm names for the KeyPairGenerator , KEM , and KeyFactory APIs, and, further, will be represented by the new NamedParameterSpec constants ML_KEM_512 , ML_KEM_768 , and ML_KEM_1024 . Generating ML-KEM key pairs You can generate an ML-KEM key pair in one of three ways: Instantiate a KeyPairGenerator with the family name and initialize it with a parameter-set name: KeyPairGenerator g = KeyPairGenerator.getInstance(\"ML-KEM\"); g.initialize(NamedParameterSpec.ML_KEM_512); KeyPair kp = g.generateKeyPair(); // an ML-KEM-512 key pair If you do not initialize the KeyPairGenerator with a parameter set, the implementation will use ML"
      },
      "fullText": "JEP 496: Quantum-Resistant Module-Lattice-Based Key Encapsulation Mechanism JEP 496: Quantum-Resistant Module-Lattice-Based Key Encapsulation Mechanism Owner Weijun Wang Type Feature Scope SE Status Closed&#8201;/&#8201;Delivered Release 24 Component security-libs&#8201;/&#8201;javax.crypto Discussion security dash dev at openjdk dot org Effort M Duration S Reviewed by Sean Mullan Endorsed by Alan Bateman, Sean Mullan Created 2024/08/26 18:33 Updated 2025/03/13 14:49 Issue 8339009 Summary Enhance the security of Java applications by providing an implementation of the quantum-resistant Module-Lattice-Based Key-Encapsulation Mechanism (ML-KEM). Key encapsulation mechanisms (KEMs) are used to secure symmetric keys over insecure communication channels using public key cryptography. ML-KEM is designed to be secure against future quantum computing attacks. It has been standardized by the United States National Institute of Standards and Technology (NIST) in FIPS&#160;203 . Goals Provide ML-KEM implementations of the KeyPairGenerator , KEM , and KeyFactory APIs, with support for the parameter sets ML-KEM-512, ML-KEM-768, and ML-KEM-1024 standardized in FIPS&#160;203. Non Goals It is not a goal to implement the Kyber algorithm , from which ML-KEM was derived. The two algorithms are not interoperable. It is not a goal to add support for ML-KEM to components of the Java Platform for which the necessary standards do not yet exist. That is the case for, in particular, the implementation of Transport Layer Security (TLS) in the javax.net.ssl package. We will add such support once the standards do exist. Motivation The field of quantum computing has been advancing steadily for years. A future large-scale quantum computer could use Shor&#8217;s algorithm , which is capable of factoring integers and solving the discrete logarithm problem, to compromise the security of widely-deployed public-key based algorithms including Rivest-Shamir-Adleman (RSA) and Diffie-Hellman. Such algorithms are used by the Java Platform to, among other things, digitally sign JAR files and establish secure network connections via the Transport Layer Security (TLS) protocol. An attack that a conventional supercomputer might need thousands to millions of years to complete could be accomplished by a quantum computer using Shor's algorithm in mere hours. Cryptographers have responded to this threat by inventing quantum-resistant cryptographic algorithms, which cannot be defeated by Shor's algorithm. Switching to quantum-resistant algorithms is urgent even though large-scale quantum computers do not yet exist, since an adversary could harvest encrypted data today, store it, and decrypt it once such computers become available. For the purpose of exchanging keys in a quantum-resistant fashion, NIST standardized the Module-Lattice-Based Key-Encapsulation Mechanism (ML-KEM) in FIPS&#160;203 . In the United States, government computer systems that handle sensitive information must be upgraded ove"
    }
  },
  {
    "url": "https://openjdk.org/jeps/458",
    "title": "JEP 458: Launch Multi-File Source-Code Programs",
    "content": {
      "title": "JEP 458: Launch Multi-File Source-Code Programs",
      "summary": "JEP 458: Launch Multi-File Source-Code Programs JEP 458: Launch Multi-File Source-Code Programs Owner Ron Pressler Type Feature Scope JDK Status Closed&#8201;/&#8201;Delivered Release 22 Component tools&#8201;/&#8201;launcher Discussion compiler dash dev at openjdk dot org Effort S Relates to JEP 330: Launch Single-File Source-Code Programs Reviewed by Alex Buckley, Brian Goetz Endorsed by Brian Goetz Created 2023/03/17 10:17 Updated 2023/12/05 18:43 Issue 8304400 Summary Enhance the java applic",
      "sections": {
        "Summary": "Enhance the java application launcher to be able to run a program supplied as multiple files of Java source code. This will make the transition from small programs to larger ones more gradual, enabling developers to choose whether and when to go to the trouble of configuring a build tool.",
        "Goals": "It is not a goal to launch multi-file source-code programs via the \"shebang\" mechanism. Only single-file source-code programs can be launched via that mechanism. It is not a goal to ease the use of external library",
        "Non-Goals": "It is not a goal to launch multi-file source-code programs via the \"shebang\" mechanism. Only single-file source-code programs can be launched via that mechanism. It is not a goal to ease the use of external library",
        "Motivation": "The Java programming language excels for writing large, complex applications developed and maintained over many years by large teams. Still, even large programs start small. In the early stages, developers tinker and explore and do not care about deliverable artifacts; the project's structure may not yet exist, and once it emerges, it changes frequently. Fast iteration and radical change are the order of the day. Several features to assist with tinkering and exploration have been added to the JDK in recent years, including JShell (an interactive shell for playing with snippets of code) and a simple web server (for quick prototyping of web apps). In JDK 11, JEP 330 enhanced the java application launcher to be able to run .java source files directly, without an explicit compilation step. For example, suppose the file Prog.java declares two classes: class Prog { public static void main(String[] args) { Helper.run(); } } class Helper { static void run() { System.out.println(\"Hello!\"); } } ",
        "Description": "We enhance the java launcher's source-file mode to be able to run a program supplied as multiple files of Java source code. For example, suppose a directory contains two files, Prog.java and Helper.java , where each file declares a single class: // Prog.java class Prog { public static void main(String[] args) { Helper.run(); } } // Helper.java class Helper { static void run() { System.out.println(\"Hello!\"); } } Running java Prog.java compiles the Prog class in memory and invokes its main method. Because code in this class refers to the class Helper , the launcher finds the Helper.java file in the filesystem and compiles its class in memory. If code in class Helper refers to some other class, e.g., HelperAux , then the launcher finds HelperAux.java and compiles that, too. When classes in different .java files refer to each other, the java launcher does not guarantee any particular order or timing for the compilation of the .java files. It is possible, for example, for the launcher to co",
        "Alternatives": "We could keep source-code programs restricted to single files and continue to require a separate compilation step for multi-file programs. While that does not impose significantly more work on the developer, the reality is that many Java developers have grown unfamiliar with the direct use of javac and prefer to rely on build tools when compilation to class files is required. Using the java command is less intimidating than using javac . We could make javac easier to use, with convenient defaults for compiling complete source trees. However, the need to set up a directory for the generated class files, or else have them pollute the source tree, is a speed bump to rapid prototyping. Developers often place their .java files under version control even at the tinkering stage, and would thus need to set up their version control repository to exclude the class files generated by javac . Installing Contributing Sponsoring Developers' Guide Vulnerabilities JDK GA/EA Builds Mailing lists Wiki &",
        "Dependencies": "in source-code programs. That may be the subject of a future JEP.",
        "Specification": "Review Compiler Conformance Core Libraries Governing Board HotSpot IDE Tooling &amp; Support Internationalization JMX Members Networking Porters Quality Security Serviceability Vulnerability Web Projects ( overview , archive ) Amber Babylon CRaC Code Tools Coin Common VM Interface Developers' Guide Device I/O Duke Galahad Graal IcedTea JDK 8 Updates JDK 9 JDK (&#8230;, 24 , 25 , 26 ) JDK Updates JMC Jigsaw Kona Lanai Leyden Lilliput Locale Enhancement Loom Memory Model Update Metropolis Multi-Language VM Nashorn New I/O OpenJFX Panama Penrose Port: AArch32 Port: AArch64 Port: BSD Port: Haiku Port: Mac OS X Port: MIPS Port: Mobile Port: PowerPC/AIX Port: RISC-V Port: s390x SCTP Shenandoah Skara Sumatra Tsan Valhalla Verona VisualVM Wakefield Zero ZGC &#169; 2025 Oracle Corporation and/or its affiliates Terms of Use &#183; License: GPLv2 &#183; Privacy &#183; Trademarks"
      },
      "fullText": "JEP 458: Launch Multi-File Source-Code Programs JEP 458: Launch Multi-File Source-Code Programs Owner Ron Pressler Type Feature Scope JDK Status Closed&#8201;/&#8201;Delivered Release 22 Component tools&#8201;/&#8201;launcher Discussion compiler dash dev at openjdk dot org Effort S Relates to JEP 330: Launch Single-File Source-Code Programs Reviewed by Alex Buckley, Brian Goetz Endorsed by Brian Goetz Created 2023/03/17 10:17 Updated 2023/12/05 18:43 Issue 8304400 Summary Enhance the java application launcher to be able to run a program supplied as multiple files of Java source code. This will make the transition from small programs to larger ones more gradual, enabling developers to choose whether and when to go to the trouble of configuring a build tool. Non-Goals It is not a goal to launch multi-file source-code programs via the \"shebang\" mechanism. Only single-file source-code programs can be launched via that mechanism. It is not a goal to ease the use of external library dependencies in source-code programs. That may be the subject of a future JEP. Motivation The Java programming language excels for writing large, complex applications developed and maintained over many years by large teams. Still, even large programs start small. In the early stages, developers tinker and explore and do not care about deliverable artifacts; the project's structure may not yet exist, and once it emerges, it changes frequently. Fast iteration and radical change are the order of the day. Several features to assist with tinkering and exploration have been added to the JDK in recent years, including JShell (an interactive shell for playing with snippets of code) and a simple web server (for quick prototyping of web apps). In JDK 11, JEP 330 enhanced the java application launcher to be able to run .java source files directly, without an explicit compilation step. For example, suppose the file Prog.java declares two classes: class Prog { public static void main(String[] args) { Helper.run(); } } class Helper { static void run() { System.out.println(\"Hello!\"); } } Then running $ java Prog.java compiles both classes in memory and executes the main method of the first class declared in that file. This low-ceremony approach to running a program has a major limitation: All of the source code of the program must be placed in a single .java file. To work with more than one .java file, developers must return to compiling source files explicitly. For experienced developers, this often entails creating a project configuration for a build tool, but shifting from amorphous tinkering to formal project structure is irksome when trying to get ideas and experiments to flow smoothly. For beginning developers, the transition from a single .java file to two or more files requires an even starker phase change: They must pause their learning of the language and learn to operate javac , or learn a third-party build tool, or learn to rely on the magic of an IDE. It would be better if de"
    }
  },
  {
    "url": "https://openjdk.org/jeps/493",
    "title": "JEP 493: Linking Run-Time Images without JMODs",
    "content": {
      "title": "JEP 493: Linking Run-Time Images without JMODs",
      "summary": "JEP 493: Linking Run-Time Images without JMODs JEP 493: Linking Run-Time Images without JMODs Owner Severin Gehwolf Type Feature Scope JDK Status Closed&#8201;/&#8201;Delivered Release 24 Component tools&#8201;/&#8201;jlink Discussion core dash libs dash dev at openjdk dot org, jigsaw dash dev at openjdk dot org Effort M Duration M Reviewed by Alan Bateman, Mandy Chung Endorsed by Alan Bateman Created 2024/06/07 13:36 Updated 2025/02/20 09:55 Issue 8333799 Summary Reduce the size of the JDK by a",
      "sections": {
        "Summary": "Reduce the size of the JDK by approximately 25% by enabling the jlink tool to create custom run-time images without using the JDK's JMOD files. This feature must be enabled when the JDK is built; it will not be enabled by default, and some JDK vendors may choose not to enable it.",
        "Goals": "Allow users to link a run-time image from modules regardless of whether those modules are standalone JMOD files , modular JAR files , or are part of a run-time image linked previously.",
        "Motivation": "The installed size of the JDK on the filesystem is important in cloud environments, where container images that include an installed JDK are automatically and frequently copied over the network from container registries. Reducing the size of the JDK would improve the efficiency of these operations. A complete, installed JDK has two main components: A run-time image , which is the executable Java run-time system, and a set of packaged modules , in the JMOD format , for each module in the run-time image. The JMOD files are used by the jlink tool when creating custom run-time images . The run-time image in a complete JDK is itself such an image, created from these JMOD files via jlink . Thus every class file, native library, configuration file, and other resource in the run-time image is also present in one of these JMOD files &#8212; arguably a massive waste of space. In fact, the JMOD files in a complete JDK account for about 25% of the JDK's total size. If we could enhance the jlink to",
        "Description": "The new JDK build-time configuration option --enable-linkable-runtime builds a JDK whose jlink tool can create run-time images without using the JDK's JMOD files. The resulting JDK does not include those files, i.e., there is no jmods directory. It is thus approximately 25% smaller than a JDK built with the default configuration, though it contains exactly the same modules. $ configure [ ... other options ... ] --enable-linkable-runtime $ make images The jlink tool in any JDK build can consume both JMOD files and modular JAR files. In addition, in JDK builds with this feature enabled, jlink can consume modules from the run-time image of which it is part. The --help output of jlink shows whether it has this capability: $ jlink --help Usage: jlink &lt;options&gt; --module-path &lt;modulepath&gt; --add-modules &lt;module&gt;[,&lt;module&gt;...] ... Capabilities: Linking from run-time image enabled $ This means that the jlink tool in use can link JDK modules from the containing run-time im",
        "Alternatives": "A JDK vendor could provide a JDK's JMOD files as a separate download. Some Linux distributions already do essentially this, by providing one installation package for the JDK run-time image and another for the corresponding JMOD files. This approach is brittle, since if the second package is not installed then the jlink tool will not work. This approach is, furthermore, not well-suited to cloud environments in which a JDK run-time image and its JMOD files might wind up in different and conflicting container-image layers. Installing Contributing Sponsoring Developers' Guide Vulnerabilities JDK GA/EA Builds Mailing lists Wiki &#183; IRC Mastodon Bluesky Bylaws &#183; Census Legal Workshop JEP Process Source code GitHub Mercurial Tools Git jtreg harness Groups (overview) Adoption Build Client Libraries Compatibility &amp;",
        "Specification": "Review Compiler Conformance Core Libraries Governing Board HotSpot IDE Tooling &amp; Support Internationalization JMX Members Networking Porters Quality Security Serviceability Vulnerability Web Projects ( overview , archive ) Amber Babylon CRaC Code Tools Coin Common VM Interface Developers' Guide Device I/O Duke Galahad Graal IcedTea JDK 8 Updates JDK 9 JDK (&#8230;, 24 , 25 , 26 ) JDK Updates JMC Jigsaw Kona Lanai Leyden Lilliput Locale Enhancement Loom Memory Model Update Metropolis Multi-Language VM Nashorn New I/O OpenJFX Panama Penrose Port: AArch32 Port: AArch64 Port: BSD Port: Haiku Port: Mac OS X Port: MIPS Port: Mobile Port: PowerPC/AIX Port: RISC-V Port: s390x SCTP Shenandoah Skara Sumatra Tsan Valhalla Verona VisualVM Wakefield Zero ZGC &#169; 2025 Oracle Corporation and/or its affiliates Terms of Use &#183; License: GPLv2 &#183; Privacy &#183; Trademarks"
      },
      "fullText": "JEP 493: Linking Run-Time Images without JMODs JEP 493: Linking Run-Time Images without JMODs Owner Severin Gehwolf Type Feature Scope JDK Status Closed&#8201;/&#8201;Delivered Release 24 Component tools&#8201;/&#8201;jlink Discussion core dash libs dash dev at openjdk dot org, jigsaw dash dev at openjdk dot org Effort M Duration M Reviewed by Alan Bateman, Mandy Chung Endorsed by Alan Bateman Created 2024/06/07 13:36 Updated 2025/02/20 09:55 Issue 8333799 Summary Reduce the size of the JDK by approximately 25% by enabling the jlink tool to create custom run-time images without using the JDK's JMOD files. This feature must be enabled when the JDK is built; it will not be enabled by default, and some JDK vendors may choose not to enable it. Goals Allow users to link a run-time image from modules regardless of whether those modules are standalone JMOD files , modular JAR files , or are part of a run-time image linked previously. Motivation The installed size of the JDK on the filesystem is important in cloud environments, where container images that include an installed JDK are automatically and frequently copied over the network from container registries. Reducing the size of the JDK would improve the efficiency of these operations. A complete, installed JDK has two main components: A run-time image , which is the executable Java run-time system, and a set of packaged modules , in the JMOD format , for each module in the run-time image. The JMOD files are used by the jlink tool when creating custom run-time images . The run-time image in a complete JDK is itself such an image, created from these JMOD files via jlink . Thus every class file, native library, configuration file, and other resource in the run-time image is also present in one of these JMOD files &#8212; arguably a massive waste of space. In fact, the JMOD files in a complete JDK account for about 25% of the JDK's total size. If we could enhance the jlink tool to extract class files, native libraries, configuration files, and other resources from the run-time image itself then we could dramatically reduce the size of the installed JDK by omitting the JMOD files. Description The new JDK build-time configuration option --enable-linkable-runtime builds a JDK whose jlink tool can create run-time images without using the JDK's JMOD files. The resulting JDK does not include those files, i.e., there is no jmods directory. It is thus approximately 25% smaller than a JDK built with the default configuration, though it contains exactly the same modules. $ configure [ ... other options ... ] --enable-linkable-runtime $ make images The jlink tool in any JDK build can consume both JMOD files and modular JAR files. In addition, in JDK builds with this feature enabled, jlink can consume modules from the run-time image of which it is part. The --help output of jlink shows whether it has this capability: $ jlink --help Usage: jlink &lt;options&gt; --module-path &lt;modulepath&gt; --add-modules &lt;modu"
    }
  },
  {
    "url": "https://openjdk.org/jeps/467",
    "title": "JEP 467: Markdown Documentation Comments",
    "content": {
      "title": "JEP 467: Markdown Documentation Comments",
      "summary": "JEP 467: Markdown Documentation Comments JEP 467: Markdown Documentation Comments Owner Jonathan Gibbons Type Feature Scope SE Status Closed&#8201;/&#8201;Delivered Release 23 Component tools&#8201;/&#8201;javadoc(tool) Discussion javadoc dash dev at openjdk dot org Reviewed by Ron Pressler Endorsed by Paul Sandoz Created 2023/09/11 17:45 Updated 2025/05/05 21:09 Issue 8316039 Summary Enable JavaDoc documentation comments to be written in Markdown rather than solely in a mixture of HTML and Java",
      "sections": {
        "Summary": "Enable JavaDoc documentation comments to be written in Markdown rather than solely in a mixture of HTML and JavaDoc @ -tags.",
        "Goals": "Make API documentation comments easier to write and easier to read in source form by introducing the ability to use Markdown syntax in documentation comments, alongside HTML elements and JavaDoc tags. Do not adversely affect the interpretation of existing documentation comments. Extend the Compiler Tree API to enable other tools that analyze documentation comments to handle Markdown content in those comments.",
        "Non-Goals": "It is not a goal to enable automated conversion of existing documentation comments to Markdown syntax.",
        "Motivation": "Documentation comments are stylized comments appearing in source code, near to the declarations that they serve to document. Documentation comments in Java source code use a combination of HTML and custom JavaDoc tags to mark up the text. The choice of HTML for a markup language was reasonable in 1995. HTML is powerful, standardized, and was very popular at the time. But while it is no less popular today as a markup language consumed by web browsers, in the years since 1995 HTML has become much less popular as markup that is manually produced by humans because it is tedious to write and hard to read. These days it is more commonly generated from some other markup language that is more suitable for humans. Because HTML is tedious to write, nicely-formatted documentation comments are also tedious to write, and even more tedious since many new developers are not fluent in HTML due to its decline as a human-produced format. Inline JavaDoc tags, such as {@link} and {@code} , are also cumber",
        "Description": "As an example of the use of Markdown in a documentation comment, consider the comment for java.lang.Object.hashCode : /** * Returns a hash code value for the object. This method is * supported for the benefit of hash tables such as those provided by * {@link java.util.HashMap}. * &lt;p&gt; * The general contract of {@code hashCode} is: * &lt;ul&gt; * &lt;li&gt;Whenever it is invoked on the same object more than once during * an execution of a Java application, the {@code hashCode} method * must consistently return the same integer, provided no information * used in {@code equals} comparisons on the object is modified. * This integer need not remain consistent from one execution of an * application to another execution of the same application. * &lt;li&gt;If two objects are equal according to the {@link * #equals(Object) equals} method, then calling the {@code * hashCode} method on each of the two objects must produce the * same integer result. * &lt;li&gt;It is &lt;em&gt;not&lt;/em&gt;",
        "Alternatives": "Pluggable implementation Instead of leveraging a specific Markdown parser implementation, we could instead support the use of other user-specified Markdown processors, providing different flavors of Markdown. However, such an approach could lead to inconsistencies when generating documentation spanning different libraries for little perceived gain. Translating more Markdown to HTML We could translate additional Markdown constructs into equivalent DocTree nodes, representing plain text, HTML, and JavaDoc tags. While such an approach would have the advantage that API clients may not need to be aware that the original source for the comment was in Markdown, there are also a number of disadvantages: The more removed the representation is from the original syntax tree, the harder it is to give accurate and relevant diagnostics, should any be necessary. For example, messages about a synthetic &lt;table&gt; element may be confusing if there is no such item explicitly in the original comment. ",
        "Risks and Assumptions": "The implementation employs a third-party library, commonmark-java , to transform Markdown to HTML. If that library becomes unmaintained then we will have to maintain a fork of the library for use in the JDK, or else find an equivalent alternative. There is a risk of more errors in generated API documentation, because of the reduced ability to check for bad code, and because authors sometimes forget to check the generated form of their documentation. For example, in a traditional documentation comment a paragraph containing an unterminated code tag such as {@code abc will cause a diagnostic message to be issued when JavaDoc is invoked, and will be displayed in the generated documentation as &#9654; invalid @code . In Markdown, the equivalent unclosed code span `abc is specified to be treated as literal text, and will be displayed as such, with no corresponding diagnostic message. Installing Contributing Sponsoring Developers' Guide Vulnerabilities JDK GA/EA Builds Mailing lists Wiki &#1",
        "Specification": ", and block tags such as @implSpec and @implNote to introduce sections of particular information: /// For more information on comments, see {@jls 3.7 Comments}. /// /// @implSpec /// This implementation does nothing. public void doSomething() { } Standalone Markdown files Markdown files in doc-files subdirectories are processed appropriately, in a similar manner to HTML files in such directories. JavaDoc tags in such files are processed. The page title is inferred from the first heading. YAML metadata, such as that supported by the Pandoc Markdown processor, is not supported. The file containing the content for the generated top-level overview page may also be a Markdown file. Syntax highlighting and embedded languages The opening fence in a fenced code block may be followed by an info string . The first word of the info string is used to derive the CSS class name in the corresponding generated HTML, and may also be used by JavaScript libraries to enable syntax highlighting (such as wi"
      },
      "fullText": "JEP 467: Markdown Documentation Comments JEP 467: Markdown Documentation Comments Owner Jonathan Gibbons Type Feature Scope SE Status Closed&#8201;/&#8201;Delivered Release 23 Component tools&#8201;/&#8201;javadoc(tool) Discussion javadoc dash dev at openjdk dot org Reviewed by Ron Pressler Endorsed by Paul Sandoz Created 2023/09/11 17:45 Updated 2025/05/05 21:09 Issue 8316039 Summary Enable JavaDoc documentation comments to be written in Markdown rather than solely in a mixture of HTML and JavaDoc @ -tags. Goals Make API documentation comments easier to write and easier to read in source form by introducing the ability to use Markdown syntax in documentation comments, alongside HTML elements and JavaDoc tags. Do not adversely affect the interpretation of existing documentation comments. Extend the Compiler Tree API to enable other tools that analyze documentation comments to handle Markdown content in those comments. Non-Goals It is not a goal to enable automated conversion of existing documentation comments to Markdown syntax. Motivation Documentation comments are stylized comments appearing in source code, near to the declarations that they serve to document. Documentation comments in Java source code use a combination of HTML and custom JavaDoc tags to mark up the text. The choice of HTML for a markup language was reasonable in 1995. HTML is powerful, standardized, and was very popular at the time. But while it is no less popular today as a markup language consumed by web browsers, in the years since 1995 HTML has become much less popular as markup that is manually produced by humans because it is tedious to write and hard to read. These days it is more commonly generated from some other markup language that is more suitable for humans. Because HTML is tedious to write, nicely-formatted documentation comments are also tedious to write, and even more tedious since many new developers are not fluent in HTML due to its decline as a human-produced format. Inline JavaDoc tags, such as {@link} and {@code} , are also cumbersome and are even less familiar to developers, often requiring the author to consult the documentation for their usage. A recent analysis of the documentation comments in the JDK source code showed that over 95% of the uses of inline tags were for code fragments and links to elsewhere in the documentation, suggesting that simpler forms of these constructs would be welcome. Markdown is a popular markup language for simple documents that is easy to read, easy to write, and easily transformed into HTML. Documentation comments are typically not complicated structured documents, and for the constructs that typically appear in documentation comments, such as paragraphs, lists, styled text, and links, Markdown provides simpler forms than HTML. For those constructs that Markdown does not directly support, Markdown allows the use of HTML as well. Introducing the ability to use Markdown in documentation comments would bring together the bes"
    }
  },
  {
    "url": "https://openjdk.org/jeps/507",
    "title": "JEP 507: Primitive Types in Patterns, instanceof, and switch (Third Preview)",
    "content": {
      "title": "JEP 507: Primitive Types in Patterns, instanceof, and switch (Third Preview)",
      "summary": "JEP 507: Primitive Types in Patterns, instanceof, and switch (Third Preview) JEP 507: Primitive Types in Patterns, instanceof, and switch (Third Preview) Owner Angelos Bimpoudis Type Feature Scope SE Status Closed&#8201;/&#8201;Delivered Release 25 Component specification&#8201;/&#8201;language Discussion amber dash dev at openjdk dot org Effort M Duration M Relates to JEP 488: Primitive Types in Patterns, instanceof, and switch (Second Preview) Reviewed by Alex Buckley, Brian Goetz Endorsed by ",
      "sections": {
        "Summary": "Enhance pattern matching by allowing primitive types in all pattern contexts, and extend instanceof and switch to work with all primitive types. This is a preview language feature . History This feature was originally proposed by JEP&#160;455 (JDK&#160;23) and re-previewed by JEP&#160;488 (JDK&#160;24), without change. We here propose to preview it for a third time, without change.",
        "Goals": "Enable uniform data exploration by allowing type patterns for all types, whether primitive or reference. Align type patterns with instanceof , and align instanceof with safe casting. Allow pattern matching to use primitive types in both nested and top-level pattern contexts. Provide easy-to-use constructs that eliminate the risk of losing information due to unsafe casts. Following the enhancements to switch in Java&#160;5 (enum switch ) and Java&#160;7 (string switch ), allow switch to process values of any primitive type.",
        "Non-Goals": "It is not a goal to add new kinds of conversions to the Java language.",
        "Motivation": "Multiple restrictions pertaining to primitive types impose friction when using pattern matching, instanceof , and switch . Eliminating these restrictions would make the Java language more uniform and more expressive. Pattern matching for switch does not support primitive type patterns The first restriction is that pattern matching for switch ( JEP&#160;441 ) does not support primitive type patterns, i.e., type patterns that specify a primitive type. Only type patterns that specify a reference type are supported, such as case Integer i or case String s . (Since Java 21, record patterns ( JEP&#160;440 ) are also supported for switch .) With support for primitive type patterns in switch , we could improve the switch expression switch (x.getStatus()) { case 0 -&gt; \"okay\"; case 1 -&gt; \"warning\"; case 2 -&gt; \"error\"; default -&gt; \"unknown status: \" + x.getStatus(); } by turning the default clause into a case clause with a primitive type pattern that exposes the matched value: switch (x.g",
        "Description": "In Java 21, primitive type patterns are permitted only as nested patterns in record patterns, and only when they name the type of the match candidate exactly, as in: v instanceof JsonNumber(double a) To support the more uniform data exploration of a match candidate v with pattern matching, we will: Extend pattern matching so that primitive type patterns are applicable to a wider range of match candidate types. This will allow expressions such as v instanceof JsonNumber(int age) . Enhance the instanceof and switch constructs to support primitive type patterns as top level patterns. Further enhance the instanceof construct so that, when used for type",
        "Testing": "rather than pattern matching, it can test against all types, not just reference types. This will extend instanceof 's current role, as the precondition for safe casting on reference types, to apply to all types. More broadly, this means that instanceof can safeguard all conversions, whether the match candidate is having its type tested (e.g., x instanceof int , or y instanceof String ) or having its value matched (e.g., x instanceof int i , or y instanceof String s ). Further enhance the switch construct so that it works with all primitive types, not just a subset of the integral primitive types . We achieve these changes by altering a small number of rules in the Java language that govern the use of primitive types, and by characterizing when a conversion from one type to another is safe &#8212; which involves knowledge of the value to be converted as well as the source and target types of the conversion. Safety of conversions A conversion is exact if no loss of information occurs. Wh",
        "Specification": "&#8201;/&#8201;language Discussion amber dash dev at openjdk dot org Effort M Duration M Relates to JEP 488: Primitive Types in Patterns, instanceof, and switch (Second Preview) Reviewed by Alex Buckley, Brian Goetz Endorsed by Brian Goetz Created 2025/02/03 12:20 Updated 2025/08/26 12:38 Issue 8349215"
      },
      "fullText": "JEP 507: Primitive Types in Patterns, instanceof, and switch (Third Preview) JEP 507: Primitive Types in Patterns, instanceof, and switch (Third Preview) Owner Angelos Bimpoudis Type Feature Scope SE Status Closed&#8201;/&#8201;Delivered Release 25 Component specification&#8201;/&#8201;language Discussion amber dash dev at openjdk dot org Effort M Duration M Relates to JEP 488: Primitive Types in Patterns, instanceof, and switch (Second Preview) Reviewed by Alex Buckley, Brian Goetz Endorsed by Brian Goetz Created 2025/02/03 12:20 Updated 2025/08/26 12:38 Issue 8349215 Summary Enhance pattern matching by allowing primitive types in all pattern contexts, and extend instanceof and switch to work with all primitive types. This is a preview language feature . History This feature was originally proposed by JEP&#160;455 (JDK&#160;23) and re-previewed by JEP&#160;488 (JDK&#160;24), without change. We here propose to preview it for a third time, without change. Goals Enable uniform data exploration by allowing type patterns for all types, whether primitive or reference. Align type patterns with instanceof , and align instanceof with safe casting. Allow pattern matching to use primitive types in both nested and top-level pattern contexts. Provide easy-to-use constructs that eliminate the risk of losing information due to unsafe casts. Following the enhancements to switch in Java&#160;5 (enum switch ) and Java&#160;7 (string switch ), allow switch to process values of any primitive type. Non-Goals It is not a goal to add new kinds of conversions to the Java language. Motivation Multiple restrictions pertaining to primitive types impose friction when using pattern matching, instanceof , and switch . Eliminating these restrictions would make the Java language more uniform and more expressive. Pattern matching for switch does not support primitive type patterns The first restriction is that pattern matching for switch ( JEP&#160;441 ) does not support primitive type patterns, i.e., type patterns that specify a primitive type. Only type patterns that specify a reference type are supported, such as case Integer i or case String s . (Since Java 21, record patterns ( JEP&#160;440 ) are also supported for switch .) With support for primitive type patterns in switch , we could improve the switch expression switch (x.getStatus()) { case 0 -&gt; \"okay\"; case 1 -&gt; \"warning\"; case 2 -&gt; \"error\"; default -&gt; \"unknown status: \" + x.getStatus(); } by turning the default clause into a case clause with a primitive type pattern that exposes the matched value: switch (x.getStatus()) { case 0 -&gt; \"okay\"; case 1 -&gt; \"warning\"; case 2 -&gt; \"error\"; case int i -&gt; \"unknown status: \" + i; } Supporting primitive type patterns would also allow guards to inspect the matched value: switch (x.getYearlyFlights()) { case 0 -&gt; ...; case 1 -&gt; ...; case 2 -&gt; issueDiscount(); case int i when i &gt;= 100 -&gt; issueGoldCard(); case int i -&gt; ... appropriate action wh"
    }
  },
  {
    "url": "https://openjdk.org/jeps/470",
    "title": "JEP 470: PEM Encodings of Cryptographic Objects (Preview)",
    "content": {
      "title": "JEP 470: PEM Encodings of Cryptographic Objects (Preview)",
      "summary": "JEP 470: PEM Encodings of Cryptographic Objects (Preview) JEP 470: PEM Encodings of Cryptographic Objects (Preview) Owner Anthony Scarpino Type Feature Scope SE Status Closed&#8201;/&#8201;Delivered Release 25 Component security-libs&#8201;/&#8201;java.security Discussion security dash dev at openjdk dot org Effort M Duration M Relates to JEP 524: PEM Encodings of Cryptographic Objects (Second Preview) Reviewed by Alan Bateman, Sean Mullan Endorsed by Sean Mullan Created 2023/01/23 18:28 Updated",
      "sections": {
        "Summary": "Introduce an API for encoding objects that represent cryptographic keys, certificates, and certificate revocation lists into the widely-used Privacy-Enhanced Mail (PEM) transport format, and for decoding from that format back into objects. This is a preview API .",
        "Goals": "Ease of use &#8212; Define a concise API that converts between PEM text and objects representing keys, certificates, and certificate revocation lists. Support standards &#8212; Support conversions between PEM text and cryptographic objects that have standard representations in the binary formats PKCS#8 (for private keys), X.509 (public keys, certificates, and certificate revocation lists), and PKCS#8 v2.0 (encrypted private keys and asymmetric keys).",
        "Motivation": "The Java Platform API has rich support for cryptographic objects such as public keys, private keys, certificates, and certificate revocation lists. Developers use these objects to sign and verify signatures, verify network connections secured by TLS, and perform other cryptographic operations. Applications often send and receive representations of cryptographic objects, whether via user interfaces, over the network, or to and from storage devices. The Privacy-Enhanced Mail (PEM) format, defined by RFC 7468 , is often used for this purpose. This textual format was originally designed for sending cryptographic objects via e-mail, but over time it has been used and extended for other purposes. Certificate authorities issue certificate chains in the PEM format. Cryptographic libraries such as OpenSSL provide operations for generating and converting PEM-encoded cryptographic objects. Security-sensitive applications such as OpenSSH store communication keys in the PEM format. Hardware authent",
        "Description": "We introduce a new interface and three new classes in the java.security package: The DEREncodable interface is implemented by Java Platform API classes representing cryptographic objects with binary-encodable key or certificate material. The PEMEncoder and PEMDecoder classes are for encoding to and decoding from the PEM format. Instances of these classes are immutable and reusable, i.e., they do not retain information from the previously encoded or decoded cryptographic object. The PEMRecord class, which implements DEREncodable , is for encoding and decoding PEM texts representing cryptographic objects for which no Java Platform API exists. This is a preview API , disabled by default To use this API in JDK 25, you must enable preview APIs: Compile the program with javac --release 25 --enable-preview Main.java and run it with java --enable-preview Main ; or, When using the source code launcher , run the program with java --enable-preview Main.java ; or, When using jshell , start it with",
        "Alternatives": "A PEM API is a bridge between Base64 and cryptographic objects. We rejected many other potential designs because they did not fit well with the existing cryptographic APIs. While some of the",
        "Testing": "Tests will include: Verifying that all supported DEREncodable classes can encode and decode PEM text. Verifying that RSA, EC, and EdDSA cryptographic objects can be encoded and decoded. Reading PEM text generated by third-party applications, and vice versa. Negative",
        "Specification": "Review Compiler Conformance Core Libraries Governing Board HotSpot IDE Tooling &amp; Support Internationalization JMX Members Networking Porters Quality Security Serviceability Vulnerability Web Projects ( overview , archive ) Amber Babylon CRaC Code Tools Coin Common VM Interface Developers' Guide Device I/O Duke Galahad Graal IcedTea JDK 8 Updates JDK 9 JDK (&#8230;, 24 , 25 , 26 ) JDK Updates JMC Jigsaw Kona Lanai Leyden Lilliput Locale Enhancement Loom Memory Model Update Metropolis Multi-Language VM Nashorn New I/O OpenJFX Panama Penrose Port: AArch32 Port: AArch64 Port: BSD Port: Haiku Port: Mac OS X Port: MIPS Port: Mobile Port: PowerPC/AIX Port: RISC-V Port: s390x SCTP Shenandoah Skara Sumatra Tsan Valhalla Verona VisualVM Wakefield Zero ZGC &#169; 2025 Oracle Corporation and/or its affiliates Terms of Use &#183; License: GPLv2 &#183; Privacy &#183; Trademarks"
      },
      "fullText": "JEP 470: PEM Encodings of Cryptographic Objects (Preview) JEP 470: PEM Encodings of Cryptographic Objects (Preview) Owner Anthony Scarpino Type Feature Scope SE Status Closed&#8201;/&#8201;Delivered Release 25 Component security-libs&#8201;/&#8201;java.security Discussion security dash dev at openjdk dot org Effort M Duration M Relates to JEP 524: PEM Encodings of Cryptographic Objects (Second Preview) Reviewed by Alan Bateman, Sean Mullan Endorsed by Sean Mullan Created 2023/01/23 18:28 Updated 2025/08/28 06:00 Issue 8300911 Summary Introduce an API for encoding objects that represent cryptographic keys, certificates, and certificate revocation lists into the widely-used Privacy-Enhanced Mail (PEM) transport format, and for decoding from that format back into objects. This is a preview API . Goals Ease of use &#8212; Define a concise API that converts between PEM text and objects representing keys, certificates, and certificate revocation lists. Support standards &#8212; Support conversions between PEM text and cryptographic objects that have standard representations in the binary formats PKCS#8 (for private keys), X.509 (public keys, certificates, and certificate revocation lists), and PKCS#8 v2.0 (encrypted private keys and asymmetric keys). Motivation The Java Platform API has rich support for cryptographic objects such as public keys, private keys, certificates, and certificate revocation lists. Developers use these objects to sign and verify signatures, verify network connections secured by TLS, and perform other cryptographic operations. Applications often send and receive representations of cryptographic objects, whether via user interfaces, over the network, or to and from storage devices. The Privacy-Enhanced Mail (PEM) format, defined by RFC 7468 , is often used for this purpose. This textual format was originally designed for sending cryptographic objects via e-mail, but over time it has been used and extended for other purposes. Certificate authorities issue certificate chains in the PEM format. Cryptographic libraries such as OpenSSL provide operations for generating and converting PEM-encoded cryptographic objects. Security-sensitive applications such as OpenSSH store communication keys in the PEM format. Hardware authentication devices such as Yubikeys ingest and dispense PEM-encoded cryptographic objects. Here is an example of a PEM-encoded cryptographic object, in this case an elliptic curve public key: -----BEGIN PUBLIC KEY----- MFkwEwYHKoZIzj0CAQYIKoZIzj0DAQcDQgAEi/kRGOL7wCPTN4KJ2ppeSt5UYB6u cPjjuKDtFTXbguOIFDdZ65O/8HTUqS/sVzRF+dg7H3/tkQ/36KdtuADbwQ== -----END PUBLIC KEY----- A PEM text contains a Base64-encoded representation of the key's binary representation surrounded by a header and footer containing the words BEGIN and END , respectively. The remaining text in the header and the footer identifies the type of the cryptographic object, in this case a PUBLIC KEY . Details of the key, such as its algorithm and content, can b"
    }
  },
  {
    "url": "https://openjdk.org/jeps/502",
    "title": "JEP 502: Stable Values (Preview)",
    "content": {
      "title": "JEP 502: Stable Values (Preview)",
      "summary": "JEP 502: Stable Values (Preview) JEP 502: Stable Values (Preview) Author Per Minborg &amp; Maurizio Cimadamore Owner Per-Ake Minborg Type Feature Scope SE Status Closed&#8201;/&#8201;Delivered Release 25 Component core-libs&#8201;/&#8201;java.lang Discussion core dash libs dash dev at openjdk dot org Effort S Duration S Reviewed by Alex Buckley, Brian Goetz Endorsed by Mark Reinhold Created 2023/07/24 15:11 Updated 2025/07/16 19:11 Issue 8312611 Summary Introduce an API for stable values , which",
      "sections": {
        "Summary": "Introduce an API for stable values , which are objects that hold immutable data. Stable values are treated as constants by the JVM, enabling the same performance optimizations that are enabled by declaring a field final . Compared to final fields, however, stable values offer greater flexibility as to the timing of their initialization. This is a preview API .",
        "Goals": "Improve the startup of Java applications by breaking up the monolithic initialization of application state. Decouple the creation of stable values from their initialization, without significant performance penalties. Guarantee that stable values are initialized at most once, even in multi-threaded programs. Enable user code to safely enjoy constant-folding optimizations previously available only to JDK-internal code.",
        "Non-Goals": "It is not a goal to enhance the Java programming language with a means to declare stable values. It is not a goal to alter the semantics of final fields.",
        "Motivation": "Most Java developers have heard the advice to \"prefer immutability\" or \"minimize mutability\" ( Effective Java , Third Edition, Item 17). Immutability confers many advantages, since an immutable object can be only in one state and therefore can be shared freely across multiple threads. The Java Platform&#8217;s main tool for managing immutability is final fields. Unfortunately, final fields have restrictions. They must be set eagerly, either during construction for instance fields or during class initialization for static fields. Moreover, the order in which final fields are initialized is determined by the textual order in which the fields are declared. Such limitations restrict the applicability of final in many real-world applications. Immutability in practice Consider a simple application component that records events via a logger object: class OrderController { private final Logger logger = Logger.create(OrderController.class); void submitOrder(User user, List&lt;Product&gt; produc",
        "Description": "A stable value is an object, of type StableValue , that holds a single data value, its content . A stable value must be initialized some time before its content is first retrieved, and it is immutable thereafter. A stable value is a way to achieve deferred immutability. Here is the OrderController class, rewritten to use a stable value for its logger: class OrderController { // OLD: // private Logger logger = null; // NEW: private final StableValue&lt;Logger&gt; logger = StableValue.of(); Logger getLogger() { return logger.orElseSet(() -&gt; Logger.create(OrderController.class)); } void submitOrder(User user, List&lt;Product&gt; products) { getLogger().info(\"order started\"); ... getLogger().info(\"order submitted\"); } } The logger field holds a stable value, created with the static factory method StableValue.of() . Initially the stable value is unset, i.e., it holds no content. The getLogger method calls logger.orElseSet(...) on the stable value to retrieve its content. If the stable va",
        "Alternatives": ". First-class support for deferred immutability would fill an important gap between immutable and mutable fields.",
        "Risks and Assumptions": "The JVM can perform constant-folding optimizations only when it can trust that final fields can be updated only once. Unfortunately, the core reflection API allows instance final fields to be updated arbitrarily , except for fields that are members of hidden classes or records . In the long term we intend to limit the reflection API so that all instance final fields can be trusted, as part of the broader shift toward integrity by default . Until then, however, the mutability of most instance final fields will limit the constant-folding optimizations enabled by stable values. Fortunately, the reflection API does not allow static final fields to be updated arbitrarily, so constant folding across such fields is not only possible but routine. Thus the examples shown above that store stable values, suppliers, or lists in static final fields will have good performance. Installing Contributing Sponsoring Developers' Guide Vulnerabilities JDK GA/EA Builds Mailing lists Wiki &#183; IRC Mastodon",
        "Specification": "Review Compiler Conformance Core Libraries Governing Board HotSpot IDE Tooling &amp; Support Internationalization JMX Members Networking Porters Quality Security Serviceability Vulnerability Web Projects ( overview , archive ) Amber Babylon CRaC Code Tools Coin Common VM Interface Developers' Guide Device I/O Duke Galahad Graal IcedTea JDK 8 Updates JDK 9 JDK (&#8230;, 24 , 25 , 26 ) JDK Updates JMC Jigsaw Kona Lanai Leyden Lilliput Locale Enhancement Loom Memory Model Update Metropolis Multi-Language VM Nashorn New I/O OpenJFX Panama Penrose Port: AArch32 Port: AArch64 Port: BSD Port: Haiku Port: Mac OS X Port: MIPS Port: Mobile Port: PowerPC/AIX Port: RISC-V Port: s390x SCTP Shenandoah Skara Sumatra Tsan Valhalla Verona VisualVM Wakefield Zero ZGC &#169; 2025 Oracle Corporation and/or its affiliates Terms of Use &#183; License: GPLv2 &#183; Privacy &#183; Trademarks"
      },
      "fullText": "JEP 502: Stable Values (Preview) JEP 502: Stable Values (Preview) Author Per Minborg &amp; Maurizio Cimadamore Owner Per-Ake Minborg Type Feature Scope SE Status Closed&#8201;/&#8201;Delivered Release 25 Component core-libs&#8201;/&#8201;java.lang Discussion core dash libs dash dev at openjdk dot org Effort S Duration S Reviewed by Alex Buckley, Brian Goetz Endorsed by Mark Reinhold Created 2023/07/24 15:11 Updated 2025/07/16 19:11 Issue 8312611 Summary Introduce an API for stable values , which are objects that hold immutable data. Stable values are treated as constants by the JVM, enabling the same performance optimizations that are enabled by declaring a field final . Compared to final fields, however, stable values offer greater flexibility as to the timing of their initialization. This is a preview API . Goals Improve the startup of Java applications by breaking up the monolithic initialization of application state. Decouple the creation of stable values from their initialization, without significant performance penalties. Guarantee that stable values are initialized at most once, even in multi-threaded programs. Enable user code to safely enjoy constant-folding optimizations previously available only to JDK-internal code. Non-goals It is not a goal to enhance the Java programming language with a means to declare stable values. It is not a goal to alter the semantics of final fields. Motivation Most Java developers have heard the advice to \"prefer immutability\" or \"minimize mutability\" ( Effective Java , Third Edition, Item 17). Immutability confers many advantages, since an immutable object can be only in one state and therefore can be shared freely across multiple threads. The Java Platform&#8217;s main tool for managing immutability is final fields. Unfortunately, final fields have restrictions. They must be set eagerly, either during construction for instance fields or during class initialization for static fields. Moreover, the order in which final fields are initialized is determined by the textual order in which the fields are declared. Such limitations restrict the applicability of final in many real-world applications. Immutability in practice Consider a simple application component that records events via a logger object: class OrderController { private final Logger logger = Logger.create(OrderController.class); void submitOrder(User user, List&lt;Product&gt; products) { logger.info(\"order started\"); ... logger.info(\"order submitted\"); } } Since logger is a final field of the OrderController class, this field must be initialized eagerly, whenever an instance of OrderController is created. This means that creating a new OrderController can be slow &#8212; after all, obtaining a logger sometimes entails expensive operations such as reading and parsing configuration data, or preparing the storage where logging events will be recorded. Furthermore, if an application is composed of not just one component with a logger but several compon"
    }
  },
  {
    "url": "https://openjdk.org/jeps/505",
    "title": "JEP 505: Structured Concurrency (Fifth Preview)",
    "content": {
      "title": "JEP 505: Structured Concurrency (Fifth Preview)",
      "summary": "JEP 505: Structured Concurrency (Fifth Preview) JEP 505: Structured Concurrency (Fifth Preview) Authors Alan Bateman, Viktor Klang, &amp; Ron Pressler Owner Alan Bateman Type Feature Scope SE Status Closed&#8201;/&#8201;Delivered Release 25 Component core-libs Discussion loom dash dev at openjdk dot org Relates to JEP 499: Structured Concurrency (Fourth Preview) JEP 525: Structured Concurrency (Sixth Preview) Reviewed by Paul Sandoz Endorsed by Paul Sandoz Created 2024/09/18 04:58 Updated 2025/0",
      "sections": {
        "Summary": "Simplify concurrent programming by introducing an API for structured concurrency . Structured concurrency treats groups of related tasks running in different threads as single units of work, thereby streamlining error handling and cancellation, improving reliability, and enhancing observability. This is a preview API . History Structured Concurrency incubated in JDK 19 via JEP 428 and JDK 20 via JEP 437 . It previewed in JDK 21 via JEP 453 , with the fork method changed to return a Subtask rather than a Future . It re-previewed in JDK 22 via JEP 462 , JDK 23 via JEP 480 , and JDK 24 via JEP 499 . We propose to preview the API once more in JDK 25 with several",
        "Goals": "Promote a style of concurrent programming that can eliminate common risks arising from cancellation and shutdown, such as thread leaks and cancellation delays. Improve the observability of concurrent code.",
        "Non-Goals": "It is not a goal to replace any of the concurrency constructs in the java.util.concurrent package, such as ExecutorService or Future . It is not a goal to create the definitive structured concurrency API for all Java programs. Other structured concurrency constructs can be defined by third-party libraries or in future JDK releases. It is not a goal to define a means of sharing streams of data among threads (i.e., channels ). We might propose to do so in the future. It is not a goal to replace the existing thread interruption mechanism with a new thread cancellation mechanism. We might propose to do so in the future.",
        "Motivation": "We manage complexity in programs by breaking tasks down into multiple subtasks. In ordinary single-threaded code, the subtasks execute sequentially. However, if the subtasks are sufficiently independent of each other, and if there are sufficient hardware resources, then the overall task can be made to run faster, i.e., with lower latency, by executing the subtasks concurrently. For example, a task that composes the results of multiple I/O operations will run faster if each I/O operation executes concurrently in its own thread. Virtual threads ( JEP 444 ) make it cost-effective to dedicate a thread to every such I/O operation, but managing the huge number of threads that can result remains a challenge. Unstructured concurrency with ExecutorService The java.util.concurrent.ExecutorService API, introduced in Java 5, can execute subtasks concurrently. For example, here is a method, handle() , that represents a task in a server application. It handles an incoming request by submitting two s",
        "Description": "The principal class of the structured concurrency API is StructuredTaskScope , in the java.util.concurrent package. This class allows us to structure a task as a family of concurrent subtasks, and to coordinate them as a unit. Subtasks are executed in their own threads by forking them individually and then joining them as a unit. StructuredTaskScope confines the lifetimes of the subtasks to a clear lexical scope in which all of a task's interactions with its subtasks &#8212; forking, joining, handling errors, and composing results &#8212; takes place. Here is the handle() example from earlier, revised to use StructuredTaskScope : Response handle() throws InterruptedException { try (var scope = StructuredTaskScope.open()) { Subtask&lt;String&gt; user = scope.fork(() -&gt; findUser()); Subtask&lt;Integer&gt; order = scope.fork(() -&gt; fetchOrder()); scope.join(); // Join subtasks, propagating exceptions // Both subtasks have succeeded, so compose their results return new Response(user.g",
        "Alternatives": "Enhance the ExecutorService interface We prototyped an implementation of this interface that always enforces structure and restricts which threads can submit tasks. However, we found it to be problematic because most uses of ExecutorService , and its parent interface Executor , in the JDK and in the ecosystem are not structured. Reusing the same API for a far more restricted concept is bound to cause confusion. For example, passing a structured ExecutorService instance to existing methods that accept this type would be all but certain to throw exceptions in most situations. Have the fork methods return a Future When the StructuredTaskScope API was incubating, the fork methods returned a Future . This provided a sense of familiarity, by making these methods resemble the existing ExecutorService::submit method. However, the fact that StructuredTaskScope is intended to be used in a structured way, while ExecutorService is not, brought more confusion than clarity. The familiar use of Futur",
        "API Changes": ". In particular, a StructuredTaskScope is now opened via static factory methods rather than public constructors. The zero-parameter open factory method covers the common case by creating a StructuredTaskScope that waits for all subtasks to succeed or any subtask to fail. Other policies and outcomes can be implemented by providing an appropriate Joiner to one of the richer open factory methods.",
        "Specification": "Review Compiler Conformance Core Libraries Governing Board HotSpot IDE Tooling &amp; Support Internationalization JMX Members Networking Porters Quality Security Serviceability Vulnerability Web Projects ( overview , archive ) Amber Babylon CRaC Code Tools Coin Common VM Interface Developers' Guide Device I/O Duke Galahad Graal IcedTea JDK 8 Updates JDK 9 JDK (&#8230;, 24 , 25 , 26 ) JDK Updates JMC Jigsaw Kona Lanai Leyden Lilliput Locale Enhancement Loom Memory Model Update Metropolis Multi-Language VM Nashorn New I/O OpenJFX Panama Penrose Port: AArch32 Port: AArch64 Port: BSD Port: Haiku Port: Mac OS X Port: MIPS Port: Mobile Port: PowerPC/AIX Port: RISC-V Port: s390x SCTP Shenandoah Skara Sumatra Tsan Valhalla Verona VisualVM Wakefield Zero ZGC &#169; 2025 Oracle Corporation and/or its affiliates Terms of Use &#183; License: GPLv2 &#183; Privacy &#183; Trademarks"
      },
      "fullText": "JEP 505: Structured Concurrency (Fifth Preview) JEP 505: Structured Concurrency (Fifth Preview) Authors Alan Bateman, Viktor Klang, &amp; Ron Pressler Owner Alan Bateman Type Feature Scope SE Status Closed&#8201;/&#8201;Delivered Release 25 Component core-libs Discussion loom dash dev at openjdk dot org Relates to JEP 499: Structured Concurrency (Fourth Preview) JEP 525: Structured Concurrency (Sixth Preview) Reviewed by Paul Sandoz Endorsed by Paul Sandoz Created 2024/09/18 04:58 Updated 2025/09/23 15:13 Issue 8340343 Summary Simplify concurrent programming by introducing an API for structured concurrency . Structured concurrency treats groups of related tasks running in different threads as single units of work, thereby streamlining error handling and cancellation, improving reliability, and enhancing observability. This is a preview API . History Structured Concurrency incubated in JDK 19 via JEP 428 and JDK 20 via JEP 437 . It previewed in JDK 21 via JEP 453 , with the fork method changed to return a Subtask rather than a Future . It re-previewed in JDK 22 via JEP 462 , JDK 23 via JEP 480 , and JDK 24 via JEP 499 . We propose to preview the API once more in JDK 25 with several API changes. In particular, a StructuredTaskScope is now opened via static factory methods rather than public constructors. The zero-parameter open factory method covers the common case by creating a StructuredTaskScope that waits for all subtasks to succeed or any subtask to fail. Other policies and outcomes can be implemented by providing an appropriate Joiner to one of the richer open factory methods. Goals Promote a style of concurrent programming that can eliminate common risks arising from cancellation and shutdown, such as thread leaks and cancellation delays. Improve the observability of concurrent code. Non-Goals It is not a goal to replace any of the concurrency constructs in the java.util.concurrent package, such as ExecutorService or Future . It is not a goal to create the definitive structured concurrency API for all Java programs. Other structured concurrency constructs can be defined by third-party libraries or in future JDK releases. It is not a goal to define a means of sharing streams of data among threads (i.e., channels ). We might propose to do so in the future. It is not a goal to replace the existing thread interruption mechanism with a new thread cancellation mechanism. We might propose to do so in the future. Motivation We manage complexity in programs by breaking tasks down into multiple subtasks. In ordinary single-threaded code, the subtasks execute sequentially. However, if the subtasks are sufficiently independent of each other, and if there are sufficient hardware resources, then the overall task can be made to run faster, i.e., with lower latency, by executing the subtasks concurrently. For example, a task that composes the results of multiple I/O operations will run faster if each I/O operation executes concurrently in its own thread. Vi"
    }
  },
  {
    "url": "https://openjdk.org/jeps/508",
    "title": "JEP 508: Vector API (Tenth Incubator)",
    "content": {
      "title": "JEP 508: Vector API (Tenth Incubator)",
      "summary": "JEP 508: Vector API (Tenth Incubator) JEP 508: Vector API (Tenth Incubator) Owner Ian Graves Type Feature Scope JDK Status Closed&#8201;/&#8201;Delivered Release 25 Component core-libs Discussion panama dash dev at openjdk dot org Effort XS Duration XS Relates to JEP 489: Vector API (Ninth Incubator) Reviewed by Jatin Bhateja, Sandhya Viswanathan, Vladimir Ivanov Endorsed by Paul Sandoz Created 2025/03/31 18:19 Updated 2025/05/21 21:28 Issue 8353296 Summary Introduce an API to express vector com",
      "sections": {
        "Summary": "Introduce an API to express vector computations that reliably compile at runtime to optimal vector instructions on supported CPUs, thus achieving performance superior to equivalent scalar computations. History We first proposed the Vector API in JEP&#160;338 and integrated it into JDK&#160;16 as an incubating API . We proposed further rounds of incubation in JEP&#160;414 (integrated into JDK&#160;17), JEP&#160;417 (JDK&#160;18), JEP&#160;426 (JDK&#160;19), JEP&#160;438 (JDK&#160;20), JEP&#160;448 (JDK&#160;21), JEP&#160;460 (JDK&#160;22), JEP&#160;469 (JDK&#160;23), and JEP&#160;489 (JDK&#160;24). We here propose to re-incubate the Vector API in JDK&#160;25 with one API change and two notable implementation changes: VectorShuffle now supports access to and from MemorySegment. The implementation now links to native mathematical-function libraries via the Foreign Function &amp; Memory API ( JEP&#160;454 ) rather than custom C++ code inside the HotSpot JVM, thereby improving maintainabili",
        "Goals": "Clear and concise API &#8212; The API should be capable of clearly and concisely expressing a wide range of vector computations consisting of sequences of vector operations composed within loops and, possibly, with control flow. It should be possible to express a computation that is generic with respect to vector size, or the number of lanes per vector, thus enabling such computations to be portable across hardware supporting different vector sizes. Platform agnostic &#8212; The API should be CPU-architecture agnostic, enabling implementations on multiple architectures supporting vector instructions. As is usual in Java APIs, where platform optimization and portability conflict then we will bias toward making the API portable, even if that results in some platform-specific idioms not being expressible in portable code. Reliable compilation and performance on x64 and AArch64 CPUs &#8212; On capable x64 CPUs, the Java runtime, specifically the HotSpot C2 compiler, should compile vector o",
        "Non-Goals": "It is not a goal to enhance the existing auto-vectorization algorithm in the HotSpot JVM. It is not a goal to implement support for vector instructions on CPU architectures other than x64 and AArch64, although the API must not rule out such implementations. Other contributors have already begun to implement the Vector API on other architectures, such as RISC-V . It is not a goal to support the C1 compiler. It is not a goal to guarantee support for strict floating point calculations, which are required by the Java Platform for scalar operations. The results of floating point operations performed on floating point scalars may differ from equivalent floating point operations performed on vectors of floating point scalars. Any deviations will be clearly documented. This non-goal does not rule out options to express or control the desired precision or reproducibility of floating point vector computations.",
        "Motivation": "A vector computation consists of a sequence of operations on vectors. A vector comprises a (usually) fixed sequence of scalar values, where the number of scalar values corresponds to the number of hardware-defined vector lanes. A binary operation applied to two vectors of the same length applies the equivalent scalar operation on the corresponding scalar values from each vector. This is commonly referred to as Single Instruction Multiple Data (SIMD). Vector operations express a degree of parallelism that enables more work to be performed in a single CPU cycle and thus can result in significant performance gains. For example, given two vectors, each containing a sequence of eight integers (i.e., eight lanes), the two vectors can be added together using a single hardware instruction. The vector addition instruction operates on sixteen integers, performing eight integer additions, in the time it would ordinarily take to operate on two integers, performing one integer addition. The HotSpot",
        "Description": "A vector is represented by the abstract class Vector&lt;E&gt; . The type variable E is instantiated as the boxed type of the scalar primitive integral or floating point element types covered by the vector. A vector also has a shape , which defines the size, in bits, of the vector. The shape of a vector governs how an instance of Vector&lt;E&gt; is mapped to a hardware vector register when vector computations are compiled by the HotSpot C2 compiler. The length of a vector, i.e., the number of lanes or elements, is the vector size divided by the element size. The element types ( E ) supported are Byte , Short , Integer , Long , Float and Double , corresponding to the scalar primitive types byte , short , int , long , float and double , respectively. The shapes supported correspond to vector sizes of 64, 128, 256, and 512 bits, as well as max bits. A 512-bit shape can pack byte s into 64 lanes or pack int s into 16 lanes, and a vector of such a shape can operate on 64 byte s at a time or ",
        "Alternatives": "HotSpot's auto-vectorization is an alternative approach, but it would require significant work. It would, moreover, still be fragile and limited compared to the Vector API, since auto-vectorization with complex control flow is very hard to perform. In general, even after decades of research &#8212; especially for FORTRAN and C array loops &#8212; it seems that auto-vectorization of scalar code is not a reliable tactic for optimizing ad-hoc user-written loops unless the user pays unusually careful attention to unwritten contracts about exactly which loops a compiler is prepared to auto-vectorize. It is too easy to write a loop that fails to auto-vectorize, for a reason that no human reader can detect. Years of work on auto-vectorization, even in HotSpot, have left us with lots of optimization machinery that works only on special occasions. We want to enjoy the use of this machinery more often!",
        "Testing": "We will develop combinatorial unit tests to ensure coverage for all operations, for all supported types and shapes, over various data sets. We will also develop performance tests to ensure that performance",
        "Risks and Assumptions": "The Vector API uses box types (e.g., Integer ) as proxies for primitive types (e.g., int ). This decision is forced by the current limitations of Java generics, which are hostile to primitive types. When Project Valhalla eventually introduces more capable generics then the current decision will seem awkward, and will likely need changing. We assume that such changes will be possible without excessive backward incompatibility. Installing Contributing Sponsoring Developers' Guide Vulnerabilities JDK GA/EA Builds Mailing lists Wiki &#183; IRC Mastodon Bluesky Bylaws &#183; Census Legal Workshop JEP Process Source code GitHub Mercurial Tools Git jtreg harness Groups (overview) Adoption Build Client Libraries Compatibility &amp;",
        "Specification": ". The Vector&lt;E&gt; class declares a set of methods for common vector operations supported by all element types. For operations specific to an element type there are six abstract subclasses of Vector&lt;E&gt; , one for each supported element type: ByteVector , ShortVector , IntVector , LongVector , FloatVector , and DoubleVector . These type-specific subclasses define additional operations that are bound to the element type, since the method signature refers either to the element type or to the related array type. Examples of such operations include reduction (e.g., summing all lanes to a scalar value), and copying a vector's elements into an array. These subclasses also define additional full-service operations specific to the integral subtypes (e.g., bitwise operations such as logical or), as well as operations specific to the floating point types (e.g., transcendental mathematical functions such as exponentiation). As an implementation matter, these type-specific subclasses of Vec"
      },
      "fullText": "JEP 508: Vector API (Tenth Incubator) JEP 508: Vector API (Tenth Incubator) Owner Ian Graves Type Feature Scope JDK Status Closed&#8201;/&#8201;Delivered Release 25 Component core-libs Discussion panama dash dev at openjdk dot org Effort XS Duration XS Relates to JEP 489: Vector API (Ninth Incubator) Reviewed by Jatin Bhateja, Sandhya Viswanathan, Vladimir Ivanov Endorsed by Paul Sandoz Created 2025/03/31 18:19 Updated 2025/05/21 21:28 Issue 8353296 Summary Introduce an API to express vector computations that reliably compile at runtime to optimal vector instructions on supported CPUs, thus achieving performance superior to equivalent scalar computations. History We first proposed the Vector API in JEP&#160;338 and integrated it into JDK&#160;16 as an incubating API . We proposed further rounds of incubation in JEP&#160;414 (integrated into JDK&#160;17), JEP&#160;417 (JDK&#160;18), JEP&#160;426 (JDK&#160;19), JEP&#160;438 (JDK&#160;20), JEP&#160;448 (JDK&#160;21), JEP&#160;460 (JDK&#160;22), JEP&#160;469 (JDK&#160;23), and JEP&#160;489 (JDK&#160;24). We here propose to re-incubate the Vector API in JDK&#160;25 with one API change and two notable implementation changes: VectorShuffle now supports access to and from MemorySegment. The implementation now links to native mathematical-function libraries via the Foreign Function &amp; Memory API ( JEP&#160;454 ) rather than custom C++ code inside the HotSpot JVM, thereby improving maintainability. Addition, subtraction, division, multiplication, square root, and fused multiply/add operations on Float16 values are now auto-vectorized on supporting x64 CPUs. The Vector API will incubate until necessary features of Project Valhalla become available as preview features. At that time, we will adapt the Vector API and its implementation to use them and then promote the Vector API from incubation to preview. Goals Clear and concise API &#8212; The API should be capable of clearly and concisely expressing a wide range of vector computations consisting of sequences of vector operations composed within loops and, possibly, with control flow. It should be possible to express a computation that is generic with respect to vector size, or the number of lanes per vector, thus enabling such computations to be portable across hardware supporting different vector sizes. Platform agnostic &#8212; The API should be CPU-architecture agnostic, enabling implementations on multiple architectures supporting vector instructions. As is usual in Java APIs, where platform optimization and portability conflict then we will bias toward making the API portable, even if that results in some platform-specific idioms not being expressible in portable code. Reliable compilation and performance on x64 and AArch64 CPUs &#8212; On capable x64 CPUs, the Java runtime, specifically the HotSpot C2 compiler, should compile vector operations to corresponding efficient and performant vector instructions, such as those supported by Streaming SIMD E"
    }
  },
  {
    "url": "https://openjdk.org/jeps/501",
    "title": "JEP 501: Deprecate the 32-bit x86 Port for Removal",
    "content": {
      "title": "JEP 501: Deprecate the 32-bit x86 Port for Removal",
      "summary": "JEP 501: Deprecate the 32-bit x86 Port for Removal JEP 501: Deprecate the 32-bit x86 Port for Removal Owner Aleksey Shipilev Type Feature Scope Implementation Status Closed&#8201;/&#8201;Delivered Release 24 Component hotspot&#8201;/&#8201;other Discussion hotspot dash dev at openjdk dot org Effort S Duration S Relates to JEP 449: Deprecate the Windows 32-bit x86 Port for Removal JEP 479: Remove the Windows 32-bit x86 Port JEP 503: Remove the 32-bit x86 Port Reviewed by Coleen Phillimore, Magnus",
      "sections": {
        "Summary": "Deprecate the 32-bit x86 port, with the intent to remove it in a future release. This will thereby deprecate the Linux 32-bit x86 port, which is the only 32-bit x86 port remaining in the JDK. It will also, effectively, deprecate any remaining downstream 32-bit x86 ports. After the 32-bit x86 port is removed, the architecture-agnostic Zero port will be the only way to run Java programs on 32-bit x86 processors.",
        "Goals": "Unblock new features that require platform-specific support from having to implement 32-bit x86 fallbacks. Mark the port, and related port-specific features, as deprecated for removal in the relevant documentation, configuration scripts, and test jobs.",
        "Non-Goals": "It is not a goal to deprecate any other 32-bit port.",
        "Motivation": "As noted in a recent discussion involving the current 32-bit x86 maintainer and interested parties, the cost of maintaining this port outweighs the benefits. Maintaining parity with new features, such as Loom, the Foreign Function &amp; Memory API (FFM), the Vector API, late GC barrier expansion, etc., is a major opportunity cost. Deprecating and eventually removing the port would allow OpenJDK developers to accelerate the development of new features and enhancements. Deprecating this port in JDK 24 will allow us to remove it in JDK&#160;25.",
        "Description": "An attempt to configure a 32-bit x86 build will produce: $ bash ./configure ... checking compilation type... native configure: error: The 32-bit x86 port is deprecated and may be removed in a future release. \\ Use --enable-deprecated-ports=yes to suppress this error. configure exiting with result code 1 $ The build configuration option --enable-deprecated-ports=yes will suppress the error and continue: $ bash ./configure --enable-deprecated-ports=yes ... checking compilation type... native configure: WARNING: The 32-bit x86 port is deprecated and may be removed in a future release. ... Build performance",
        "Alternatives": "The alternative would be to continue to support 32-bit x86. This would require active maintainers who can provide a sustainable and performant implementation of virtual threads, as well as future JEPs, to ensure that the JDK on 32-bit x86 continues to meet the expectations of Java developers. There are no prospective maintainers who are willing to take that role. Installing Contributing Sponsoring Developers' Guide Vulnerabilities JDK GA/EA Builds Mailing lists Wiki &#183; IRC Mastodon Bluesky Bylaws &#183; Census Legal Workshop JEP Process Source code GitHub Mercurial Tools Git jtreg harness Groups (overview) Adoption Build Client Libraries Compatibility &amp;",
        "Risks and Assumptions": "There is no pressing industry need for 32-bit x86 with modern JDKs &#8212; We assume that the x86 world has moved firmly to the 64-bit realm. No new 32-bit-only x86 hardware is being manufactured. The remaining 32-bit x86 deployments are legacies. Industry support has dwindled to match this reality. Windows 10, the last Windows operating system to support 32-bit operation, will reach End of Life in October 2025 , and the Windows 32-bit x86 port has already been removed from the JDK ( JEP&#160;479 ). Debian plans to stop supporting 32-bit x86 in the near future. There is enough margin for backport safety with releases that still support 32-bit x86 &#8212; Not having the Linux 32-bit x86 port in the main line means that backports from the main line to actively supported LTS releases will be more complicated, since they will have to be reconciled with the Linux 32-bit x86 port still in those releases. We assume that the majority of older Linux 32-bit x86 application stacks are still on JD",
        "Specification": "Review Compiler Conformance Core Libraries Governing Board HotSpot IDE Tooling &amp; Support Internationalization JMX Members Networking Porters Quality Security Serviceability Vulnerability Web Projects ( overview , archive ) Amber Babylon CRaC Code Tools Coin Common VM Interface Developers' Guide Device I/O Duke Galahad Graal IcedTea JDK 8 Updates JDK 9 JDK (&#8230;, 24 , 25 , 26 ) JDK Updates JMC Jigsaw Kona Lanai Leyden Lilliput Locale Enhancement Loom Memory Model Update Metropolis Multi-Language VM Nashorn New I/O OpenJFX Panama Penrose Port: AArch32 Port: AArch64 Port: BSD Port: Haiku Port: Mac OS X Port: MIPS Port: Mobile Port: PowerPC/AIX Port: RISC-V Port: s390x SCTP Shenandoah Skara Sumatra Tsan Valhalla Verona VisualVM Wakefield Zero ZGC &#169; 2025 Oracle Corporation and/or its affiliates Terms of Use &#183; License: GPLv2 &#183; Privacy &#183; Trademarks"
      },
      "fullText": "JEP 501: Deprecate the 32-bit x86 Port for Removal JEP 501: Deprecate the 32-bit x86 Port for Removal Owner Aleksey Shipilev Type Feature Scope Implementation Status Closed&#8201;/&#8201;Delivered Release 24 Component hotspot&#8201;/&#8201;other Discussion hotspot dash dev at openjdk dot org Effort S Duration S Relates to JEP 449: Deprecate the Windows 32-bit x86 Port for Removal JEP 479: Remove the Windows 32-bit x86 Port JEP 503: Remove the 32-bit x86 Port Reviewed by Coleen Phillimore, Magnus Ihse Bursie, Vladimir Kozlov Endorsed by Vladimir Kozlov Created 2024/08/13 09:08 Updated 2025/02/19 23:38 Issue 8338285 Summary Deprecate the 32-bit x86 port, with the intent to remove it in a future release. This will thereby deprecate the Linux 32-bit x86 port, which is the only 32-bit x86 port remaining in the JDK. It will also, effectively, deprecate any remaining downstream 32-bit x86 ports. After the 32-bit x86 port is removed, the architecture-agnostic Zero port will be the only way to run Java programs on 32-bit x86 processors. Goals Unblock new features that require platform-specific support from having to implement 32-bit x86 fallbacks. Mark the port, and related port-specific features, as deprecated for removal in the relevant documentation, configuration scripts, and test jobs. Non-Goals It is not a goal to deprecate any other 32-bit port. Motivation As noted in a recent discussion involving the current 32-bit x86 maintainer and interested parties, the cost of maintaining this port outweighs the benefits. Maintaining parity with new features, such as Loom, the Foreign Function &amp; Memory API (FFM), the Vector API, late GC barrier expansion, etc., is a major opportunity cost. Deprecating and eventually removing the port would allow OpenJDK developers to accelerate the development of new features and enhancements. Deprecating this port in JDK 24 will allow us to remove it in JDK&#160;25. Description An attempt to configure a 32-bit x86 build will produce: $ bash ./configure ... checking compilation type... native configure: error: The 32-bit x86 port is deprecated and may be removed in a future release. \\ Use --enable-deprecated-ports=yes to suppress this error. configure exiting with result code 1 $ The build configuration option --enable-deprecated-ports=yes will suppress the error and continue: $ bash ./configure --enable-deprecated-ports=yes ... checking compilation type... native configure: WARNING: The 32-bit x86 port is deprecated and may be removed in a future release. ... Build performance summary: * Cores to use: 32 * Memory limit: 96601 MB The following warnings were produced. Repeated here for convenience: WARNING: The 32-bit x86 port is deprecated and may be removed in a future release. $ There will be no guarantee that the port will build, much less function. In order to unblock mainline development, we have already disabled Linux 32-bit x86 builds in the GitHub Actions defined in the JDK source repository ( 8338286 ). We will c"
    }
  },
  {
    "url": "https://openjdk.org/jeps/471",
    "title": "JEP 471: Deprecate the Memory-Access Methods in sun.misc.Unsafe for Removal",
    "content": {
      "title": "JEP 471: Deprecate the Memory-Access Methods in sun.misc.Unsafe for Removal",
      "summary": "JEP 471: Deprecate the Memory-Access Methods in sun.misc.Unsafe for Removal JEP 471: Deprecate the Memory-Access Methods in sun.misc.Unsafe for Removal Author Ron Pressler &amp; Alex Buckley Owner Ron Pressler Type Feature Scope JDK Status Closed&#8201;/&#8201;Delivered Release 23 Component core-libs Discussion jdk dash dev at openjdk dot org Relates to JEP 498: Warn upon Use of Memory-Access Methods in sun.misc.Unsafe Reviewed by Alan Bateman, Brian Goetz, Mark Reinhold, Maurizio Cimadamore, Pa",
      "sections": {
        "Summary": "Deprecate the memory-access methods in sun.misc.Unsafe for removal in a future release. These unsupported methods have been superseded by standard APIs, namely the VarHandle API ( JEP&#160;193 , JDK&#160;9) and the Foreign Function &amp; Memory API ( JEP&#160;454 , JDK&#160;22). We strongly encourage library developers to migrate from sun.misc.Unsafe to supported replacements, so that applications can migrate smoothly to modern JDK releases.",
        "Goals": "Prepare the ecosystem for the removal of the memory-access methods in sun.misc.Unsafe in a future JDK release. Help developers realize when their applications rely, directly or indirectly, on the memory-access methods in sun.misc.Unsafe .",
        "Non-Goals": "It is not a goal to remove the sun.misc.Unsafe class entirely. A small number of its methods are not used for memory access; these will be deprecated and removed separately. It is not a goal to change other sun.* classes in the jdk.unsupported module.",
        "Motivation": "The sun.misc.Unsafe class was introduced in 2002 as a way for Java classes in the JDK to perform low-level operations. Most of its methods &#8212; 79 out of 87 &#8212; are for accessing memory, either in the JVM's garbage-collected heap or in off-heap memory, which is not controlled by the JVM. As the name of the class suggests, these memory-access methods are unsafe: They can lead to undefined behavior, including JVM crashes. Therefore, they were not exposed as a standard API. They were neither envisaged for use by a broad range of clients nor intended to be permanent. Rather, they were introduced with the assumption that they were exclusively for use within the JDK, and that callers within the JDK would perform exhaustive safety checks before using them, and that safe standard APIs for this functionality would eventually be added to the Java Platform. However, with no way in 2002 to prevent sun.misc.Unsafe from being used outside the JDK, its memory-access methods became a handy tool",
        "Description": "The memory-access methods of sun.misc.Unsafe can be divided into three categories: Methods for accessing on-heap memory ( on-heap ), Methods for accessing off-heap memory ( off-heap ), and Methods for accessing both on-heap and off-heap memory ( bimodal &#8212; a bimodal method takes a parameter which either refers to an object on the heap or is null to signify off-heap access). We will deprecate and remove the methods in phases, where each phase takes place in a separate JDK feature release: Deprecate all of the memory-access methods &#8212; on-heap, off-heap, and bimodal &#8212; for removal. This will cause compile-time deprecation warnings for code that refers to the methods, alerting library developers to their forthcoming removal. A new command-line option, described below, will enable application developers and users to receive runtime warnings when the methods are used. Distinct from deprecation warnings, javac has issued warnings about the use of sun.misc.Unsafe since 2006: war",
        "Alternatives": ". Over the past several years, we have introduced two standard APIs that are safe and performant replacements for the memory-access methods in sun.misc.Unsafe : java.lang.invoke.VarHandle , introduced in JDK&#160;9 ( JEP&#160;193 ), provides methods to safely and efficiently manipulate on-heap memory, i.e., fields of objects, static fields of classes, and elements of arrays. java.lang.foreign.MemorySegment , introduced in JDK&#160;22 ( JEP&#160;454 ), provides methods to safely and efficiently access off-heap memory, sometimes in cooperation with VarHandle . These standard APIs guarantee no undefined behavior, promise long-term stability, and have high-quality integration with the tooling and documentation of the Java Platform (examples of their use are given below ). Given the availability of these APIs, it is now appropriate to deprecate and eventually remove the memory-access methods in sun.misc.Unsafe . Removing the memory-access methods in sun.misc.Unsafe is part of a long-term co",
        "Risks and Assumptions": "Over the years, methods in sun.misc.Unsafe that are unrelated to memory access have been deprecated for removal after standard replacements were introduced, and many of them have already been removed: sun.misc.Unsafe::defineClass was removed in JDK&#160;11 after java.lang.invoke.MethodHandles.Lookup::defineClass was introduced in JDK&#160;9. sun.misc.Unsafe::defineAnonymousClass was removed in JDK&#160;17 after MethodHandles.Lookup::defineHiddenClass was introduced in in JDK&#160;15 . sun.misc.Unsafe::{ensureClass,shouldBe}Initialized were removed in JDK&#160;22 after MethodHandles.Lookup::ensureInitialized was introduced in JDK&#160;15. Six miscellaneous methods in sun.misc.Unsafe were deprecated for removal in JDK&#160;22 after standard replacements were available. We have seen very little impact in the Java ecosystem from the removal of these relatively obscure methods. However, the memory-access methods are much better known. This proposal assumes that removing them will impact lib",
        "Specification": "Review Compiler Conformance Core Libraries Governing Board HotSpot IDE Tooling &amp; Support Internationalization JMX Members Networking Porters Quality Security Serviceability Vulnerability Web Projects ( overview , archive ) Amber Babylon CRaC Code Tools Coin Common VM Interface Developers' Guide Device I/O Duke Galahad Graal IcedTea JDK 8 Updates JDK 9 JDK (&#8230;, 24 , 25 , 26 ) JDK Updates JMC Jigsaw Kona Lanai Leyden Lilliput Locale Enhancement Loom Memory Model Update Metropolis Multi-Language VM Nashorn New I/O OpenJFX Panama Penrose Port: AArch32 Port: AArch64 Port: BSD Port: Haiku Port: Mac OS X Port: MIPS Port: Mobile Port: PowerPC/AIX Port: RISC-V Port: s390x SCTP Shenandoah Skara Sumatra Tsan Valhalla Verona VisualVM Wakefield Zero ZGC &#169; 2025 Oracle Corporation and/or its affiliates Terms of Use &#183; License: GPLv2 &#183; Privacy &#183; Trademarks"
      },
      "fullText": "JEP 471: Deprecate the Memory-Access Methods in sun.misc.Unsafe for Removal JEP 471: Deprecate the Memory-Access Methods in sun.misc.Unsafe for Removal Author Ron Pressler &amp; Alex Buckley Owner Ron Pressler Type Feature Scope JDK Status Closed&#8201;/&#8201;Delivered Release 23 Component core-libs Discussion jdk dash dev at openjdk dot org Relates to JEP 498: Warn upon Use of Memory-Access Methods in sun.misc.Unsafe Reviewed by Alan Bateman, Brian Goetz, Mark Reinhold, Maurizio Cimadamore, Paul Sandoz Endorsed by Alan Bateman Created 2024/01/05 15:46 Updated 2025/02/20 20:13 Issue 8323072 Summary Deprecate the memory-access methods in sun.misc.Unsafe for removal in a future release. These unsupported methods have been superseded by standard APIs, namely the VarHandle API ( JEP&#160;193 , JDK&#160;9) and the Foreign Function &amp; Memory API ( JEP&#160;454 , JDK&#160;22). We strongly encourage library developers to migrate from sun.misc.Unsafe to supported replacements, so that applications can migrate smoothly to modern JDK releases. Goals Prepare the ecosystem for the removal of the memory-access methods in sun.misc.Unsafe in a future JDK release. Help developers realize when their applications rely, directly or indirectly, on the memory-access methods in sun.misc.Unsafe . Non-Goals It is not a goal to remove the sun.misc.Unsafe class entirely. A small number of its methods are not used for memory access; these will be deprecated and removed separately. It is not a goal to change other sun.* classes in the jdk.unsupported module. Motivation The sun.misc.Unsafe class was introduced in 2002 as a way for Java classes in the JDK to perform low-level operations. Most of its methods &#8212; 79 out of 87 &#8212; are for accessing memory, either in the JVM's garbage-collected heap or in off-heap memory, which is not controlled by the JVM. As the name of the class suggests, these memory-access methods are unsafe: They can lead to undefined behavior, including JVM crashes. Therefore, they were not exposed as a standard API. They were neither envisaged for use by a broad range of clients nor intended to be permanent. Rather, they were introduced with the assumption that they were exclusively for use within the JDK, and that callers within the JDK would perform exhaustive safety checks before using them, and that safe standard APIs for this functionality would eventually be added to the Java Platform. However, with no way in 2002 to prevent sun.misc.Unsafe from being used outside the JDK, its memory-access methods became a handy tool for library developers who wanted more power and performance than standard APIs could offer. For example, sun.misc.Unsafe::compareAndSwap can perform a CAS (compare-and-swap) operation on a field without the overhead of the java.util.concurrent.atomic API, while sun.misc.Unsafe::setMemory can manipulate off-heap memory without the 2GB limitation of java.nio.ByteBuffer . Libraries that do rely on ByteBuffer to manipulate off-"
    }
  },
  {
    "url": "https://openjdk.org/jeps/503",
    "title": "JEP 503: Remove the 32-bit x86 Port",
    "content": {
      "title": "JEP 503: Remove the 32-bit x86 Port",
      "summary": "JEP 503: Remove the 32-bit x86 Port JEP 503: Remove the 32-bit x86 Port Owner Aleksey Shipilev Type Feature Scope Implementation Status Closed&#8201;/&#8201;Delivered Release 25 Component hotspot&#8201;/&#8201;other Discussion hotspot dash dev at openjdk dot org Effort M Duration M Relates to JEP 501: Deprecate the 32-bit x86 Port for Removal Reviewed by Mark Reinhold Created 2024/11/28 09:59 Updated 2025/08/01 18:15 Issue 8345168 Summary Remove the source code and build support for the 32-bit x",
      "sections": {
        "Summary": "Remove the source code and build support for the 32-bit x86 port. This port was deprecated for removal in JDK&#160;24 ( JEP&#160;501 ) with the express intent to remove it in a future release.",
        "Goals": "Unblock new features that require platform-specific support from having to implement 32-bit x86 fallbacks. Remove all code paths that apply only to 32-bit x86. Simplify the JDK's build and test infrastructure.",
        "Non-Goals": "It is not a goal to remove or change 32-bit support for any other architecture. It is not a goal to remove the 32-bit x86 port from past releases.",
        "Motivation": "As noted when we deprecated this port in JEP&#160;501 : The cost of maintaining this port outweighs the benefits. Maintaining parity with new features, such as Loom, the Foreign Function &amp; Memory API (FFM), the Vector API, late GC barrier expansion, etc., is a major opportunity cost. Deprecating and eventually removing the port would allow OpenJDK developers to accelerate the development of new features and enhancements.",
        "Description": "At present the 32-bit x86 port can still be be built, although it is not supported and not guaranteed to perform well. We will find and remove build and code support for 32-bit x86. Given the high cohesion between the 32-bit and 64-bit portions of the x86-specific code in the HotSpot JVM, we expect the deeper cleanups to take considerable time and have many on-going conflicts with the ever-changing HotSpot code. This is why we intend to remove the 32-bit x86 port early in the JDK 25 timeframe and then perform a series of follow-up cleanups in shared code, before large features begin integrating. We will modify the JDK build system to remove support for compiling on 32-bit x86 platforms, as well as update the JDK documentation to reflect the removal of 32-bit x86 support.",
        "Risks and Assumptions": "The original",
        "Specification": "Review Compiler Conformance Core Libraries Governing Board HotSpot IDE Tooling &amp; Support Internationalization JMX Members Networking Porters Quality Security Serviceability Vulnerability Web Projects ( overview , archive ) Amber Babylon CRaC Code Tools Coin Common VM Interface Developers' Guide Device I/O Duke Galahad Graal IcedTea JDK 8 Updates JDK 9 JDK (&#8230;, 24 , 25 , 26 ) JDK Updates JMC Jigsaw Kona Lanai Leyden Lilliput Locale Enhancement Loom Memory Model Update Metropolis Multi-Language VM Nashorn New I/O OpenJFX Panama Penrose Port: AArch32 Port: AArch64 Port: BSD Port: Haiku Port: Mac OS X Port: MIPS Port: Mobile Port: PowerPC/AIX Port: RISC-V Port: s390x SCTP Shenandoah Skara Sumatra Tsan Valhalla Verona VisualVM Wakefield Zero ZGC &#169; 2025 Oracle Corporation and/or its affiliates Terms of Use &#183; License: GPLv2 &#183; Privacy &#183; Trademarks"
      },
      "fullText": "JEP 503: Remove the 32-bit x86 Port JEP 503: Remove the 32-bit x86 Port Owner Aleksey Shipilev Type Feature Scope Implementation Status Closed&#8201;/&#8201;Delivered Release 25 Component hotspot&#8201;/&#8201;other Discussion hotspot dash dev at openjdk dot org Effort M Duration M Relates to JEP 501: Deprecate the 32-bit x86 Port for Removal Reviewed by Mark Reinhold Created 2024/11/28 09:59 Updated 2025/08/01 18:15 Issue 8345168 Summary Remove the source code and build support for the 32-bit x86 port. This port was deprecated for removal in JDK&#160;24 ( JEP&#160;501 ) with the express intent to remove it in a future release. Goals Unblock new features that require platform-specific support from having to implement 32-bit x86 fallbacks. Remove all code paths that apply only to 32-bit x86. Simplify the JDK's build and test infrastructure. Non-Goals It is not a goal to remove or change 32-bit support for any other architecture. It is not a goal to remove the 32-bit x86 port from past releases. Motivation As noted when we deprecated this port in JEP&#160;501 : The cost of maintaining this port outweighs the benefits. Maintaining parity with new features, such as Loom, the Foreign Function &amp; Memory API (FFM), the Vector API, late GC barrier expansion, etc., is a major opportunity cost. Deprecating and eventually removing the port would allow OpenJDK developers to accelerate the development of new features and enhancements. Description At present the 32-bit x86 port can still be be built, although it is not supported and not guaranteed to perform well. We will find and remove build and code support for 32-bit x86. Given the high cohesion between the 32-bit and 64-bit portions of the x86-specific code in the HotSpot JVM, we expect the deeper cleanups to take considerable time and have many on-going conflicts with the ever-changing HotSpot code. This is why we intend to remove the 32-bit x86 port early in the JDK 25 timeframe and then perform a series of follow-up cleanups in shared code, before large features begin integrating. We will modify the JDK build system to remove support for compiling on 32-bit x86 platforms, as well as update the JDK documentation to reflect the removal of 32-bit x86 support. Risks and Assumptions The original risks and assumptions from JEP&#160;501 apply here: There is no pressing industry need for 32-bit x86 with modern JDKs &#8212; We assume that the x86 world has moved firmly to the 64-bit realm. No new 32-bit-only x86 hardware is being manufactured. The remaining 32-bit x86 deployments are legacies. Industry support has dwindled to match this reality. Windows 10, the last Windows operating system to support 32-bit operation, will reach End of Life in October 2025 , and the Windows 32-bit x86 port has already been removed from the JDK ( JEP&#160;479 ). Debian plans to stop supporting 32-bit x86 in the near future. There is enough margin for backport safety with releases that still support 32-bit x86 &#8212; Not hav"
    }
  },
  {
    "url": "https://openjdk.org/jeps/479",
    "title": "JEP 479: Remove the Windows 32-bit x86 Port",
    "content": {
      "title": "JEP 479: Remove the Windows 32-bit x86 Port",
      "summary": "JEP 479: Remove the Windows 32-bit x86 Port JEP 479: Remove the Windows 32-bit x86 Port Author George Adams &amp; Saint Wesonga Owner George Adams Type Feature Scope Implementation Status Closed&#8201;/&#8201;Delivered Release 24 Component hotspot&#8201;/&#8201;other Discussion jdk dash dev at openjdk dot org Effort S Duration S Relates to JEP 449: Deprecate the Windows 32-bit x86 Port for Removal JEP 501: Deprecate the 32-bit x86 Port for Removal Reviewed by Magnus Ihse Bursie, Vladimir Kozlov ",
      "sections": {
        "Summary": "Remove the source code and build support for the Windows 32-bit x86 port. This port was deprecated for removal in JDK&#160;21 with the express intent to remove it in a future release.",
        "Goals": "Remove all code paths that apply only to Windows 32-bit x86. Cease all",
        "Non-Goals": "It is not a goal to remove or change 32-bit support for any platforms other than Windows. It is not a goal to remove either code or support for Windows 32-bit in previous releases.",
        "Motivation": "Allow contributors in the OpenJDK Community to accelerate the development of new features and enhancements that will move the platform forward. The implementation of JEP 436 (Virtual Threads) for Windows x86-32 falls back to the use of kernel threads and therefore does not bring the expected benefits of Project Loom. Windows 10, the last Windows operating system to support 32-bit operation, will reach End of Life in October 2025 .",
        "Description": "Find and remove all code paths in the code base that apply only to Windows 32-bit. Modify the JDK build system to remove support for compiling on Windows 32-bit platforms, and halt",
        "Testing": "and development efforts targeting the Windows 32-bit x86 platform. Simplify the JDK's build and test infrastructure.",
        "Risks and Assumptions": "Some users may still rely on 32-bit Java applications on Windows. This change requires Java applications running on 32-bit Windows to migrate to a 64-bit JDK and Windows environment, or else remain on legacy versions of the JDK, prior to JDK 23, which still include 32-bit support. Transition guidance and support by distributions and vendors of JDK binaries will be critical. Installing Contributing Sponsoring Developers' Guide Vulnerabilities JDK GA/EA Builds Mailing lists Wiki &#183; IRC Mastodon Bluesky Bylaws &#183; Census Legal Workshop JEP Process Source code GitHub Mercurial Tools Git jtreg harness Groups (overview) Adoption Build Client Libraries Compatibility &amp;",
        "Specification": "Review Compiler Conformance Core Libraries Governing Board HotSpot IDE Tooling &amp; Support Internationalization JMX Members Networking Porters Quality Security Serviceability Vulnerability Web Projects ( overview , archive ) Amber Babylon CRaC Code Tools Coin Common VM Interface Developers' Guide Device I/O Duke Galahad Graal IcedTea JDK 8 Updates JDK 9 JDK (&#8230;, 24 , 25 , 26 ) JDK Updates JMC Jigsaw Kona Lanai Leyden Lilliput Locale Enhancement Loom Memory Model Update Metropolis Multi-Language VM Nashorn New I/O OpenJFX Panama Penrose Port: AArch32 Port: AArch64 Port: BSD Port: Haiku Port: Mac OS X Port: MIPS Port: Mobile Port: PowerPC/AIX Port: RISC-V Port: s390x SCTP Shenandoah Skara Sumatra Tsan Valhalla Verona VisualVM Wakefield Zero ZGC &#169; 2025 Oracle Corporation and/or its affiliates Terms of Use &#183; License: GPLv2 &#183; Privacy &#183; Trademarks"
      },
      "fullText": "JEP 479: Remove the Windows 32-bit x86 Port JEP 479: Remove the Windows 32-bit x86 Port Author George Adams &amp; Saint Wesonga Owner George Adams Type Feature Scope Implementation Status Closed&#8201;/&#8201;Delivered Release 24 Component hotspot&#8201;/&#8201;other Discussion jdk dash dev at openjdk dot org Effort S Duration S Relates to JEP 449: Deprecate the Windows 32-bit x86 Port for Removal JEP 501: Deprecate the 32-bit x86 Port for Removal Reviewed by Magnus Ihse Bursie, Vladimir Kozlov Endorsed by Vladimir Kozlov Created 2024/04/19 07:33 Updated 2025/02/20 09:54 Issue 8330623 Summary Remove the source code and build support for the Windows 32-bit x86 port. This port was deprecated for removal in JDK&#160;21 with the express intent to remove it in a future release. Goals Remove all code paths that apply only to Windows 32-bit x86. Cease all testing and development efforts targeting the Windows 32-bit x86 platform. Simplify the JDK's build and test infrastructure. Non-Goals It is not a goal to remove or change 32-bit support for any platforms other than Windows. It is not a goal to remove either code or support for Windows 32-bit in previous releases. Motivation Allow contributors in the OpenJDK Community to accelerate the development of new features and enhancements that will move the platform forward. The implementation of JEP 436 (Virtual Threads) for Windows x86-32 falls back to the use of kernel threads and therefore does not bring the expected benefits of Project Loom. Windows 10, the last Windows operating system to support 32-bit operation, will reach End of Life in October 2025 . Description Find and remove all code paths in the code base that apply only to Windows 32-bit. Modify the JDK build system to remove support for compiling on Windows 32-bit platforms, and halt testing activities for this architecture. Update the JDK documentation to reflect the removal of Windows 32-bit support, and publicize this change so as to ensure a smooth transition for users and developers. Risks and Assumptions Some users may still rely on 32-bit Java applications on Windows. This change requires Java applications running on 32-bit Windows to migrate to a 64-bit JDK and Windows environment, or else remain on legacy versions of the JDK, prior to JDK 23, which still include 32-bit support. Transition guidance and support by distributions and vendors of JDK binaries will be critical. Installing Contributing Sponsoring Developers' Guide Vulnerabilities JDK GA/EA Builds Mailing lists Wiki &#183; IRC Mastodon Bluesky Bylaws &#183; Census Legal Workshop JEP Process Source code GitHub Mercurial Tools Git jtreg harness Groups (overview) Adoption Build Client Libraries Compatibility &amp; Specification Review Compiler Conformance Core Libraries Governing Board HotSpot IDE Tooling &amp; Support Internationalization JMX Members Networking Porters Quality Security Serviceability Vulnerability Web Projects ( overview , archive ) Amber Babylon CRaC Code Tools C"
    }
  }
]